/home/jjc/miniconda3/envs/ant_quant/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb3', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:42:48 - INFO - __main__ -   output/resnet50_imagenet/int_W8A8_5826/gpu_0
01/13/2023 15:42:48 - INFO - __main__ -   Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb3', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:42:48 - INFO - __main__ -   ==> Preparing data..
01/13/2023 15:42:50 - INFO - __main__ -   ==> Setting quantizer..
Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb3', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:42:50 - INFO - __main__ -   Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb3', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:42:50 - INFO - __main__ -   ==> Building model..
ResNet(
  (conv1): Conv2dQuantizer(
    (quant_weight): TensorQuantizer()
    (quant_input): TensorQuantizer()
  )
  (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): LinearQuantizer(
    (quant_weight): TensorQuantizer()
    (quant_input): TensorQuantizer()
  )
)
01/13/2023 15:42:50 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00025]}
01/13/2023 15:42:50 - INFO - __main__ -   
Epoch: 0
Layer quant EB csd_eb3
int	8-bit 	 conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer1.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.3.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.3.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer2.3.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.3.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.3.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.3.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.4.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.4.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.4.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.5.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.5.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer3.5.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 layer4.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb3
int	8-bit 	 fc.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 fc.quant_input,
set init to 1
01/13/2023 15:43:07 - INFO - __main__ -   test: [epoch: 0 | batch: 0/10010 ] | Loss: 0.678 | Acc: 80.469% (103/128)
01/13/2023 15:43:39 - INFO - __main__ -   test: [epoch: 0 | batch: 100/10010 ] | Loss: 0.841 | Acc: 79.247% (10245/12928)
01/13/2023 15:44:29 - INFO - __main__ -   test: [epoch: 0 | batch: 200/10010 ] | Loss: 0.825 | Acc: 79.412% (20431/25728)
01/13/2023 15:46:45 - INFO - __main__ -   test: [epoch: 0 | batch: 300/10010 ] | Loss: 0.838 | Acc: 79.057% (30459/38528)
01/13/2023 15:51:03 - INFO - __main__ -   test: [epoch: 0 | batch: 400/10010 ] | Loss: 0.849 | Acc: 78.789% (40441/51328)
01/13/2023 15:55:23 - INFO - __main__ -   test: [epoch: 0 | batch: 500/10010 ] | Loss: 0.851 | Acc: 78.669% (50449/64128)
01/13/2023 15:59:45 - INFO - __main__ -   test: [epoch: 0 | batch: 600/10010 ] | Loss: 0.852 | Acc: 78.668% (60518/76928)
01/13/2023 16:04:05 - INFO - __main__ -   test: [epoch: 0 | batch: 700/10010 ] | Loss: 0.852 | Acc: 78.698% (70614/89728)
01/13/2023 16:08:26 - INFO - __main__ -   test: [epoch: 0 | batch: 800/10010 ] | Loss: 0.854 | Acc: 78.656% (80644/102528)
01/13/2023 16:12:46 - INFO - __main__ -   test: [epoch: 0 | batch: 900/10010 ] | Loss: 0.855 | Acc: 78.647% (90702/115328)
01/13/2023 16:17:07 - INFO - __main__ -   test: [epoch: 0 | batch: 1000/10010 ] | Loss: 0.855 | Acc: 78.621% (100735/128128)
01/13/2023 16:21:28 - INFO - __main__ -   test: [epoch: 0 | batch: 1100/10010 ] | Loss: 0.857 | Acc: 78.627% (110807/140928)
01/13/2023 16:25:49 - INFO - __main__ -   test: [epoch: 0 | batch: 1200/10010 ] | Loss: 0.859 | Acc: 78.592% (120818/153728)
01/13/2023 16:30:11 - INFO - __main__ -   test: [epoch: 0 | batch: 1300/10010 ] | Loss: 0.857 | Acc: 78.644% (130964/166528)
01/13/2023 16:34:33 - INFO - __main__ -   test: [epoch: 0 | batch: 1400/10010 ] | Loss: 0.858 | Acc: 78.665% (141069/179328)
01/13/2023 16:38:54 - INFO - __main__ -   test: [epoch: 0 | batch: 1500/10010 ] | Loss: 0.856 | Acc: 78.710% (151223/192128)
01/13/2023 16:43:15 - INFO - __main__ -   test: [epoch: 0 | batch: 1600/10010 ] | Loss: 0.857 | Acc: 78.696% (161271/204928)
01/13/2023 16:47:37 - INFO - __main__ -   test: [epoch: 0 | batch: 1700/10010 ] | Loss: 0.857 | Acc: 78.690% (171330/217728)
01/13/2023 16:51:59 - INFO - __main__ -   test: [epoch: 0 | batch: 1800/10010 ] | Loss: 0.855 | Acc: 78.729% (181493/230528)
01/13/2023 16:56:20 - INFO - __main__ -   test: [epoch: 0 | batch: 1900/10010 ] | Loss: 0.854 | Acc: 78.735% (191585/243328)
01/13/2023 17:00:41 - INFO - __main__ -   test: [epoch: 0 | batch: 2000/10010 ] | Loss: 0.854 | Acc: 78.746% (201690/256128)
01/13/2023 17:05:01 - INFO - __main__ -   test: [epoch: 0 | batch: 2100/10010 ] | Loss: 0.854 | Acc: 78.726% (211717/268928)
01/13/2023 17:09:21 - INFO - __main__ -   test: [epoch: 0 | batch: 2200/10010 ] | Loss: 0.854 | Acc: 78.711% (221752/281728)
01/13/2023 17:13:42 - INFO - __main__ -   test: [epoch: 0 | batch: 2300/10010 ] | Loss: 0.855 | Acc: 78.706% (231811/294528)
01/13/2023 17:18:04 - INFO - __main__ -   test: [epoch: 0 | batch: 2400/10010 ] | Loss: 0.855 | Acc: 78.713% (241908/307328)
01/13/2023 17:22:24 - INFO - __main__ -   test: [epoch: 0 | batch: 2500/10010 ] | Loss: 0.855 | Acc: 78.713% (251982/320128)
01/13/2023 17:26:44 - INFO - __main__ -   test: [epoch: 0 | batch: 2600/10010 ] | Loss: 0.856 | Acc: 78.713% (262057/332928)
01/13/2023 17:31:06 - INFO - __main__ -   test: [epoch: 0 | batch: 2700/10010 ] | Loss: 0.855 | Acc: 78.714% (272138/345728)
01/13/2023 17:35:26 - INFO - __main__ -   test: [epoch: 0 | batch: 2800/10010 ] | Loss: 0.855 | Acc: 78.700% (282163/358528)
01/13/2023 17:39:45 - INFO - __main__ -   test: [epoch: 0 | batch: 2900/10010 ] | Loss: 0.855 | Acc: 78.692% (292206/371328)
01/13/2023 17:44:06 - INFO - __main__ -   test: [epoch: 0 | batch: 3000/10010 ] | Loss: 0.855 | Acc: 78.688% (302262/384128)
01/13/2023 17:48:24 - INFO - __main__ -   test: [epoch: 0 | batch: 3100/10010 ] | Loss: 0.855 | Acc: 78.687% (312329/396928)
01/13/2023 17:52:45 - INFO - __main__ -   test: [epoch: 0 | batch: 3200/10010 ] | Loss: 0.855 | Acc: 78.682% (322381/409728)
01/13/2023 17:57:05 - INFO - __main__ -   test: [epoch: 0 | batch: 3300/10010 ] | Loss: 0.856 | Acc: 78.670% (332401/422528)
01/13/2023 18:01:25 - INFO - __main__ -   test: [epoch: 0 | batch: 3400/10010 ] | Loss: 0.856 | Acc: 78.684% (342534/435328)
01/13/2023 18:05:46 - INFO - __main__ -   test: [epoch: 0 | batch: 3500/10010 ] | Loss: 0.855 | Acc: 78.692% (352639/448128)
01/13/2023 18:10:07 - INFO - __main__ -   test: [epoch: 0 | batch: 3600/10010 ] | Loss: 0.856 | Acc: 78.684% (362677/460928)
01/13/2023 18:14:27 - INFO - __main__ -   test: [epoch: 0 | batch: 3700/10010 ] | Loss: 0.856 | Acc: 78.671% (372688/473728)
01/13/2023 18:18:49 - INFO - __main__ -   test: [epoch: 0 | batch: 3800/10010 ] | Loss: 0.856 | Acc: 78.669% (382748/486528)
01/13/2023 18:23:10 - INFO - __main__ -   test: [epoch: 0 | batch: 3900/10010 ] | Loss: 0.856 | Acc: 78.655% (392746/499328)
01/13/2023 18:27:29 - INFO - __main__ -   test: [epoch: 0 | batch: 4000/10010 ] | Loss: 0.857 | Acc: 78.649% (402785/512128)
01/13/2023 18:31:49 - INFO - __main__ -   test: [epoch: 0 | batch: 4100/10010 ] | Loss: 0.857 | Acc: 78.652% (412865/524928)
01/13/2023 18:36:08 - INFO - __main__ -   test: [epoch: 0 | batch: 4200/10010 ] | Loss: 0.857 | Acc: 78.651% (422931/537728)
01/13/2023 18:40:28 - INFO - __main__ -   test: [epoch: 0 | batch: 4300/10010 ] | Loss: 0.857 | Acc: 78.653% (433005/550528)
01/13/2023 18:44:47 - INFO - __main__ -   test: [epoch: 0 | batch: 4400/10010 ] | Loss: 0.856 | Acc: 78.658% (443105/563328)
01/13/2023 18:49:08 - INFO - __main__ -   test: [epoch: 0 | batch: 4500/10010 ] | Loss: 0.857 | Acc: 78.650% (453122/576128)
01/13/2023 18:53:28 - INFO - __main__ -   test: [epoch: 0 | batch: 4600/10010 ] | Loss: 0.856 | Acc: 78.658% (463237/588928)
01/13/2023 18:57:49 - INFO - __main__ -   test: [epoch: 0 | batch: 4700/10010 ] | Loss: 0.857 | Acc: 78.658% (473308/601728)
01/13/2023 19:02:09 - INFO - __main__ -   test: [epoch: 0 | batch: 4800/10010 ] | Loss: 0.856 | Acc: 78.657% (483371/614528)
01/13/2023 19:06:27 - INFO - __main__ -   test: [epoch: 0 | batch: 4900/10010 ] | Loss: 0.857 | Acc: 78.660% (493457/627328)
01/13/2023 19:10:47 - INFO - __main__ -   test: [epoch: 0 | batch: 5000/10010 ] | Loss: 0.856 | Acc: 78.673% (503610/640128)
01/13/2023 19:15:08 - INFO - __main__ -   test: [epoch: 0 | batch: 5100/10010 ] | Loss: 0.856 | Acc: 78.677% (513706/652928)
01/13/2023 19:19:28 - INFO - __main__ -   test: [epoch: 0 | batch: 5200/10010 ] | Loss: 0.856 | Acc: 78.676% (523768/665728)
01/13/2023 19:23:47 - INFO - __main__ -   test: [epoch: 0 | batch: 5300/10010 ] | Loss: 0.856 | Acc: 78.681% (533876/678528)
01/13/2023 19:28:07 - INFO - __main__ -   test: [epoch: 0 | batch: 5400/10010 ] | Loss: 0.857 | Acc: 78.669% (543861/691328)
01/13/2023 19:32:28 - INFO - __main__ -   test: [epoch: 0 | batch: 5500/10010 ] | Loss: 0.857 | Acc: 78.661% (553873/704128)
01/13/2023 19:36:48 - INFO - __main__ -   test: [epoch: 0 | batch: 5600/10010 ] | Loss: 0.857 | Acc: 78.668% (563995/716928)
01/13/2023 19:41:09 - INFO - __main__ -   test: [epoch: 0 | batch: 5700/10010 ] | Loss: 0.856 | Acc: 78.671% (574081/729728)
01/13/2023 19:45:32 - INFO - __main__ -   test: [epoch: 0 | batch: 5800/10010 ] | Loss: 0.856 | Acc: 78.671% (584153/742528)
01/13/2023 19:49:53 - INFO - __main__ -   test: [epoch: 0 | batch: 5900/10010 ] | Loss: 0.856 | Acc: 78.678% (594276/755328)
01/13/2023 19:54:12 - INFO - __main__ -   test: [epoch: 0 | batch: 6000/10010 ] | Loss: 0.856 | Acc: 78.674% (604319/768128)
01/13/2023 19:58:33 - INFO - __main__ -   test: [epoch: 0 | batch: 6100/10010 ] | Loss: 0.857 | Acc: 78.674% (614387/780928)
01/13/2023 20:02:55 - INFO - __main__ -   test: [epoch: 0 | batch: 6200/10010 ] | Loss: 0.857 | Acc: 78.665% (624389/793728)
01/13/2023 20:07:16 - INFO - __main__ -   test: [epoch: 0 | batch: 6300/10010 ] | Loss: 0.857 | Acc: 78.664% (634450/806528)
01/13/2023 20:11:38 - INFO - __main__ -   test: [epoch: 0 | batch: 6400/10010 ] | Loss: 0.857 | Acc: 78.660% (644484/819328)
01/13/2023 20:15:57 - INFO - __main__ -   test: [epoch: 0 | batch: 6500/10010 ] | Loss: 0.857 | Acc: 78.658% (654536/832128)
01/13/2023 20:20:21 - INFO - __main__ -   test: [epoch: 0 | batch: 6600/10010 ] | Loss: 0.857 | Acc: 78.659% (664614/844928)
01/13/2023 20:24:41 - INFO - __main__ -   test: [epoch: 0 | batch: 6700/10010 ] | Loss: 0.857 | Acc: 78.662% (674709/857728)
01/13/2023 20:28:59 - INFO - __main__ -   test: [epoch: 0 | batch: 6800/10010 ] | Loss: 0.857 | Acc: 78.660% (684755/870528)
01/13/2023 20:33:19 - INFO - __main__ -   test: [epoch: 0 | batch: 6900/10010 ] | Loss: 0.857 | Acc: 78.664% (694862/883328)
01/13/2023 20:37:39 - INFO - __main__ -   test: [epoch: 0 | batch: 7000/10010 ] | Loss: 0.857 | Acc: 78.660% (704891/896128)
01/13/2023 20:41:59 - INFO - __main__ -   test: [epoch: 0 | batch: 7100/10010 ] | Loss: 0.857 | Acc: 78.668% (715039/908928)
01/13/2023 20:46:19 - INFO - __main__ -   test: [epoch: 0 | batch: 7200/10010 ] | Loss: 0.856 | Acc: 78.677% (725190/921728)
01/13/2023 20:50:39 - INFO - __main__ -   test: [epoch: 0 | batch: 7300/10010 ] | Loss: 0.857 | Acc: 78.668% (735175/934528)
01/13/2023 20:55:00 - INFO - __main__ -   test: [epoch: 0 | batch: 7400/10010 ] | Loss: 0.857 | Acc: 78.663% (745199/947328)
01/13/2023 20:59:21 - INFO - __main__ -   test: [epoch: 0 | batch: 7500/10010 ] | Loss: 0.857 | Acc: 78.667% (755303/960128)
01/13/2023 21:03:39 - INFO - __main__ -   test: [epoch: 0 | batch: 7600/10010 ] | Loss: 0.857 | Acc: 78.669% (765390/972928)
01/13/2023 21:08:00 - INFO - __main__ -   test: [epoch: 0 | batch: 7700/10010 ] | Loss: 0.857 | Acc: 78.659% (775360/985728)
01/13/2023 21:12:22 - INFO - __main__ -   test: [epoch: 0 | batch: 7800/10010 ] | Loss: 0.857 | Acc: 78.658% (785426/998528)
01/13/2023 21:16:43 - INFO - __main__ -   test: [epoch: 0 | batch: 7900/10010 ] | Loss: 0.858 | Acc: 78.661% (795523/1011328)
01/13/2023 21:21:04 - INFO - __main__ -   test: [epoch: 0 | batch: 8000/10010 ] | Loss: 0.858 | Acc: 78.657% (805548/1024128)
01/13/2023 21:25:24 - INFO - __main__ -   test: [epoch: 0 | batch: 8100/10010 ] | Loss: 0.857 | Acc: 78.662% (815673/1036928)
01/13/2023 21:29:45 - INFO - __main__ -   test: [epoch: 0 | batch: 8200/10010 ] | Loss: 0.857 | Acc: 78.656% (825678/1049728)
01/13/2023 21:34:07 - INFO - __main__ -   test: [epoch: 0 | batch: 8300/10010 ] | Loss: 0.857 | Acc: 78.658% (835762/1062528)
01/13/2023 21:38:29 - INFO - __main__ -   test: [epoch: 0 | batch: 8400/10010 ] | Loss: 0.857 | Acc: 78.659% (845845/1075328)
01/13/2023 21:42:50 - INFO - __main__ -   test: [epoch: 0 | batch: 8500/10010 ] | Loss: 0.857 | Acc: 78.664% (855960/1088128)
01/13/2023 21:47:11 - INFO - __main__ -   test: [epoch: 0 | batch: 8600/10010 ] | Loss: 0.857 | Acc: 78.658% (865970/1100928)
01/13/2023 21:51:33 - INFO - __main__ -   test: [epoch: 0 | batch: 8700/10010 ] | Loss: 0.857 | Acc: 78.657% (876022/1113728)
01/13/2023 21:55:51 - INFO - __main__ -   test: [epoch: 0 | batch: 8800/10010 ] | Loss: 0.857 | Acc: 78.657% (886094/1126528)
01/13/2023 22:00:12 - INFO - __main__ -   test: [epoch: 0 | batch: 8900/10010 ] | Loss: 0.857 | Acc: 78.661% (896208/1139328)
01/13/2023 22:04:33 - INFO - __main__ -   test: [epoch: 0 | batch: 9000/10010 ] | Loss: 0.857 | Acc: 78.664% (906305/1152128)
01/13/2023 22:08:53 - INFO - __main__ -   test: [epoch: 0 | batch: 9100/10010 ] | Loss: 0.857 | Acc: 78.661% (916349/1164928)
01/13/2023 22:13:15 - INFO - __main__ -   test: [epoch: 0 | batch: 9200/10010 ] | Loss: 0.857 | Acc: 78.661% (926411/1177728)
01/13/2023 22:17:36 - INFO - __main__ -   test: [epoch: 0 | batch: 9300/10010 ] | Loss: 0.857 | Acc: 78.665% (936524/1190528)
01/13/2023 22:21:57 - INFO - __main__ -   test: [epoch: 0 | batch: 9400/10010 ] | Loss: 0.857 | Acc: 78.664% (946587/1203328)
01/13/2023 22:26:17 - INFO - __main__ -   test: [epoch: 0 | batch: 9500/10010 ] | Loss: 0.857 | Acc: 78.668% (956702/1216128)
01/13/2023 22:30:39 - INFO - __main__ -   test: [epoch: 0 | batch: 9600/10010 ] | Loss: 0.857 | Acc: 78.667% (966762/1228928)
01/13/2023 22:35:02 - INFO - __main__ -   test: [epoch: 0 | batch: 9700/10010 ] | Loss: 0.857 | Acc: 78.664% (976794/1241728)
01/13/2023 22:39:23 - INFO - __main__ -   test: [epoch: 0 | batch: 9800/10010 ] | Loss: 0.857 | Acc: 78.659% (986804/1254528)
01/13/2023 22:43:43 - INFO - __main__ -   test: [epoch: 0 | batch: 9900/10010 ] | Loss: 0.857 | Acc: 78.665% (996942/1267328)
01/13/2023 22:48:04 - INFO - __main__ -   test: [epoch: 0 | batch: 10000/10010 ] | Loss: 0.857 | Acc: 78.662% (1006977/1280128)
01/13/2023 22:48:28 - INFO - __main__ -   Saving Checkpoint
01/13/2023 22:48:31 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.456 | Acc: 86.719% (111/128)/ 97.656% (125/128)
01/13/2023 22:48:34 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.468 | Acc: 86.328% (221/256)/ 98.047% (251/256)
01/13/2023 22:48:36 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.618 | Acc: 83.073% (319/384)/ 95.833% (368/384)
01/13/2023 22:48:39 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.570 | Acc: 84.766% (434/512)/ 96.484% (494/512)
01/13/2023 22:48:42 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.486 | Acc: 87.031% (557/640)/ 97.188% (622/640)
01/13/2023 22:48:44 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.430 | Acc: 88.151% (677/768)/ 97.656% (750/768)
01/13/2023 22:48:47 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.425 | Acc: 88.281% (791/896)/ 97.545% (874/896)
01/13/2023 22:48:49 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.406 | Acc: 89.258% (914/1024)/ 97.656% (1000/1024)
01/13/2023 22:48:52 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.424 | Acc: 89.149% (1027/1152)/ 97.569% (1124/1152)
01/13/2023 22:48:54 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.404 | Acc: 89.688% (1148/1280)/ 97.656% (1250/1280)
01/13/2023 22:48:57 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.454 | Acc: 88.423% (1245/1408)/ 97.514% (1373/1408)
01/13/2023 22:49:00 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.457 | Acc: 88.607% (1361/1536)/ 97.331% (1495/1536)
01/13/2023 22:49:02 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.506 | Acc: 87.560% (1457/1664)/ 96.995% (1614/1664)
01/13/2023 22:49:05 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.555 | Acc: 85.993% (1541/1792)/ 96.484% (1729/1792)
01/13/2023 22:49:08 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.576 | Acc: 85.260% (1637/1920)/ 96.562% (1854/1920)
01/13/2023 22:49:10 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.584 | Acc: 84.863% (1738/2048)/ 96.631% (1979/2048)
01/13/2023 22:49:13 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.593 | Acc: 84.651% (1842/2176)/ 96.461% (2099/2176)
01/13/2023 22:49:16 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.620 | Acc: 84.245% (1941/2304)/ 96.007% (2212/2304)
01/13/2023 22:49:18 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.641 | Acc: 83.635% (2034/2432)/ 95.847% (2331/2432)
01/13/2023 22:49:21 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.648 | Acc: 83.359% (2134/2560)/ 95.781% (2452/2560)
01/13/2023 22:49:23 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.646 | Acc: 83.445% (2243/2688)/ 95.685% (2572/2688)
01/13/2023 22:49:26 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.678 | Acc: 82.741% (2330/2816)/ 95.526% (2690/2816)
01/13/2023 22:49:29 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.678 | Acc: 82.575% (2431/2944)/ 95.550% (2813/2944)
01/13/2023 22:49:31 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.722 | Acc: 81.673% (2509/3072)/ 95.280% (2927/3072)
01/13/2023 22:49:34 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.740 | Acc: 81.281% (2601/3200)/ 95.156% (3045/3200)
01/13/2023 22:49:36 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.764 | Acc: 80.619% (2683/3328)/ 94.892% (3158/3328)
01/13/2023 22:49:39 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.778 | Acc: 79.977% (2764/3456)/ 94.878% (3279/3456)
01/13/2023 22:49:41 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.760 | Acc: 80.497% (2885/3584)/ 94.922% (3402/3584)
01/13/2023 22:49:44 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.768 | Acc: 79.984% (2969/3712)/ 94.989% (3526/3712)
01/13/2023 22:49:46 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.761 | Acc: 80.130% (3077/3840)/ 95.104% (3652/3840)
01/13/2023 22:49:49 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.776 | Acc: 80.040% (3176/3968)/ 94.985% (3769/3968)
01/13/2023 22:49:52 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.772 | Acc: 80.249% (3287/4096)/ 95.068% (3894/4096)
01/13/2023 22:49:54 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.757 | Acc: 80.540% (3402/4224)/ 95.147% (4019/4224)
01/13/2023 22:49:57 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.751 | Acc: 80.744% (3514/4352)/ 95.198% (4143/4352)
01/13/2023 22:50:00 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.737 | Acc: 81.116% (3634/4480)/ 95.268% (4268/4480)
01/13/2023 22:50:02 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.724 | Acc: 81.489% (3755/4608)/ 95.269% (4390/4608)
01/13/2023 22:50:05 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.709 | Acc: 81.905% (3879/4736)/ 95.376% (4517/4736)
01/13/2023 22:50:07 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.700 | Acc: 82.216% (3999/4864)/ 95.436% (4642/4864)
01/13/2023 22:50:10 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.692 | Acc: 82.352% (4111/4992)/ 95.513% (4768/4992)
01/13/2023 22:50:12 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.687 | Acc: 82.402% (4219/5120)/ 95.547% (4892/5120)
01/13/2023 22:50:15 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.685 | Acc: 82.527% (4331/5248)/ 95.446% (5009/5248)
01/13/2023 22:50:17 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.690 | Acc: 82.552% (4438/5376)/ 95.387% (5128/5376)
01/13/2023 22:50:20 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.690 | Acc: 82.485% (4540/5504)/ 95.440% (5253/5504)
01/13/2023 22:50:23 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.687 | Acc: 82.564% (4650/5632)/ 95.401% (5373/5632)
01/13/2023 22:50:25 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.691 | Acc: 82.569% (4756/5760)/ 95.312% (5490/5760)
01/13/2023 22:50:28 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.688 | Acc: 82.711% (4870/5888)/ 95.329% (5613/5888)
01/13/2023 22:50:30 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.691 | Acc: 82.663% (4973/6016)/ 95.362% (5737/6016)
01/13/2023 22:50:33 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.692 | Acc: 82.617% (5076/6144)/ 95.410% (5862/6144)
01/13/2023 22:50:36 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.697 | Acc: 82.446% (5171/6272)/ 95.392% (5983/6272)
01/13/2023 22:50:38 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.701 | Acc: 82.516% (5281/6400)/ 95.312% (6100/6400)
01/13/2023 22:50:41 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.692 | Acc: 82.721% (5400/6528)/ 95.358% (6225/6528)
01/13/2023 22:50:43 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.685 | Acc: 82.918% (5519/6656)/ 95.433% (6352/6656)
01/13/2023 22:50:46 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.681 | Acc: 83.004% (5631/6784)/ 95.460% (6476/6784)
01/13/2023 22:50:49 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.672 | Acc: 83.203% (5751/6912)/ 95.530% (6603/6912)
01/13/2023 22:50:51 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.665 | Acc: 83.338% (5867/7040)/ 95.554% (6727/7040)
01/13/2023 22:50:54 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.659 | Acc: 83.482% (5984/7168)/ 95.592% (6852/7168)
01/13/2023 22:50:57 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.651 | Acc: 83.690% (6106/7296)/ 95.641% (6978/7296)
01/13/2023 22:50:59 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.644 | Acc: 83.877% (6227/7424)/ 95.690% (7104/7424)
01/13/2023 22:51:02 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.642 | Acc: 83.938% (6339/7552)/ 95.697% (7227/7552)
01/13/2023 22:51:05 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.644 | Acc: 83.854% (6440/7680)/ 95.716% (7351/7680)
01/13/2023 22:51:07 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.649 | Acc: 83.747% (6539/7808)/ 95.684% (7471/7808)
01/13/2023 22:51:10 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.650 | Acc: 83.758% (6647/7936)/ 95.703% (7595/7936)
01/13/2023 22:51:12 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.649 | Acc: 83.718% (6751/8064)/ 95.722% (7719/8064)
01/13/2023 22:51:15 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.657 | Acc: 83.582% (6847/8192)/ 95.642% (7835/8192)
01/13/2023 22:51:18 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.665 | Acc: 83.377% (6937/8320)/ 95.589% (7953/8320)
01/13/2023 22:51:20 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.678 | Acc: 82.872% (7001/8448)/ 95.514% (8069/8448)
01/13/2023 22:51:23 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.683 | Acc: 82.871% (7107/8576)/ 95.476% (8188/8576)
01/13/2023 22:51:25 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.685 | Acc: 82.790% (7206/8704)/ 95.485% (8311/8704)
01/13/2023 22:51:28 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.686 | Acc: 82.745% (7308/8832)/ 95.505% (8435/8832)
01/13/2023 22:51:31 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.681 | Acc: 82.835% (7422/8960)/ 95.547% (8561/8960)
01/13/2023 22:51:33 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.683 | Acc: 82.768% (7522/9088)/ 95.555% (8684/9088)
01/13/2023 22:51:36 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.681 | Acc: 82.812% (7632/9216)/ 95.562% (8807/9216)
01/13/2023 22:51:39 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.683 | Acc: 82.705% (7728/9344)/ 95.580% (8931/9344)
01/13/2023 22:51:41 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.687 | Acc: 82.580% (7822/9472)/ 95.587% (9054/9472)
01/13/2023 22:51:44 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.688 | Acc: 82.552% (7925/9600)/ 95.583% (9176/9600)
01/13/2023 22:51:46 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.693 | Acc: 82.381% (8014/9728)/ 95.559% (9296/9728)
01/13/2023 22:51:49 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.693 | Acc: 82.366% (8118/9856)/ 95.566% (9419/9856)
01/13/2023 22:51:51 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.693 | Acc: 82.332% (8220/9984)/ 95.593% (9544/9984)
01/13/2023 22:51:54 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.693 | Acc: 82.229% (8315/10112)/ 95.639% (9671/10112)
01/13/2023 22:51:56 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.692 | Acc: 82.227% (8420/10240)/ 95.664% (9796/10240)
01/13/2023 22:51:59 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.691 | Acc: 82.215% (8524/10368)/ 95.669% (9919/10368)
01/13/2023 22:52:01 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.690 | Acc: 82.222% (8630/10496)/ 95.694% (10044/10496)
01/13/2023 22:52:04 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.690 | Acc: 82.229% (8736/10624)/ 95.689% (10166/10624)
01/13/2023 22:52:07 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.690 | Acc: 82.273% (8846/10752)/ 95.675% (10287/10752)
01/13/2023 22:52:09 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.686 | Acc: 82.381% (8963/10880)/ 95.708% (10413/10880)
01/13/2023 22:52:12 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.684 | Acc: 82.376% (9068/11008)/ 95.749% (10540/11008)
01/13/2023 22:52:14 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.688 | Acc: 82.301% (9165/11136)/ 95.717% (10659/11136)
01/13/2023 22:52:17 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.686 | Acc: 82.342% (9275/11264)/ 95.721% (10782/11264)
01/13/2023 22:52:19 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.693 | Acc: 82.286% (9374/11392)/ 95.655% (10897/11392)
01/13/2023 22:52:22 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.691 | Acc: 82.318% (9483/11520)/ 95.660% (11020/11520)
01/13/2023 22:52:25 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.692 | Acc: 82.203% (9575/11648)/ 95.664% (11143/11648)
01/13/2023 22:52:27 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.691 | Acc: 82.261% (9687/11776)/ 95.678% (11267/11776)
01/13/2023 22:52:30 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.692 | Acc: 82.241% (9790/11904)/ 95.665% (11388/11904)
01/13/2023 22:52:33 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.696 | Acc: 82.048% (9872/12032)/ 95.695% (11514/12032)
01/13/2023 22:52:35 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.698 | Acc: 81.916% (9961/12160)/ 95.707% (11638/12160)
01/13/2023 22:52:38 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.696 | Acc: 81.982% (10074/12288)/ 95.711% (11761/12288)
01/13/2023 22:52:41 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.699 | Acc: 81.902% (10169/12416)/ 95.723% (11885/12416)
01/13/2023 22:52:43 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.700 | Acc: 81.736% (10253/12544)/ 95.743% (12010/12544)
01/13/2023 22:52:46 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.697 | Acc: 81.834% (10370/12672)/ 95.770% (12136/12672)
01/13/2023 22:52:49 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.691 | Acc: 81.977% (10493/12800)/ 95.812% (12264/12800)
01/13/2023 22:52:51 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.690 | Acc: 82.024% (10604/12928)/ 95.823% (12388/12928)
01/13/2023 22:52:54 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.686 | Acc: 82.123% (10722/13056)/ 95.856% (12515/13056)
01/13/2023 22:52:56 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.683 | Acc: 82.259% (10845/13184)/ 95.881% (12641/13184)
01/13/2023 22:52:59 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.684 | Acc: 82.099% (10929/13312)/ 95.891% (12765/13312)
01/13/2023 22:53:02 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.684 | Acc: 82.039% (11026/13440)/ 95.885% (12887/13440)
01/13/2023 22:53:04 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.685 | Acc: 82.031% (11130/13568)/ 95.887% (13010/13568)
01/13/2023 22:53:06 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.693 | Acc: 81.929% (11221/13696)/ 95.824% (13124/13696)
01/13/2023 22:53:09 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.690 | Acc: 82.053% (11343/13824)/ 95.855% (13251/13824)
01/13/2023 22:53:11 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.693 | Acc: 81.917% (11429/13952)/ 95.864% (13375/13952)
01/13/2023 22:53:14 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.694 | Acc: 81.889% (11530/14080)/ 95.859% (13497/14080)
01/13/2023 22:53:17 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.697 | Acc: 81.707% (11609/14208)/ 95.869% (13621/14208)
01/13/2023 22:53:19 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.700 | Acc: 81.662% (11707/14336)/ 95.850% (13741/14336)
01/13/2023 22:53:22 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.700 | Acc: 81.679% (11814/14464)/ 95.866% (13866/14464)
01/13/2023 22:53:25 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.699 | Acc: 81.723% (11925/14592)/ 95.874% (13990/14592)
01/13/2023 22:53:27 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.696 | Acc: 81.814% (12043/14720)/ 95.897% (14116/14720)
01/13/2023 22:53:30 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.693 | Acc: 81.903% (12161/14848)/ 95.919% (14242/14848)
01/13/2023 22:53:33 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.696 | Acc: 81.858% (12259/14976)/ 95.880% (14359/14976)
01/13/2023 22:53:35 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.694 | Acc: 81.879% (12367/15104)/ 95.889% (14483/15104)
01/13/2023 22:53:38 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.698 | Acc: 81.769% (12455/15232)/ 95.903% (14608/15232)
01/13/2023 22:53:40 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.696 | Acc: 81.823% (12568/15360)/ 95.924% (14734/15360)
01/13/2023 22:53:43 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.695 | Acc: 81.870% (12680/15488)/ 95.939% (14859/15488)
01/13/2023 22:53:45 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.700 | Acc: 81.737% (12764/15616)/ 95.902% (14976/15616)
01/13/2023 22:53:48 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.702 | Acc: 81.676% (12859/15744)/ 95.871% (15094/15744)
01/13/2023 22:53:51 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.703 | Acc: 81.691% (12966/15872)/ 95.867% (15216/15872)
01/13/2023 22:53:54 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.702 | Acc: 81.700% (13072/16000)/ 95.881% (15341/16000)
01/13/2023 22:53:56 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.698 | Acc: 81.796% (13192/16128)/ 95.908% (15468/16128)
01/13/2023 22:53:59 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.694 | Acc: 81.884% (13311/16256)/ 95.922% (15593/16256)
01/13/2023 22:54:01 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.692 | Acc: 81.964% (13429/16384)/ 95.929% (15717/16384)
01/13/2023 22:54:04 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.693 | Acc: 81.946% (13531/16512)/ 95.906% (15836/16512)
01/13/2023 22:54:07 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.692 | Acc: 81.959% (13638/16640)/ 95.913% (15960/16640)
01/13/2023 22:54:09 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.688 | Acc: 82.055% (13759/16768)/ 95.933% (16086/16768)
01/13/2023 22:54:12 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.688 | Acc: 82.102% (13872/16896)/ 95.940% (16210/16896)
01/13/2023 22:54:15 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.686 | Acc: 82.172% (13989/17024)/ 95.953% (16335/17024)
01/13/2023 22:54:17 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.687 | Acc: 82.125% (14086/17152)/ 95.942% (16456/17152)
01/13/2023 22:54:20 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.685 | Acc: 82.153% (14196/17280)/ 95.966% (16583/17280)
01/13/2023 22:54:23 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.685 | Acc: 82.146% (14300/17408)/ 95.962% (16705/17408)
01/13/2023 22:54:25 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.684 | Acc: 82.111% (14399/17536)/ 95.985% (16832/17536)
01/13/2023 22:54:28 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.682 | Acc: 82.150% (14511/17664)/ 96.014% (16960/17664)
01/13/2023 22:54:30 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.681 | Acc: 82.166% (14619/17792)/ 96.021% (17084/17792)
01/13/2023 22:54:33 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.687 | Acc: 82.009% (14696/17920)/ 96.010% (17205/17920)
01/13/2023 22:54:35 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.689 | Acc: 81.943% (14789/18048)/ 96.005% (17327/18048)
01/13/2023 22:54:38 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.687 | Acc: 81.982% (14901/18176)/ 96.017% (17452/18176)
01/13/2023 22:54:40 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.685 | Acc: 82.064% (15021/18304)/ 96.034% (17578/18304)
01/13/2023 22:54:43 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.686 | Acc: 82.080% (15129/18432)/ 96.018% (17698/18432)
01/13/2023 22:54:46 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.687 | Acc: 82.058% (15230/18560)/ 95.991% (17816/18560)
01/13/2023 22:54:48 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.690 | Acc: 82.037% (15331/18688)/ 95.965% (17934/18688)
01/13/2023 22:54:51 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.692 | Acc: 82.021% (15433/18816)/ 95.945% (18053/18816)
01/13/2023 22:54:53 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.692 | Acc: 82.021% (15538/18944)/ 95.925% (18172/18944)
01/13/2023 22:54:56 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.693 | Acc: 81.958% (15631/19072)/ 95.926% (18295/19072)
01/13/2023 22:54:58 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.697 | Acc: 81.854% (15716/19200)/ 95.891% (18411/19200)
01/13/2023 22:55:01 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.698 | Acc: 81.788% (15808/19328)/ 95.897% (18535/19328)
01/13/2023 22:55:04 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.698 | Acc: 81.815% (15918/19456)/ 95.898% (18658/19456)
01/13/2023 22:55:06 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.699 | Acc: 81.807% (16021/19584)/ 95.890% (18779/19584)
01/13/2023 22:55:09 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.697 | Acc: 81.864% (16137/19712)/ 95.891% (18902/19712)
01/13/2023 22:55:11 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.697 | Acc: 81.845% (16238/19840)/ 95.867% (19020/19840)
01/13/2023 22:55:14 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.697 | Acc: 81.856% (16345/19968)/ 95.853% (19140/19968)
01/13/2023 22:55:16 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.699 | Acc: 81.772% (16433/20096)/ 95.840% (19260/20096)
01/13/2023 22:55:19 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.701 | Acc: 81.759% (16535/20224)/ 95.817% (19378/20224)
01/13/2023 22:55:21 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.702 | Acc: 81.722% (16632/20352)/ 95.794% (19496/20352)
01/13/2023 22:55:24 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.704 | Acc: 81.699% (16732/20480)/ 95.786% (19617/20480)
01/13/2023 22:55:27 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.704 | Acc: 81.672% (16831/20608)/ 95.769% (19736/20608)
01/13/2023 22:55:29 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.713 | Acc: 81.457% (16891/20736)/ 95.679% (19840/20736)
01/13/2023 22:55:32 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.719 | Acc: 81.360% (16975/20864)/ 95.610% (19948/20864)
01/13/2023 22:55:34 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.721 | Acc: 81.307% (17068/20992)/ 95.598% (20068/20992)
01/13/2023 22:55:37 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.721 | Acc: 81.297% (17170/21120)/ 95.616% (20194/21120)
01/13/2023 22:55:39 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.723 | Acc: 81.222% (17258/21248)/ 95.614% (20316/21248)
01/13/2023 22:55:42 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.723 | Acc: 81.227% (17363/21376)/ 95.598% (20435/21376)
01/13/2023 22:55:44 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.725 | Acc: 81.171% (17455/21504)/ 95.582% (20554/21504)
01/13/2023 22:55:47 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.724 | Acc: 81.176% (17560/21632)/ 95.581% (20676/21632)
01/13/2023 22:55:50 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.726 | Acc: 81.140% (17656/21760)/ 95.547% (20791/21760)
01/13/2023 22:55:52 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.731 | Acc: 81.031% (17736/21888)/ 95.504% (20904/21888)
01/13/2023 22:55:54 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.734 | Acc: 80.977% (17828/22016)/ 95.476% (21020/22016)
01/13/2023 22:55:57 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.735 | Acc: 80.929% (17921/22144)/ 95.475% (21142/22144)
01/13/2023 22:56:00 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.737 | Acc: 80.873% (18012/22272)/ 95.447% (21258/22272)
01/13/2023 22:56:02 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.741 | Acc: 80.790% (18097/22400)/ 95.402% (21370/22400)
01/13/2023 22:56:05 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.740 | Acc: 80.833% (18210/22528)/ 95.406% (21493/22528)
01/13/2023 22:56:07 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.740 | Acc: 80.840% (18315/22656)/ 95.388% (21611/22656)
01/13/2023 22:56:10 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.744 | Acc: 80.767% (18402/22784)/ 95.348% (21724/22784)
01/13/2023 22:56:13 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.745 | Acc: 80.744% (18500/22912)/ 95.326% (21841/22912)
01/13/2023 22:56:15 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.749 | Acc: 80.694% (18592/23040)/ 95.291% (21955/23040)
01/13/2023 22:56:18 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.755 | Acc: 80.568% (18666/23168)/ 95.256% (22069/23168)
01/13/2023 22:56:21 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.761 | Acc: 80.434% (18738/23296)/ 95.201% (22178/23296)
01/13/2023 22:56:23 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.760 | Acc: 80.447% (18844/23424)/ 95.202% (22300/23424)
01/13/2023 22:56:26 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.766 | Acc: 80.316% (18916/23552)/ 95.113% (22401/23552)
01/13/2023 22:56:28 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.766 | Acc: 80.342% (19025/23680)/ 95.101% (22520/23680)
01/13/2023 22:56:31 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.766 | Acc: 80.355% (19131/23808)/ 95.094% (22640/23808)
01/13/2023 22:56:34 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.769 | Acc: 80.318% (19225/23936)/ 95.049% (22751/23936)
01/13/2023 22:56:36 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.773 | Acc: 80.203% (19300/24064)/ 95.022% (22866/24064)
01/13/2023 22:56:39 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.777 | Acc: 80.072% (19371/24192)/ 94.998% (22982/24192)
01/13/2023 22:56:41 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.778 | Acc: 80.004% (19457/24320)/ 95.000% (23104/24320)
01/13/2023 22:56:44 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.783 | Acc: 79.917% (19538/24448)/ 94.981% (23221/24448)
01/13/2023 22:56:47 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.785 | Acc: 79.887% (19633/24576)/ 94.954% (23336/24576)
01/13/2023 22:56:49 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.792 | Acc: 79.773% (19707/24704)/ 94.871% (23437/24704)
01/13/2023 22:56:52 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.792 | Acc: 79.792% (19814/24832)/ 94.870% (23558/24832)
01/13/2023 22:56:55 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.794 | Acc: 79.728% (19900/24960)/ 94.848% (23674/24960)
01/13/2023 22:56:57 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.800 | Acc: 79.656% (19984/25088)/ 94.782% (23779/25088)
01/13/2023 22:57:00 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.803 | Acc: 79.553% (20060/25216)/ 94.734% (23888/25216)
01/13/2023 22:57:02 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.807 | Acc: 79.470% (20141/25344)/ 94.713% (24004/25344)
01/13/2023 22:57:05 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.809 | Acc: 79.432% (20233/25472)/ 94.680% (24117/25472)
01/13/2023 22:57:07 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.809 | Acc: 79.414% (20330/25600)/ 94.688% (24240/25600)
01/13/2023 22:57:10 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.809 | Acc: 79.377% (20422/25728)/ 94.687% (24361/25728)
01/13/2023 22:57:13 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.812 | Acc: 79.293% (20502/25856)/ 94.651% (24473/25856)
01/13/2023 22:57:15 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.813 | Acc: 79.283% (20601/25984)/ 94.639% (24591/25984)
01/13/2023 22:57:18 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.814 | Acc: 79.274% (20700/26112)/ 94.627% (24709/26112)
01/13/2023 22:57:20 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.817 | Acc: 79.192% (20780/26240)/ 94.607% (24825/26240)
01/13/2023 22:57:23 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.820 | Acc: 79.107% (20859/26368)/ 94.581% (24939/26368)
01/13/2023 22:57:25 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.822 | Acc: 79.091% (20956/26496)/ 94.577% (25059/26496)
01/13/2023 22:57:28 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.825 | Acc: 79.004% (21034/26624)/ 94.535% (25169/26624)
01/13/2023 22:57:30 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.827 | Acc: 78.966% (21125/26752)/ 94.509% (25283/26752)
01/13/2023 22:57:33 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.827 | Acc: 78.966% (21226/26880)/ 94.528% (25409/26880)
01/13/2023 22:57:35 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.828 | Acc: 78.951% (21323/27008)/ 94.509% (25525/27008)
01/13/2023 22:57:38 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.830 | Acc: 78.892% (21408/27136)/ 94.487% (25640/27136)
01/13/2023 22:57:41 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.833 | Acc: 78.822% (21490/27264)/ 94.465% (25755/27264)
01/13/2023 22:57:43 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.832 | Acc: 78.833% (21594/27392)/ 94.473% (25878/27392)
01/13/2023 22:57:46 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.833 | Acc: 78.812% (21689/27520)/ 94.473% (25999/27520)
01/13/2023 22:57:48 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.832 | Acc: 78.830% (21795/27648)/ 94.466% (26118/27648)
01/13/2023 22:57:51 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.831 | Acc: 78.870% (21907/27776)/ 94.488% (26245/27776)
01/13/2023 22:57:54 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.836 | Acc: 78.799% (21988/27904)/ 94.424% (26348/27904)
01/13/2023 22:57:56 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.838 | Acc: 78.739% (22072/28032)/ 94.385% (26458/28032)
01/13/2023 22:57:59 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.837 | Acc: 78.775% (22183/28160)/ 94.389% (26580/28160)
01/13/2023 22:58:02 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.835 | Acc: 78.804% (22292/28288)/ 94.404% (26705/28288)
01/13/2023 22:58:04 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.837 | Acc: 78.762% (22381/28416)/ 94.387% (26821/28416)
01/13/2023 22:58:07 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.835 | Acc: 78.822% (22499/28544)/ 94.402% (26946/28544)
01/13/2023 22:58:09 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.835 | Acc: 78.823% (22600/28672)/ 94.392% (27064/28672)
01/13/2023 22:58:12 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.835 | Acc: 78.844% (22707/28800)/ 94.385% (27183/28800)
01/13/2023 22:58:14 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.834 | Acc: 78.844% (22808/28928)/ 94.390% (27305/28928)
01/13/2023 22:58:17 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.834 | Acc: 78.813% (22900/29056)/ 94.394% (27427/29056)
01/13/2023 22:58:19 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.836 | Acc: 78.800% (22997/29184)/ 94.380% (27544/29184)
01/13/2023 22:58:22 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.841 | Acc: 78.739% (23080/29312)/ 94.323% (27648/29312)
01/13/2023 22:58:25 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.844 | Acc: 78.682% (23164/29440)/ 94.276% (27755/29440)
01/13/2023 22:58:27 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.847 | Acc: 78.629% (23249/29568)/ 94.240% (27865/29568)
01/13/2023 22:58:30 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.847 | Acc: 78.620% (23347/29696)/ 94.225% (27981/29696)
01/13/2023 22:58:32 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.846 | Acc: 78.648% (23456/29824)/ 94.240% (28106/29824)
01/13/2023 22:58:35 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.848 | Acc: 78.596% (23541/29952)/ 94.221% (28221/29952)
01/13/2023 22:58:37 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.854 | Acc: 78.477% (23606/30080)/ 94.149% (28320/30080)
01/13/2023 22:58:40 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.854 | Acc: 78.469% (23704/30208)/ 94.151% (28441/30208)
01/13/2023 22:58:43 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.853 | Acc: 78.514% (23818/30336)/ 94.159% (28564/30336)
01/13/2023 22:58:45 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.853 | Acc: 78.519% (23920/30464)/ 94.131% (28676/30464)
01/13/2023 22:58:48 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.852 | Acc: 78.556% (24032/30592)/ 94.139% (28799/30592)
01/13/2023 22:58:51 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.851 | Acc: 78.594% (24144/30720)/ 94.137% (28919/30720)
01/13/2023 22:58:53 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.851 | Acc: 78.608% (24249/30848)/ 94.129% (29037/30848)
01/13/2023 22:58:56 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.854 | Acc: 78.516% (24321/30976)/ 94.092% (29146/30976)
01/13/2023 22:58:58 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.856 | Acc: 78.411% (24389/31104)/ 94.072% (29260/31104)
01/13/2023 22:59:01 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.862 | Acc: 78.282% (24449/31232)/ 94.009% (29361/31232)
01/13/2023 22:59:04 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.862 | Acc: 78.291% (24552/31360)/ 94.005% (29480/31360)
01/13/2023 22:59:06 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.862 | Acc: 78.306% (24657/31488)/ 93.995% (29597/31488)
01/13/2023 22:59:09 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.863 | Acc: 78.283% (24750/31616)/ 93.984% (29714/31616)
01/13/2023 22:59:12 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.868 | Acc: 78.191% (24821/31744)/ 93.904% (29809/31744)
01/13/2023 22:59:14 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.869 | Acc: 78.153% (24909/31872)/ 93.894% (29926/31872)
01/13/2023 22:59:17 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.871 | Acc: 78.037% (24972/32000)/ 93.884% (30043/32000)
01/13/2023 22:59:19 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.870 | Acc: 78.066% (25081/32128)/ 93.903% (30169/32128)
01/13/2023 22:59:22 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.872 | Acc: 78.026% (25168/32256)/ 93.871% (30279/32256)
01/13/2023 22:59:25 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.871 | Acc: 78.057% (25278/32384)/ 93.864% (30397/32384)
01/13/2023 22:59:27 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.872 | Acc: 78.030% (25369/32512)/ 93.848% (30512/32512)
01/13/2023 22:59:30 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.877 | Acc: 77.966% (25448/32640)/ 93.802% (30617/32640)
01/13/2023 22:59:32 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.879 | Acc: 77.933% (25537/32768)/ 93.793% (30734/32768)
01/13/2023 22:59:35 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.884 | Acc: 77.815% (25598/32896)/ 93.759% (30843/32896)
01/13/2023 22:59:38 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.884 | Acc: 77.801% (25693/33024)/ 93.747% (30959/33024)
01/13/2023 22:59:40 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.885 | Acc: 77.781% (25786/33152)/ 93.732% (31074/33152)
01/13/2023 22:59:43 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.889 | Acc: 77.665% (25847/33280)/ 93.717% (31189/33280)
01/13/2023 22:59:46 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.890 | Acc: 77.634% (25936/33408)/ 93.711% (31307/33408)
01/13/2023 22:59:48 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.888 | Acc: 77.678% (26050/33536)/ 93.732% (31434/33536)
01/13/2023 22:59:51 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.887 | Acc: 77.700% (26157/33664)/ 93.741% (31557/33664)
01/13/2023 22:59:53 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.890 | Acc: 77.637% (26235/33792)/ 93.714% (31668/33792)
01/13/2023 22:59:56 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.895 | Acc: 77.577% (26314/33920)/ 93.653% (31767/33920)
01/13/2023 22:59:58 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.894 | Acc: 77.605% (26423/34048)/ 93.656% (31888/34048)
01/13/2023 23:00:01 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.896 | Acc: 77.537% (26499/34176)/ 93.639% (32002/34176)
01/13/2023 23:00:04 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.896 | Acc: 77.568% (26609/34304)/ 93.639% (32122/34304)
01/13/2023 23:00:06 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.895 | Acc: 77.591% (26716/34432)/ 93.634% (32240/34432)
01/13/2023 23:00:09 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.897 | Acc: 77.541% (26798/34560)/ 93.614% (32353/34560)
01/13/2023 23:00:11 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.900 | Acc: 77.479% (26876/34688)/ 93.583% (32462/34688)
01/13/2023 23:00:14 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.900 | Acc: 77.490% (26979/34816)/ 93.578% (32580/34816)
01/13/2023 23:00:17 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.901 | Acc: 77.455% (27066/34944)/ 93.575% (32699/34944)
01/13/2023 23:00:19 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.901 | Acc: 77.464% (27168/35072)/ 93.565% (32815/35072)
01/13/2023 23:00:22 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.901 | Acc: 77.460% (27266/35200)/ 93.568% (32936/35200)
01/13/2023 23:00:25 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.903 | Acc: 77.434% (27356/35328)/ 93.560% (33053/35328)
01/13/2023 23:00:27 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.904 | Acc: 77.403% (27444/35456)/ 93.558% (33172/35456)
01/13/2023 23:00:30 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.904 | Acc: 77.375% (27533/35584)/ 93.553% (33290/35584)
01/13/2023 23:00:32 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.904 | Acc: 77.383% (27635/35712)/ 93.551% (33409/35712)
01/13/2023 23:00:35 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.905 | Acc: 77.394% (27738/35840)/ 93.544% (33526/35840)
01/13/2023 23:00:37 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.905 | Acc: 77.377% (27831/35968)/ 93.536% (33643/35968)
01/13/2023 23:00:40 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.905 | Acc: 77.388% (27934/36096)/ 93.531% (33761/36096)
01/13/2023 23:00:42 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.904 | Acc: 77.424% (28046/36224)/ 93.535% (33882/36224)
01/13/2023 23:00:45 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.905 | Acc: 77.396% (28135/36352)/ 93.530% (34000/36352)
01/13/2023 23:00:47 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.908 | Acc: 77.349% (28217/36480)/ 93.498% (34108/36480)
01/13/2023 23:00:50 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.911 | Acc: 77.306% (28300/36608)/ 93.455% (34212/36608)
01/13/2023 23:00:52 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.912 | Acc: 77.273% (28387/36736)/ 93.442% (34327/36736)
01/13/2023 23:00:55 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.912 | Acc: 77.273% (28486/36864)/ 93.435% (34444/36864)
01/13/2023 23:00:58 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.911 | Acc: 77.295% (28593/36992)/ 93.439% (34565/36992)
01/13/2023 23:01:00 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.913 | Acc: 77.255% (28677/37120)/ 93.408% (34673/37120)
01/13/2023 23:01:03 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.915 | Acc: 77.177% (28747/37248)/ 93.412% (34794/37248)
01/13/2023 23:01:05 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.915 | Acc: 77.194% (28852/37376)/ 93.405% (34911/37376)
01/13/2023 23:01:08 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.916 | Acc: 77.138% (28930/37504)/ 93.390% (35025/37504)
01/13/2023 23:01:11 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.917 | Acc: 77.134% (29027/37632)/ 93.383% (35142/37632)
01/13/2023 23:01:13 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.918 | Acc: 77.108% (29116/37760)/ 93.382% (35261/37760)
01/13/2023 23:01:16 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.917 | Acc: 77.143% (29228/37888)/ 93.386% (35382/37888)
01/13/2023 23:01:19 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.917 | Acc: 77.144% (29327/38016)/ 93.376% (35498/38016)
01/13/2023 23:01:21 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.919 | Acc: 77.129% (29420/38144)/ 93.354% (35609/38144)
01/13/2023 23:01:24 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.921 | Acc: 77.096% (29506/38272)/ 93.327% (35718/38272)
01/13/2023 23:01:27 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.922 | Acc: 77.091% (29603/38400)/ 93.307% (35830/38400)
01/13/2023 23:01:29 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.923 | Acc: 77.097% (29704/38528)/ 93.304% (35948/38528)
01/13/2023 23:01:32 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.923 | Acc: 77.082% (29797/38656)/ 93.292% (36063/38656)
01/13/2023 23:01:35 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.925 | Acc: 77.047% (29882/38784)/ 93.276% (36176/38784)
01/13/2023 23:01:37 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.926 | Acc: 77.025% (29972/38912)/ 93.262% (36290/38912)
01/13/2023 23:01:40 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.925 | Acc: 77.039% (30076/39040)/ 93.266% (36411/39040)
01/13/2023 23:01:42 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.926 | Acc: 76.994% (30157/39168)/ 93.260% (36528/39168)
01/13/2023 23:01:45 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.927 | Acc: 76.975% (30248/39296)/ 93.238% (36639/39296)
01/13/2023 23:01:48 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.928 | Acc: 76.976% (30347/39424)/ 93.225% (36753/39424)
01/13/2023 23:01:50 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.928 | Acc: 76.957% (30438/39552)/ 93.224% (36872/39552)
01/13/2023 23:01:53 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.929 | Acc: 76.953% (30535/39680)/ 93.206% (36984/39680)
01/13/2023 23:01:56 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.930 | Acc: 76.947% (30631/39808)/ 93.192% (37098/39808)
01/13/2023 23:01:58 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.931 | Acc: 76.923% (30720/39936)/ 93.182% (37213/39936)
01/13/2023 23:02:01 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.933 | Acc: 76.907% (30812/40064)/ 93.158% (37323/40064)
01/13/2023 23:02:03 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.931 | Acc: 76.948% (30927/40192)/ 93.178% (37450/40192)
01/13/2023 23:02:06 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.931 | Acc: 76.935% (31020/40320)/ 93.175% (37568/40320)
01/13/2023 23:02:08 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.932 | Acc: 76.914% (31110/40448)/ 93.159% (37681/40448)
01/13/2023 23:02:11 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.935 | Acc: 76.819% (31170/40576)/ 93.134% (37790/40576)
01/13/2023 23:02:14 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.937 | Acc: 76.779% (31252/40704)/ 93.104% (37897/40704)
01/13/2023 23:02:16 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.936 | Acc: 76.810% (31363/40832)/ 93.121% (38023/40832)
01/13/2023 23:02:19 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.938 | Acc: 76.755% (31439/40960)/ 93.088% (38129/40960)
01/13/2023 23:02:21 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.937 | Acc: 76.794% (31553/41088)/ 93.098% (38252/41088)
01/13/2023 23:02:24 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.937 | Acc: 76.812% (31659/41216)/ 93.092% (38369/41216)
01/13/2023 23:02:26 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.938 | Acc: 76.790% (31748/41344)/ 93.087% (38486/41344)
01/13/2023 23:02:29 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.940 | Acc: 76.755% (31832/41472)/ 93.063% (38595/41472)
01/13/2023 23:02:32 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.941 | Acc: 76.750% (31928/41600)/ 93.058% (38712/41600)
01/13/2023 23:02:34 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.940 | Acc: 76.759% (32030/41728)/ 93.053% (38829/41728)
01/13/2023 23:02:37 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.944 | Acc: 76.677% (32094/41856)/ 93.021% (38935/41856)
01/13/2023 23:02:40 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.947 | Acc: 76.598% (32159/41984)/ 92.990% (39041/41984)
01/13/2023 23:02:42 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.949 | Acc: 76.548% (32236/42112)/ 92.966% (39150/42112)
01/13/2023 23:02:45 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.949 | Acc: 76.539% (32330/42240)/ 92.966% (39269/42240)
01/13/2023 23:02:47 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.951 | Acc: 76.499% (32411/42368)/ 92.938% (39376/42368)
01/13/2023 23:02:50 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.951 | Acc: 76.464% (32494/42496)/ 92.950% (39500/42496)
01/13/2023 23:02:53 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.951 | Acc: 76.448% (32585/42624)/ 92.948% (39618/42624)
01/13/2023 23:02:55 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.950 | Acc: 76.476% (32695/42752)/ 92.957% (39741/42752)
01/13/2023 23:02:58 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.951 | Acc: 76.446% (32780/42880)/ 92.938% (39852/42880)
01/13/2023 23:03:00 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.952 | Acc: 76.423% (32868/43008)/ 92.927% (39966/43008)
01/13/2023 23:03:03 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.954 | Acc: 76.379% (32947/43136)/ 92.913% (40079/43136)
01/13/2023 23:03:06 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.954 | Acc: 76.371% (33041/43264)/ 92.911% (40197/43264)
01/13/2023 23:03:08 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.954 | Acc: 76.362% (33135/43392)/ 92.923% (40321/43392)
01/13/2023 23:03:11 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.957 | Acc: 76.330% (33219/43520)/ 92.895% (40428/43520)
01/13/2023 23:03:13 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.956 | Acc: 76.327% (33315/43648)/ 92.905% (40551/43648)
01/13/2023 23:03:16 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.955 | Acc: 76.364% (33429/43776)/ 92.923% (40678/43776)
01/13/2023 23:03:19 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.955 | Acc: 76.310% (33503/43904)/ 92.916% (40794/43904)
01/13/2023 23:03:21 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.955 | Acc: 76.310% (33601/44032)/ 92.919% (40914/44032)
01/13/2023 23:03:24 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.956 | Acc: 76.307% (33697/44160)/ 92.908% (41028/44160)
01/13/2023 23:03:26 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.959 | Acc: 76.242% (33766/44288)/ 92.874% (41132/44288)
01/13/2023 23:03:29 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.961 | Acc: 76.229% (33858/44416)/ 92.867% (41248/44416)
01/13/2023 23:03:31 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.960 | Acc: 76.241% (33961/44544)/ 92.874% (41370/44544)
01/13/2023 23:03:34 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.962 | Acc: 76.216% (34047/44672)/ 92.855% (41480/44672)
01/13/2023 23:03:37 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.961 | Acc: 76.214% (34144/44800)/ 92.864% (41603/44800)
01/13/2023 23:03:39 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.961 | Acc: 76.222% (34245/44928)/ 92.862% (41721/44928)
01/13/2023 23:03:42 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.963 | Acc: 76.167% (34318/45056)/ 92.847% (41833/45056)
01/13/2023 23:03:45 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.963 | Acc: 76.166% (34415/45184)/ 92.845% (41951/45184)
01/13/2023 23:03:47 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.966 | Acc: 76.126% (34494/45312)/ 92.808% (42053/45312)
01/13/2023 23:03:50 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.968 | Acc: 76.067% (34565/45440)/ 92.784% (42161/45440)
01/13/2023 23:03:52 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.971 | Acc: 76.001% (34632/45568)/ 92.778% (42277/45568)
01/13/2023 23:03:55 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.971 | Acc: 75.996% (34727/45696)/ 92.781% (42397/45696)
01/13/2023 23:03:58 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.970 | Acc: 76.030% (34840/45824)/ 92.794% (42522/45824)
01/13/2023 23:04:00 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.969 | Acc: 76.055% (34949/45952)/ 92.797% (42642/45952)
01/13/2023 23:04:03 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.969 | Acc: 76.063% (35050/46080)/ 92.793% (42759/46080)
01/13/2023 23:04:06 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.971 | Acc: 76.034% (35134/46208)/ 92.785% (42874/46208)
01/13/2023 23:04:08 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.971 | Acc: 76.034% (35231/46336)/ 92.792% (42996/46336)
01/13/2023 23:04:11 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.971 | Acc: 76.029% (35326/46464)/ 92.805% (43121/46464)
01/13/2023 23:04:13 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.971 | Acc: 76.022% (35420/46592)/ 92.797% (43236/46592)
01/13/2023 23:04:16 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.970 | Acc: 76.049% (35530/46720)/ 92.806% (43359/46720)
01/13/2023 23:04:19 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.969 | Acc: 76.063% (35634/46848)/ 92.811% (43480/46848)
01/13/2023 23:04:21 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.968 | Acc: 76.098% (35748/46976)/ 92.828% (43607/46976)
01/13/2023 23:04:24 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.967 | Acc: 76.119% (35855/47104)/ 92.841% (43732/47104)
01/13/2023 23:04:27 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.966 | Acc: 76.122% (35954/47232)/ 92.850% (43855/47232)
01/13/2023 23:04:29 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.965 | Acc: 76.144% (36062/47360)/ 92.859% (43978/47360)
01/13/2023 23:04:32 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.966 | Acc: 76.131% (36153/47488)/ 92.859% (44097/47488)
01/13/2023 23:04:35 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.965 | Acc: 76.132% (36251/47616)/ 92.862% (44217/47616)
01/13/2023 23:04:37 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.964 | Acc: 76.177% (36370/47744)/ 92.874% (44342/47744)
01/13/2023 23:04:40 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.962 | Acc: 76.209% (36483/47872)/ 92.881% (44464/47872)
01/13/2023 23:04:42 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.961 | Acc: 76.240% (36595/48000)/ 92.885% (44585/48000)
01/13/2023 23:04:45 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.964 | Acc: 76.172% (36660/48128)/ 92.850% (44687/48128)
01/13/2023 23:04:47 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.965 | Acc: 76.169% (36756/48256)/ 92.836% (44799/48256)
01/13/2023 23:04:50 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.965 | Acc: 76.155% (36847/48384)/ 92.830% (44915/48384)
01/13/2023 23:04:53 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.968 | Acc: 76.080% (36908/48512)/ 92.794% (45016/48512)
01/13/2023 23:04:55 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.969 | Acc: 76.065% (36998/48640)/ 92.800% (45138/48640)
01/13/2023 23:04:58 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.968 | Acc: 76.062% (37094/48768)/ 92.809% (45261/48768)
01/13/2023 23:05:00 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.970 | Acc: 76.018% (37170/48896)/ 92.809% (45380/48896)
01/13/2023 23:05:03 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.971 | Acc: 75.983% (37250/49024)/ 92.795% (45492/49024)
01/13/2023 23:05:06 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.972 | Acc: 75.995% (37353/49152)/ 92.796% (45611/49152)
01/13/2023 23:05:08 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.970 | Acc: 76.035% (37470/49280)/ 92.808% (45736/49280)
01/13/2023 23:05:11 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.969 | Acc: 76.044% (37572/49408)/ 92.817% (45859/49408)
01/13/2023 23:05:13 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.967 | Acc: 76.092% (37693/49536)/ 92.833% (45986/49536)
01/13/2023 23:05:16 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.965 | Acc: 76.132% (37810/49664)/ 92.844% (46110/49664)
01/13/2023 23:05:18 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.963 | Acc: 76.177% (37930/49792)/ 92.856% (46235/49792)
01/13/2023 23:05:21 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.963 | Acc: 76.180% (38029/49920)/ 92.861% (46356/49920)
01/13/2023 23:05:24 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.965 | Acc: 76.136% (38068/50000)/ 92.850% (46425/50000)
01/13/2023 23:05:24 - INFO - __main__ -   Final accuracy: 76.136
01/13/2023 23:05:24 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 1, '_step_count': 2, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00025]}
01/13/2023 23:05:24 - INFO - __main__ -   
Epoch: 1
01/13/2023 23:05:26 - INFO - __main__ -   test: [epoch: 1 | batch: 0/10010 ] | Loss: 0.630 | Acc: 86.719% (111/128)
01/13/2023 23:09:49 - INFO - __main__ -   test: [epoch: 1 | batch: 100/10010 ] | Loss: 0.826 | Acc: 79.595% (10290/12928)
01/13/2023 23:14:13 - INFO - __main__ -   test: [epoch: 1 | batch: 200/10010 ] | Loss: 0.825 | Acc: 79.474% (20447/25728)
01/13/2023 23:18:35 - INFO - __main__ -   test: [epoch: 1 | batch: 300/10010 ] | Loss: 0.839 | Acc: 79.140% (30491/38528)
01/13/2023 23:22:56 - INFO - __main__ -   test: [epoch: 1 | batch: 400/10010 ] | Loss: 0.852 | Acc: 78.902% (40499/51328)
01/13/2023 23:27:17 - INFO - __main__ -   test: [epoch: 1 | batch: 500/10010 ] | Loss: 0.852 | Acc: 78.869% (50577/64128)
01/13/2023 23:31:37 - INFO - __main__ -   test: [epoch: 1 | batch: 600/10010 ] | Loss: 0.855 | Acc: 78.796% (60616/76928)
01/13/2023 23:35:55 - INFO - __main__ -   test: [epoch: 1 | batch: 700/10010 ] | Loss: 0.855 | Acc: 78.785% (70692/89728)
01/13/2023 23:40:15 - INFO - __main__ -   test: [epoch: 1 | batch: 800/10010 ] | Loss: 0.854 | Acc: 78.762% (80753/102528)
01/13/2023 23:44:35 - INFO - __main__ -   test: [epoch: 1 | batch: 900/10010 ] | Loss: 0.854 | Acc: 78.730% (90798/115328)
01/13/2023 23:48:56 - INFO - __main__ -   test: [epoch: 1 | batch: 1000/10010 ] | Loss: 0.855 | Acc: 78.710% (100849/128128)
01/13/2023 23:53:16 - INFO - __main__ -   test: [epoch: 1 | batch: 1100/10010 ] | Loss: 0.857 | Acc: 78.656% (110848/140928)
01/13/2023 23:57:36 - INFO - __main__ -   test: [epoch: 1 | batch: 1200/10010 ] | Loss: 0.857 | Acc: 78.679% (120952/153728)
01/14/2023 00:01:57 - INFO - __main__ -   test: [epoch: 1 | batch: 1300/10010 ] | Loss: 0.854 | Acc: 78.746% (131134/166528)
01/14/2023 00:06:17 - INFO - __main__ -   test: [epoch: 1 | batch: 1400/10010 ] | Loss: 0.854 | Acc: 78.754% (141228/179328)
01/14/2023 00:10:39 - INFO - __main__ -   test: [epoch: 1 | batch: 1500/10010 ] | Loss: 0.854 | Acc: 78.751% (151303/192128)
01/14/2023 00:14:59 - INFO - __main__ -   test: [epoch: 1 | batch: 1600/10010 ] | Loss: 0.856 | Acc: 78.705% (161289/204928)
01/14/2023 00:19:20 - INFO - __main__ -   test: [epoch: 1 | batch: 1700/10010 ] | Loss: 0.856 | Acc: 78.709% (171372/217728)
01/14/2023 00:23:39 - INFO - __main__ -   test: [epoch: 1 | batch: 1800/10010 ] | Loss: 0.856 | Acc: 78.721% (181475/230528)
01/14/2023 00:27:59 - INFO - __main__ -   test: [epoch: 1 | batch: 1900/10010 ] | Loss: 0.854 | Acc: 78.757% (191638/243328)
01/14/2023 00:32:20 - INFO - __main__ -   test: [epoch: 1 | batch: 2000/10010 ] | Loss: 0.854 | Acc: 78.759% (201723/256128)
01/14/2023 00:36:40 - INFO - __main__ -   test: [epoch: 1 | batch: 2100/10010 ] | Loss: 0.853 | Acc: 78.753% (211789/268928)
01/14/2023 00:41:00 - INFO - __main__ -   test: [epoch: 1 | batch: 2200/10010 ] | Loss: 0.855 | Acc: 78.720% (221777/281728)
01/14/2023 00:45:21 - INFO - __main__ -   test: [epoch: 1 | batch: 2300/10010 ] | Loss: 0.855 | Acc: 78.709% (231819/294528)
01/14/2023 00:49:43 - INFO - __main__ -   test: [epoch: 1 | batch: 2400/10010 ] | Loss: 0.855 | Acc: 78.734% (241972/307328)
01/14/2023 00:54:03 - INFO - __main__ -   test: [epoch: 1 | batch: 2500/10010 ] | Loss: 0.856 | Acc: 78.700% (251941/320128)
01/14/2023 00:58:25 - INFO - __main__ -   test: [epoch: 1 | batch: 2600/10010 ] | Loss: 0.856 | Acc: 78.698% (262008/332928)
01/14/2023 01:02:46 - INFO - __main__ -   test: [epoch: 1 | batch: 2700/10010 ] | Loss: 0.856 | Acc: 78.698% (272082/345728)
01/14/2023 01:07:06 - INFO - __main__ -   test: [epoch: 1 | batch: 2800/10010 ] | Loss: 0.856 | Acc: 78.694% (282139/358528)
01/14/2023 01:11:27 - INFO - __main__ -   test: [epoch: 1 | batch: 2900/10010 ] | Loss: 0.857 | Acc: 78.698% (292228/371328)
01/14/2023 01:15:47 - INFO - __main__ -   test: [epoch: 1 | batch: 3000/10010 ] | Loss: 0.856 | Acc: 78.708% (302339/384128)
01/14/2023 01:20:09 - INFO - __main__ -   test: [epoch: 1 | batch: 3100/10010 ] | Loss: 0.856 | Acc: 78.702% (312390/396928)
01/14/2023 01:24:30 - INFO - __main__ -   test: [epoch: 1 | batch: 3200/10010 ] | Loss: 0.856 | Acc: 78.682% (322384/409728)
01/14/2023 01:28:50 - INFO - __main__ -   test: [epoch: 1 | batch: 3300/10010 ] | Loss: 0.857 | Acc: 78.670% (332402/422528)
01/14/2023 01:33:10 - INFO - __main__ -   test: [epoch: 1 | batch: 3400/10010 ] | Loss: 0.857 | Acc: 78.683% (342527/435328)
01/14/2023 01:37:30 - INFO - __main__ -   test: [epoch: 1 | batch: 3500/10010 ] | Loss: 0.857 | Acc: 78.679% (352582/448128)
01/14/2023 01:41:51 - INFO - __main__ -   test: [epoch: 1 | batch: 3600/10010 ] | Loss: 0.857 | Acc: 78.676% (362638/460928)
01/14/2023 01:46:11 - INFO - __main__ -   test: [epoch: 1 | batch: 3700/10010 ] | Loss: 0.858 | Acc: 78.662% (372646/473728)
01/14/2023 01:50:31 - INFO - __main__ -   test: [epoch: 1 | batch: 3800/10010 ] | Loss: 0.858 | Acc: 78.659% (382700/486528)
01/14/2023 01:54:51 - INFO - __main__ -   test: [epoch: 1 | batch: 3900/10010 ] | Loss: 0.857 | Acc: 78.674% (392840/499328)
01/14/2023 01:59:11 - INFO - __main__ -   test: [epoch: 1 | batch: 4000/10010 ] | Loss: 0.858 | Acc: 78.668% (402881/512128)
01/14/2023 02:03:32 - INFO - __main__ -   test: [epoch: 1 | batch: 4100/10010 ] | Loss: 0.857 | Acc: 78.677% (412997/524928)
01/14/2023 02:07:54 - INFO - __main__ -   test: [epoch: 1 | batch: 4200/10010 ] | Loss: 0.857 | Acc: 78.669% (423024/537728)
01/14/2023 02:12:13 - INFO - __main__ -   test: [epoch: 1 | batch: 4300/10010 ] | Loss: 0.857 | Acc: 78.674% (433121/550528)
01/14/2023 02:16:36 - INFO - __main__ -   test: [epoch: 1 | batch: 4400/10010 ] | Loss: 0.857 | Acc: 78.679% (443222/563328)
01/14/2023 02:20:57 - INFO - __main__ -   test: [epoch: 1 | batch: 4500/10010 ] | Loss: 0.857 | Acc: 78.674% (453263/576128)
01/14/2023 02:25:17 - INFO - __main__ -   test: [epoch: 1 | batch: 4600/10010 ] | Loss: 0.857 | Acc: 78.672% (463322/588928)
01/14/2023 02:29:39 - INFO - __main__ -   test: [epoch: 1 | batch: 4700/10010 ] | Loss: 0.857 | Acc: 78.686% (473474/601728)
01/14/2023 02:33:59 - INFO - __main__ -   test: [epoch: 1 | batch: 4800/10010 ] | Loss: 0.856 | Acc: 78.692% (483584/614528)
01/14/2023 02:38:19 - INFO - __main__ -   test: [epoch: 1 | batch: 4900/10010 ] | Loss: 0.856 | Acc: 78.684% (493608/627328)
01/14/2023 02:42:39 - INFO - __main__ -   test: [epoch: 1 | batch: 5000/10010 ] | Loss: 0.856 | Acc: 78.700% (503779/640128)
01/14/2023 02:46:59 - INFO - __main__ -   test: [epoch: 1 | batch: 5100/10010 ] | Loss: 0.856 | Acc: 78.699% (513845/652928)
01/14/2023 02:51:20 - INFO - __main__ -   test: [epoch: 1 | batch: 5200/10010 ] | Loss: 0.856 | Acc: 78.689% (523852/665728)
01/14/2023 02:55:41 - INFO - __main__ -   test: [epoch: 1 | batch: 5300/10010 ] | Loss: 0.856 | Acc: 78.684% (533890/678528)
01/14/2023 03:00:01 - INFO - __main__ -   test: [epoch: 1 | batch: 5400/10010 ] | Loss: 0.856 | Acc: 78.681% (543942/691328)
01/14/2023 03:04:22 - INFO - __main__ -   test: [epoch: 1 | batch: 5500/10010 ] | Loss: 0.856 | Acc: 78.673% (553961/704128)
01/14/2023 03:08:42 - INFO - __main__ -   test: [epoch: 1 | batch: 5600/10010 ] | Loss: 0.856 | Acc: 78.687% (564126/716928)
01/14/2023 03:13:04 - INFO - __main__ -   test: [epoch: 1 | batch: 5700/10010 ] | Loss: 0.856 | Acc: 78.695% (574256/729728)
01/14/2023 03:17:25 - INFO - __main__ -   test: [epoch: 1 | batch: 5800/10010 ] | Loss: 0.856 | Acc: 78.704% (584398/742528)
01/14/2023 03:21:45 - INFO - __main__ -   test: [epoch: 1 | batch: 5900/10010 ] | Loss: 0.856 | Acc: 78.702% (594462/755328)
01/14/2023 03:26:07 - INFO - __main__ -   test: [epoch: 1 | batch: 6000/10010 ] | Loss: 0.856 | Acc: 78.706% (604563/768128)
01/14/2023 03:30:28 - INFO - __main__ -   test: [epoch: 1 | batch: 6100/10010 ] | Loss: 0.856 | Acc: 78.695% (614548/780928)
01/14/2023 03:34:48 - INFO - __main__ -   test: [epoch: 1 | batch: 6200/10010 ] | Loss: 0.856 | Acc: 78.696% (624632/793728)
01/14/2023 03:39:11 - INFO - __main__ -   test: [epoch: 1 | batch: 6300/10010 ] | Loss: 0.856 | Acc: 78.694% (634689/806528)
01/14/2023 03:43:33 - INFO - __main__ -   test: [epoch: 1 | batch: 6400/10010 ] | Loss: 0.856 | Acc: 78.682% (644662/819328)
01/14/2023 03:47:53 - INFO - __main__ -   test: [epoch: 1 | batch: 6500/10010 ] | Loss: 0.856 | Acc: 78.681% (654728/832128)
01/14/2023 03:52:15 - INFO - __main__ -   test: [epoch: 1 | batch: 6600/10010 ] | Loss: 0.856 | Acc: 78.687% (664846/844928)
01/14/2023 03:56:34 - INFO - __main__ -   test: [epoch: 1 | batch: 6700/10010 ] | Loss: 0.856 | Acc: 78.680% (674863/857728)
01/14/2023 04:00:54 - INFO - __main__ -   test: [epoch: 1 | batch: 6800/10010 ] | Loss: 0.856 | Acc: 78.672% (684865/870528)
01/14/2023 04:05:15 - INFO - __main__ -   test: [epoch: 1 | batch: 6900/10010 ] | Loss: 0.856 | Acc: 78.676% (694967/883328)
01/14/2023 04:09:35 - INFO - __main__ -   test: [epoch: 1 | batch: 7000/10010 ] | Loss: 0.856 | Acc: 78.673% (705014/896128)
01/14/2023 04:13:56 - INFO - __main__ -   test: [epoch: 1 | batch: 7100/10010 ] | Loss: 0.856 | Acc: 78.680% (715146/908928)
01/14/2023 04:18:16 - INFO - __main__ -   test: [epoch: 1 | batch: 7200/10010 ] | Loss: 0.856 | Acc: 78.680% (725216/921728)
01/14/2023 04:22:36 - INFO - __main__ -   test: [epoch: 1 | batch: 7300/10010 ] | Loss: 0.856 | Acc: 78.678% (735272/934528)
01/14/2023 04:26:56 - INFO - __main__ -   test: [epoch: 1 | batch: 7400/10010 ] | Loss: 0.856 | Acc: 78.671% (745273/947328)
01/14/2023 04:31:18 - INFO - __main__ -   test: [epoch: 1 | batch: 7500/10010 ] | Loss: 0.856 | Acc: 78.672% (755351/960128)
01/14/2023 04:35:38 - INFO - __main__ -   test: [epoch: 1 | batch: 7600/10010 ] | Loss: 0.856 | Acc: 78.670% (765402/972928)
01/14/2023 04:39:58 - INFO - __main__ -   test: [epoch: 1 | batch: 7700/10010 ] | Loss: 0.856 | Acc: 78.668% (775457/985728)
01/14/2023 04:44:18 - INFO - __main__ -   test: [epoch: 1 | batch: 7800/10010 ] | Loss: 0.857 | Acc: 78.656% (785403/998528)
01/14/2023 04:48:39 - INFO - __main__ -   test: [epoch: 1 | batch: 7900/10010 ] | Loss: 0.857 | Acc: 78.660% (795510/1011328)
01/14/2023 04:53:00 - INFO - __main__ -   test: [epoch: 1 | batch: 8000/10010 ] | Loss: 0.857 | Acc: 78.663% (805609/1024128)
01/14/2023 04:57:19 - INFO - __main__ -   test: [epoch: 1 | batch: 8100/10010 ] | Loss: 0.856 | Acc: 78.673% (815785/1036928)
01/14/2023 05:01:40 - INFO - __main__ -   test: [epoch: 1 | batch: 8200/10010 ] | Loss: 0.856 | Acc: 78.670% (825822/1049728)
01/14/2023 05:06:00 - INFO - __main__ -   test: [epoch: 1 | batch: 8300/10010 ] | Loss: 0.857 | Acc: 78.667% (835856/1062528)
01/14/2023 05:10:21 - INFO - __main__ -   test: [epoch: 1 | batch: 8400/10010 ] | Loss: 0.856 | Acc: 78.666% (845915/1075328)
01/14/2023 05:14:42 - INFO - __main__ -   test: [epoch: 1 | batch: 8500/10010 ] | Loss: 0.856 | Acc: 78.669% (856020/1088128)
01/14/2023 05:19:01 - INFO - __main__ -   test: [epoch: 1 | batch: 8600/10010 ] | Loss: 0.856 | Acc: 78.667% (866069/1100928)
01/14/2023 05:23:21 - INFO - __main__ -   test: [epoch: 1 | batch: 8700/10010 ] | Loss: 0.856 | Acc: 78.673% (876208/1113728)
01/14/2023 05:27:41 - INFO - __main__ -   test: [epoch: 1 | batch: 8800/10010 ] | Loss: 0.856 | Acc: 78.679% (886338/1126528)
01/14/2023 05:32:01 - INFO - __main__ -   test: [epoch: 1 | batch: 8900/10010 ] | Loss: 0.856 | Acc: 78.682% (896450/1139328)
01/14/2023 05:36:19 - INFO - __main__ -   test: [epoch: 1 | batch: 9000/10010 ] | Loss: 0.856 | Acc: 78.684% (906544/1152128)
01/14/2023 05:40:40 - INFO - __main__ -   test: [epoch: 1 | batch: 9100/10010 ] | Loss: 0.856 | Acc: 78.685% (916618/1164928)
01/14/2023 05:45:02 - INFO - __main__ -   test: [epoch: 1 | batch: 9200/10010 ] | Loss: 0.856 | Acc: 78.686% (926710/1177728)
01/14/2023 05:49:23 - INFO - __main__ -   test: [epoch: 1 | batch: 9300/10010 ] | Loss: 0.856 | Acc: 78.693% (936857/1190528)
01/14/2023 05:53:44 - INFO - __main__ -   test: [epoch: 1 | batch: 9400/10010 ] | Loss: 0.856 | Acc: 78.689% (946883/1203328)
01/14/2023 05:58:06 - INFO - __main__ -   test: [epoch: 1 | batch: 9500/10010 ] | Loss: 0.856 | Acc: 78.691% (956987/1216128)
01/14/2023 06:02:29 - INFO - __main__ -   test: [epoch: 1 | batch: 9600/10010 ] | Loss: 0.856 | Acc: 78.690% (967040/1228928)
01/14/2023 06:06:52 - INFO - __main__ -   test: [epoch: 1 | batch: 9700/10010 ] | Loss: 0.856 | Acc: 78.691% (977133/1241728)
01/14/2023 06:11:24 - INFO - __main__ -   test: [epoch: 1 | batch: 9800/10010 ] | Loss: 0.856 | Acc: 78.690% (987183/1254528)
01/14/2023 06:15:47 - INFO - __main__ -   test: [epoch: 1 | batch: 9900/10010 ] | Loss: 0.856 | Acc: 78.691% (997269/1267328)
01/14/2023 06:20:09 - INFO - __main__ -   test: [epoch: 1 | batch: 10000/10010 ] | Loss: 0.856 | Acc: 78.689% (1007315/1280128)
01/14/2023 06:20:33 - INFO - __main__ -   Saving Checkpoint
01/14/2023 06:20:36 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.444 | Acc: 86.719% (111/128)/ 97.656% (125/128)
01/14/2023 06:20:38 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.456 | Acc: 86.328% (221/256)/ 98.047% (251/256)
01/14/2023 06:20:41 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.610 | Acc: 82.812% (318/384)/ 96.094% (369/384)
01/14/2023 06:20:44 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.566 | Acc: 84.570% (433/512)/ 96.680% (495/512)
01/14/2023 06:20:46 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.484 | Acc: 86.875% (556/640)/ 97.344% (623/640)
01/14/2023 06:20:49 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.428 | Acc: 88.151% (677/768)/ 97.786% (751/768)
01/14/2023 06:20:51 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.423 | Acc: 88.281% (791/896)/ 97.656% (875/896)
01/14/2023 06:20:54 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.405 | Acc: 89.258% (914/1024)/ 97.754% (1001/1024)
01/14/2023 06:20:57 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.423 | Acc: 89.323% (1029/1152)/ 97.656% (1125/1152)
01/14/2023 06:20:59 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.402 | Acc: 89.844% (1150/1280)/ 97.734% (1251/1280)
01/14/2023 06:21:02 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.451 | Acc: 88.565% (1247/1408)/ 97.727% (1376/1408)
01/14/2023 06:21:05 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.455 | Acc: 88.737% (1363/1536)/ 97.591% (1499/1536)
01/14/2023 06:21:07 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.504 | Acc: 87.680% (1459/1664)/ 97.236% (1618/1664)
01/14/2023 06:21:10 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.555 | Acc: 86.049% (1542/1792)/ 96.708% (1733/1792)
01/14/2023 06:21:13 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.575 | Acc: 85.156% (1635/1920)/ 96.771% (1858/1920)
01/14/2023 06:21:15 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.583 | Acc: 84.717% (1735/2048)/ 96.875% (1984/2048)
01/14/2023 06:21:18 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.593 | Acc: 84.605% (1841/2176)/ 96.645% (2103/2176)
01/14/2023 06:21:20 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.621 | Acc: 84.245% (1941/2304)/ 96.181% (2216/2304)
01/14/2023 06:21:23 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.642 | Acc: 83.717% (2036/2432)/ 96.053% (2336/2432)
01/14/2023 06:21:25 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.652 | Acc: 83.438% (2136/2560)/ 95.977% (2457/2560)
01/14/2023 06:21:28 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.649 | Acc: 83.519% (2245/2688)/ 95.908% (2578/2688)
01/14/2023 06:21:31 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.681 | Acc: 82.812% (2332/2816)/ 95.739% (2696/2816)
01/14/2023 06:21:33 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.679 | Acc: 82.711% (2435/2944)/ 95.754% (2819/2944)
01/14/2023 06:21:36 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.724 | Acc: 81.836% (2514/3072)/ 95.475% (2933/3072)
01/14/2023 06:21:39 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.743 | Acc: 81.344% (2603/3200)/ 95.281% (3049/3200)
01/14/2023 06:21:41 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.767 | Acc: 80.739% (2687/3328)/ 95.042% (3163/3328)
01/14/2023 06:21:44 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.782 | Acc: 80.006% (2765/3456)/ 95.023% (3284/3456)
01/14/2023 06:21:46 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.764 | Acc: 80.525% (2886/3584)/ 95.061% (3407/3584)
01/14/2023 06:21:49 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.773 | Acc: 79.957% (2968/3712)/ 95.124% (3531/3712)
01/14/2023 06:21:51 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.766 | Acc: 80.104% (3076/3840)/ 95.234% (3657/3840)
01/14/2023 06:21:54 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.780 | Acc: 80.091% (3178/3968)/ 95.111% (3774/3968)
01/14/2023 06:21:57 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.776 | Acc: 80.273% (3288/4096)/ 95.190% (3899/4096)
01/14/2023 06:21:59 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.761 | Acc: 80.563% (3403/4224)/ 95.289% (4025/4224)
01/14/2023 06:22:02 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.755 | Acc: 80.722% (3513/4352)/ 95.335% (4149/4352)
01/14/2023 06:22:04 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.741 | Acc: 81.094% (3633/4480)/ 95.379% (4273/4480)
01/14/2023 06:22:07 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.728 | Acc: 81.445% (3753/4608)/ 95.399% (4396/4608)
01/14/2023 06:22:10 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.713 | Acc: 81.883% (3878/4736)/ 95.503% (4523/4736)
01/14/2023 06:22:12 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.704 | Acc: 82.175% (3997/4864)/ 95.559% (4648/4864)
01/14/2023 06:22:15 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.696 | Acc: 82.372% (4112/4992)/ 95.633% (4774/4992)
01/14/2023 06:22:17 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.691 | Acc: 82.402% (4219/5120)/ 95.664% (4898/5120)
01/14/2023 06:22:20 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.690 | Acc: 82.527% (4331/5248)/ 95.560% (5015/5248)
01/14/2023 06:22:23 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.693 | Acc: 82.571% (4439/5376)/ 95.499% (5134/5376)
01/14/2023 06:22:25 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.693 | Acc: 82.558% (4544/5504)/ 95.531% (5258/5504)
01/14/2023 06:22:28 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.690 | Acc: 82.635% (4654/5632)/ 95.490% (5378/5632)
01/14/2023 06:22:31 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.693 | Acc: 82.656% (4761/5760)/ 95.417% (5496/5760)
01/14/2023 06:22:33 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.690 | Acc: 82.829% (4877/5888)/ 95.414% (5618/5888)
01/14/2023 06:22:36 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.693 | Acc: 82.812% (4982/6016)/ 95.445% (5742/6016)
01/14/2023 06:22:39 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.695 | Acc: 82.731% (5083/6144)/ 95.508% (5868/6144)
01/14/2023 06:22:41 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.700 | Acc: 82.573% (5179/6272)/ 95.488% (5989/6272)
01/14/2023 06:22:43 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.703 | Acc: 82.625% (5288/6400)/ 95.406% (6106/6400)
01/14/2023 06:22:46 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.694 | Acc: 82.812% (5406/6528)/ 95.450% (6231/6528)
01/14/2023 06:22:49 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.687 | Acc: 82.993% (5524/6656)/ 95.538% (6359/6656)
01/14/2023 06:22:51 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.683 | Acc: 83.078% (5636/6784)/ 95.563% (6483/6784)
01/14/2023 06:22:54 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.674 | Acc: 83.275% (5756/6912)/ 95.631% (6610/6912)
01/14/2023 06:22:57 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.667 | Acc: 83.409% (5872/7040)/ 95.682% (6736/7040)
01/14/2023 06:22:59 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.661 | Acc: 83.552% (5989/7168)/ 95.717% (6861/7168)
01/14/2023 06:23:02 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.652 | Acc: 83.758% (6111/7296)/ 95.779% (6988/7296)
01/14/2023 06:23:04 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.645 | Acc: 83.944% (6232/7424)/ 95.824% (7114/7424)
01/14/2023 06:23:07 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.643 | Acc: 84.004% (6344/7552)/ 95.802% (7235/7552)
01/14/2023 06:23:09 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.646 | Acc: 83.932% (6446/7680)/ 95.820% (7359/7680)
01/14/2023 06:23:12 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.650 | Acc: 83.837% (6546/7808)/ 95.786% (7479/7808)
01/14/2023 06:23:15 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.651 | Acc: 83.833% (6653/7936)/ 95.779% (7601/7936)
01/14/2023 06:23:17 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.650 | Acc: 83.792% (6757/8064)/ 95.809% (7726/8064)
01/14/2023 06:23:20 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.658 | Acc: 83.655% (6853/8192)/ 95.752% (7844/8192)
01/14/2023 06:23:22 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.666 | Acc: 83.474% (6945/8320)/ 95.709% (7963/8320)
01/14/2023 06:23:25 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.679 | Acc: 82.966% (7009/8448)/ 95.632% (8079/8448)
01/14/2023 06:23:27 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.684 | Acc: 82.976% (7116/8576)/ 95.592% (8198/8576)
01/14/2023 06:23:30 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.687 | Acc: 82.904% (7216/8704)/ 95.600% (8321/8704)
01/14/2023 06:23:32 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.687 | Acc: 82.869% (7319/8832)/ 95.618% (8445/8832)
01/14/2023 06:23:35 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.683 | Acc: 82.969% (7434/8960)/ 95.647% (8570/8960)
01/14/2023 06:23:38 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.684 | Acc: 82.901% (7534/9088)/ 95.643% (8692/9088)
01/14/2023 06:23:40 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.683 | Acc: 82.943% (7644/9216)/ 95.649% (8815/9216)
01/14/2023 06:23:43 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.685 | Acc: 82.823% (7739/9344)/ 95.666% (8939/9344)
01/14/2023 06:23:45 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.689 | Acc: 82.696% (7833/9472)/ 95.671% (9062/9472)
01/14/2023 06:23:48 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.689 | Acc: 82.656% (7935/9600)/ 95.656% (9183/9600)
01/14/2023 06:23:51 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.695 | Acc: 82.494% (8025/9728)/ 95.631% (9303/9728)
01/14/2023 06:23:53 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.695 | Acc: 82.468% (8128/9856)/ 95.637% (9426/9856)
01/14/2023 06:23:56 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.695 | Acc: 82.422% (8229/9984)/ 95.663% (9551/9984)
01/14/2023 06:23:58 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.695 | Acc: 82.318% (8324/10112)/ 95.708% (9678/10112)
01/14/2023 06:24:01 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.694 | Acc: 82.324% (8430/10240)/ 95.732% (9803/10240)
01/14/2023 06:24:04 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.693 | Acc: 82.311% (8534/10368)/ 95.737% (9926/10368)
01/14/2023 06:24:06 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.692 | Acc: 82.327% (8641/10496)/ 95.760% (10051/10496)
01/14/2023 06:24:09 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.691 | Acc: 82.332% (8747/10624)/ 95.755% (10173/10624)
01/14/2023 06:24:11 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.691 | Acc: 82.366% (8856/10752)/ 95.740% (10294/10752)
01/14/2023 06:24:14 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.687 | Acc: 82.482% (8974/10880)/ 95.772% (10420/10880)
01/14/2023 06:24:17 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.686 | Acc: 82.485% (9080/11008)/ 95.812% (10547/11008)
01/14/2023 06:24:19 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.690 | Acc: 82.399% (9176/11136)/ 95.788% (10667/11136)
01/14/2023 06:24:22 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.688 | Acc: 82.422% (9284/11264)/ 95.792% (10790/11264)
01/14/2023 06:24:25 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.695 | Acc: 82.347% (9381/11392)/ 95.725% (10905/11392)
01/14/2023 06:24:27 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.693 | Acc: 82.396% (9492/11520)/ 95.738% (11029/11520)
01/14/2023 06:24:30 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.694 | Acc: 82.315% (9588/11648)/ 95.733% (11151/11648)
01/14/2023 06:24:32 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.693 | Acc: 82.354% (9698/11776)/ 95.746% (11275/11776)
01/14/2023 06:24:35 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.694 | Acc: 82.334% (9801/11904)/ 95.716% (11394/11904)
01/14/2023 06:24:38 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.698 | Acc: 82.148% (9884/12032)/ 95.745% (11520/12032)
01/14/2023 06:24:40 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.700 | Acc: 82.023% (9974/12160)/ 95.757% (11644/12160)
01/14/2023 06:24:43 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.697 | Acc: 82.080% (10086/12288)/ 95.760% (11767/12288)
01/14/2023 06:24:45 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.701 | Acc: 81.983% (10179/12416)/ 95.772% (11891/12416)
01/14/2023 06:24:48 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.703 | Acc: 81.800% (10261/12544)/ 95.791% (12016/12544)
01/14/2023 06:24:50 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.699 | Acc: 81.913% (10380/12672)/ 95.818% (12142/12672)
01/14/2023 06:24:53 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.694 | Acc: 82.062% (10504/12800)/ 95.859% (12270/12800)
01/14/2023 06:24:56 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.693 | Acc: 82.116% (10616/12928)/ 95.877% (12395/12928)
01/14/2023 06:24:58 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.688 | Acc: 82.215% (10734/13056)/ 95.910% (12522/13056)
01/14/2023 06:25:01 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.685 | Acc: 82.342% (10856/13184)/ 95.934% (12648/13184)
01/14/2023 06:25:04 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.686 | Acc: 82.174% (10939/13312)/ 95.959% (12774/13312)
01/14/2023 06:25:06 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.686 | Acc: 82.113% (11036/13440)/ 95.952% (12896/13440)
01/14/2023 06:25:09 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.687 | Acc: 82.105% (11140/13568)/ 95.946% (13018/13568)
01/14/2023 06:25:11 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.695 | Acc: 81.980% (11228/13696)/ 95.875% (13131/13696)
01/14/2023 06:25:14 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.692 | Acc: 82.104% (11350/13824)/ 95.906% (13258/13824)
01/14/2023 06:25:16 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.695 | Acc: 81.974% (11437/13952)/ 95.915% (13382/13952)
01/14/2023 06:25:19 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.696 | Acc: 81.946% (11538/14080)/ 95.916% (13505/14080)
01/14/2023 06:25:22 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.699 | Acc: 81.764% (11617/14208)/ 95.925% (13629/14208)
01/14/2023 06:25:24 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.702 | Acc: 81.710% (11714/14336)/ 95.891% (13747/14336)
01/14/2023 06:25:27 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.702 | Acc: 81.734% (11822/14464)/ 95.907% (13872/14464)
01/14/2023 06:25:29 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.701 | Acc: 81.771% (11932/14592)/ 95.916% (13996/14592)
01/14/2023 06:25:32 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.698 | Acc: 81.861% (12050/14720)/ 95.944% (14123/14720)
01/14/2023 06:25:35 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.695 | Acc: 81.944% (12167/14848)/ 95.966% (14249/14848)
01/14/2023 06:25:37 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.698 | Acc: 81.891% (12264/14976)/ 95.927% (14366/14976)
01/14/2023 06:25:40 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.697 | Acc: 81.912% (12372/15104)/ 95.935% (14490/15104)
01/14/2023 06:25:43 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.700 | Acc: 81.795% (12459/15232)/ 95.943% (14614/15232)
01/14/2023 06:25:45 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.698 | Acc: 81.849% (12572/15360)/ 95.964% (14740/15360)
01/14/2023 06:25:48 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.697 | Acc: 81.889% (12683/15488)/ 95.971% (14864/15488)
01/14/2023 06:25:51 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.702 | Acc: 81.749% (12766/15616)/ 95.946% (14983/15616)
01/14/2023 06:25:53 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.704 | Acc: 81.695% (12862/15744)/ 95.916% (15101/15744)
01/14/2023 06:25:56 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.704 | Acc: 81.710% (12969/15872)/ 95.911% (15223/15872)
01/14/2023 06:25:59 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.703 | Acc: 81.719% (13075/16000)/ 95.925% (15348/16000)
01/14/2023 06:26:01 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.699 | Acc: 81.820% (13196/16128)/ 95.951% (15475/16128)
01/14/2023 06:26:04 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.695 | Acc: 81.921% (13317/16256)/ 95.965% (15600/16256)
01/14/2023 06:26:06 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.693 | Acc: 82.001% (13435/16384)/ 95.972% (15724/16384)
01/14/2023 06:26:09 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.694 | Acc: 81.989% (13538/16512)/ 95.942% (15842/16512)
01/14/2023 06:26:12 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.693 | Acc: 82.001% (13645/16640)/ 95.950% (15966/16640)
01/14/2023 06:26:14 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.690 | Acc: 82.097% (13766/16768)/ 95.969% (16092/16768)
01/14/2023 06:26:17 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.689 | Acc: 82.144% (13879/16896)/ 95.975% (16216/16896)
01/14/2023 06:26:19 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.687 | Acc: 82.213% (13996/17024)/ 95.988% (16341/17024)
01/14/2023 06:26:22 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.688 | Acc: 82.160% (14092/17152)/ 95.971% (16461/17152)
01/14/2023 06:26:25 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.686 | Acc: 82.188% (14202/17280)/ 95.990% (16587/17280)
01/14/2023 06:26:27 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.687 | Acc: 82.181% (14306/17408)/ 95.985% (16709/17408)
01/14/2023 06:26:30 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.685 | Acc: 82.122% (14401/17536)/ 96.008% (16836/17536)
01/14/2023 06:26:32 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.683 | Acc: 82.167% (14514/17664)/ 96.037% (16964/17664)
01/14/2023 06:26:34 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.682 | Acc: 82.172% (14620/17792)/ 96.043% (17088/17792)
01/14/2023 06:26:37 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.688 | Acc: 82.015% (14697/17920)/ 96.038% (17210/17920)
01/14/2023 06:26:39 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.690 | Acc: 81.937% (14788/18048)/ 96.033% (17332/18048)
01/14/2023 06:26:42 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.688 | Acc: 81.976% (14900/18176)/ 96.044% (17457/18176)
01/14/2023 06:26:44 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.686 | Acc: 82.059% (15020/18304)/ 96.061% (17583/18304)
01/14/2023 06:26:47 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.686 | Acc: 82.069% (15127/18432)/ 96.045% (17703/18432)
01/14/2023 06:26:49 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.689 | Acc: 82.042% (15227/18560)/ 96.018% (17821/18560)
01/14/2023 06:26:52 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.691 | Acc: 82.026% (15329/18688)/ 95.992% (17939/18688)
01/14/2023 06:26:55 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.693 | Acc: 81.999% (15429/18816)/ 95.982% (18060/18816)
01/14/2023 06:26:57 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.693 | Acc: 82.015% (15537/18944)/ 95.962% (18179/18944)
01/14/2023 06:27:00 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.694 | Acc: 81.958% (15631/19072)/ 95.957% (18301/19072)
01/14/2023 06:27:03 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.698 | Acc: 81.885% (15722/19200)/ 95.927% (18418/19200)
01/14/2023 06:27:05 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.698 | Acc: 81.829% (15816/19328)/ 95.933% (18542/19328)
01/14/2023 06:27:08 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.698 | Acc: 81.862% (15927/19456)/ 95.934% (18665/19456)
01/14/2023 06:27:10 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.700 | Acc: 81.847% (16029/19584)/ 95.925% (18786/19584)
01/14/2023 06:27:13 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.698 | Acc: 81.899% (16144/19712)/ 95.931% (18910/19712)
01/14/2023 06:27:15 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.697 | Acc: 81.895% (16248/19840)/ 95.912% (19029/19840)
01/14/2023 06:27:18 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.698 | Acc: 81.906% (16355/19968)/ 95.908% (19151/19968)
01/14/2023 06:27:21 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.700 | Acc: 81.807% (16440/20096)/ 95.885% (19269/20096)
01/14/2023 06:27:23 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.702 | Acc: 81.789% (16541/20224)/ 95.861% (19387/20224)
01/14/2023 06:27:26 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.703 | Acc: 81.756% (16639/20352)/ 95.838% (19505/20352)
01/14/2023 06:27:28 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.704 | Acc: 81.729% (16738/20480)/ 95.835% (19627/20480)
01/14/2023 06:27:31 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.704 | Acc: 81.716% (16840/20608)/ 95.822% (19747/20608)
01/14/2023 06:27:34 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.714 | Acc: 81.491% (16898/20736)/ 95.727% (19850/20736)
01/14/2023 06:27:36 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.719 | Acc: 81.399% (16983/20864)/ 95.653% (19957/20864)
01/14/2023 06:27:39 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.722 | Acc: 81.350% (17077/20992)/ 95.646% (20078/20992)
01/14/2023 06:27:41 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.722 | Acc: 81.340% (17179/21120)/ 95.663% (20204/21120)
01/14/2023 06:27:44 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.724 | Acc: 81.255% (17265/21248)/ 95.656% (20325/21248)
01/14/2023 06:27:47 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.723 | Acc: 81.269% (17372/21376)/ 95.640% (20444/21376)
01/14/2023 06:27:49 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.725 | Acc: 81.199% (17461/21504)/ 95.619% (20562/21504)
01/14/2023 06:27:52 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.725 | Acc: 81.204% (17566/21632)/ 95.618% (20684/21632)
01/14/2023 06:27:54 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.727 | Acc: 81.176% (17664/21760)/ 95.584% (20799/21760)
01/14/2023 06:27:57 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.731 | Acc: 81.067% (17744/21888)/ 95.546% (20913/21888)
01/14/2023 06:27:59 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.735 | Acc: 81.014% (17836/22016)/ 95.512% (21028/22016)
01/14/2023 06:28:02 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.735 | Acc: 80.970% (17930/22144)/ 95.516% (21151/22144)
01/14/2023 06:28:05 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.738 | Acc: 80.918% (18022/22272)/ 95.492% (21268/22272)
01/14/2023 06:28:07 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.742 | Acc: 80.830% (18106/22400)/ 95.446% (21380/22400)
01/14/2023 06:28:10 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.740 | Acc: 80.873% (18219/22528)/ 95.450% (21503/22528)
01/14/2023 06:28:12 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.741 | Acc: 80.875% (18323/22656)/ 95.427% (21620/22656)
01/14/2023 06:28:15 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.745 | Acc: 80.798% (18409/22784)/ 95.383% (21732/22784)
01/14/2023 06:28:18 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.746 | Acc: 80.774% (18507/22912)/ 95.361% (21849/22912)
01/14/2023 06:28:21 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.750 | Acc: 80.703% (18594/23040)/ 95.321% (21962/23040)
01/14/2023 06:28:23 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.756 | Acc: 80.577% (18668/23168)/ 95.291% (22077/23168)
01/14/2023 06:28:26 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.762 | Acc: 80.443% (18740/23296)/ 95.227% (22184/23296)
01/14/2023 06:28:28 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.761 | Acc: 80.452% (18845/23424)/ 95.227% (22306/23424)
01/14/2023 06:28:31 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.768 | Acc: 80.324% (18918/23552)/ 95.138% (22407/23552)
01/14/2023 06:28:34 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.767 | Acc: 80.351% (19027/23680)/ 95.127% (22526/23680)
01/14/2023 06:28:36 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.767 | Acc: 80.364% (19133/23808)/ 95.119% (22646/23808)
01/14/2023 06:28:39 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.770 | Acc: 80.331% (19228/23936)/ 95.079% (22758/23936)
01/14/2023 06:28:41 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.775 | Acc: 80.219% (19304/24064)/ 95.051% (22873/24064)
01/14/2023 06:28:44 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.778 | Acc: 80.093% (19376/24192)/ 95.027% (22989/24192)
01/14/2023 06:28:46 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.780 | Acc: 80.025% (19462/24320)/ 95.029% (23111/24320)
01/14/2023 06:28:49 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.785 | Acc: 79.937% (19543/24448)/ 94.998% (23225/24448)
01/14/2023 06:28:52 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.787 | Acc: 79.899% (19636/24576)/ 94.971% (23340/24576)
01/14/2023 06:28:54 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.793 | Acc: 79.785% (19710/24704)/ 94.883% (23440/24704)
01/14/2023 06:28:57 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.793 | Acc: 79.804% (19817/24832)/ 94.882% (23561/24832)
01/14/2023 06:29:00 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.796 | Acc: 79.736% (19902/24960)/ 94.860% (23677/24960)
01/14/2023 06:29:02 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.801 | Acc: 79.664% (19986/25088)/ 94.798% (23783/25088)
01/14/2023 06:29:05 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.804 | Acc: 79.572% (20065/25216)/ 94.757% (23894/25216)
01/14/2023 06:29:08 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.809 | Acc: 79.498% (20148/25344)/ 94.732% (24009/25344)
01/14/2023 06:29:10 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.811 | Acc: 79.460% (20240/25472)/ 94.700% (24122/25472)
01/14/2023 06:29:13 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.810 | Acc: 79.449% (20339/25600)/ 94.699% (24243/25600)
01/14/2023 06:29:15 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.810 | Acc: 79.404% (20429/25728)/ 94.694% (24363/25728)
01/14/2023 06:29:18 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.814 | Acc: 79.316% (20508/25856)/ 94.659% (24475/25856)
01/14/2023 06:29:20 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.815 | Acc: 79.303% (20606/25984)/ 94.651% (24594/25984)
01/14/2023 06:29:23 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.816 | Acc: 79.293% (20705/26112)/ 94.646% (24714/26112)
01/14/2023 06:29:26 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.818 | Acc: 79.207% (20784/26240)/ 94.627% (24830/26240)
01/14/2023 06:29:28 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.821 | Acc: 79.122% (20863/26368)/ 94.596% (24943/26368)
01/14/2023 06:29:30 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.823 | Acc: 79.099% (20958/26496)/ 94.592% (25063/26496)
01/14/2023 06:29:33 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.826 | Acc: 79.019% (21038/26624)/ 94.550% (25173/26624)
01/14/2023 06:29:36 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.828 | Acc: 78.985% (21130/26752)/ 94.520% (25286/26752)
01/14/2023 06:29:38 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.828 | Acc: 78.984% (21231/26880)/ 94.539% (25412/26880)
01/14/2023 06:29:41 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.829 | Acc: 78.969% (21328/27008)/ 94.520% (25528/27008)
01/14/2023 06:29:43 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.831 | Acc: 78.910% (21413/27136)/ 94.502% (25644/27136)
01/14/2023 06:29:46 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.833 | Acc: 78.844% (21496/27264)/ 94.480% (25759/27264)
01/14/2023 06:29:48 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.833 | Acc: 78.851% (21599/27392)/ 94.484% (25881/27392)
01/14/2023 06:29:51 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.834 | Acc: 78.826% (21693/27520)/ 94.491% (26004/27520)
01/14/2023 06:29:54 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.834 | Acc: 78.841% (21798/27648)/ 94.484% (26123/27648)
01/14/2023 06:29:56 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.832 | Acc: 78.881% (21910/27776)/ 94.506% (26250/27776)
01/14/2023 06:29:59 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.837 | Acc: 78.813% (21992/27904)/ 94.442% (26353/27904)
01/14/2023 06:30:02 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.839 | Acc: 78.756% (22077/28032)/ 94.406% (26464/28032)
01/14/2023 06:30:04 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.838 | Acc: 78.789% (22187/28160)/ 94.411% (26586/28160)
01/14/2023 06:30:07 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.836 | Acc: 78.825% (22298/28288)/ 94.425% (26711/28288)
01/14/2023 06:30:09 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.838 | Acc: 78.783% (22387/28416)/ 94.412% (26828/28416)
01/14/2023 06:30:12 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.836 | Acc: 78.836% (22503/28544)/ 94.426% (26953/28544)
01/14/2023 06:30:15 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.836 | Acc: 78.836% (22604/28672)/ 94.413% (27070/28672)
01/14/2023 06:30:17 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.836 | Acc: 78.854% (22710/28800)/ 94.406% (27189/28800)
01/14/2023 06:30:20 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.835 | Acc: 78.851% (22810/28928)/ 94.417% (27313/28928)
01/14/2023 06:30:22 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.835 | Acc: 78.837% (22907/29056)/ 94.425% (27436/29056)
01/14/2023 06:30:25 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.838 | Acc: 78.827% (23005/29184)/ 94.408% (27552/29184)
01/14/2023 06:30:28 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.842 | Acc: 78.749% (23083/29312)/ 94.350% (27656/29312)
01/14/2023 06:30:30 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.845 | Acc: 78.692% (23167/29440)/ 94.307% (27764/29440)
01/14/2023 06:30:33 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.848 | Acc: 78.636% (23251/29568)/ 94.271% (27874/29568)
01/14/2023 06:30:35 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.848 | Acc: 78.630% (23350/29696)/ 94.258% (27991/29696)
01/14/2023 06:30:38 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.847 | Acc: 78.661% (23460/29824)/ 94.273% (28116/29824)
01/14/2023 06:30:40 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.849 | Acc: 78.612% (23546/29952)/ 94.254% (28231/29952)
01/14/2023 06:30:43 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.855 | Acc: 78.497% (23612/30080)/ 94.182% (28330/30080)
01/14/2023 06:30:46 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.856 | Acc: 78.486% (23709/30208)/ 94.177% (28449/30208)
01/14/2023 06:30:48 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.854 | Acc: 78.524% (23821/30336)/ 94.182% (28571/30336)
01/14/2023 06:30:51 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.855 | Acc: 78.522% (23921/30464)/ 94.150% (28682/30464)
01/14/2023 06:30:54 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.854 | Acc: 78.560% (24033/30592)/ 94.159% (28805/30592)
01/14/2023 06:30:56 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.852 | Acc: 78.597% (24145/30720)/ 94.160% (28926/30720)
01/14/2023 06:30:59 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.853 | Acc: 78.611% (24250/30848)/ 94.149% (29043/30848)
01/14/2023 06:31:02 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.856 | Acc: 78.522% (24323/30976)/ 94.108% (29151/30976)
01/14/2023 06:31:04 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.858 | Acc: 78.424% (24393/31104)/ 94.091% (29266/31104)
01/14/2023 06:31:07 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.864 | Acc: 78.285% (24450/31232)/ 94.022% (29365/31232)
01/14/2023 06:31:09 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.864 | Acc: 78.291% (24552/31360)/ 94.018% (29484/31360)
01/14/2023 06:31:12 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.863 | Acc: 78.300% (24655/31488)/ 94.010% (29602/31488)
01/14/2023 06:31:15 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.864 | Acc: 78.274% (24747/31616)/ 94.003% (29720/31616)
01/14/2023 06:31:17 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.870 | Acc: 78.179% (24817/31744)/ 93.936% (29819/31744)
01/14/2023 06:31:20 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.870 | Acc: 78.134% (24903/31872)/ 93.926% (29936/31872)
01/14/2023 06:31:22 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.872 | Acc: 78.009% (24963/32000)/ 93.916% (30053/32000)
01/14/2023 06:31:25 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.871 | Acc: 78.044% (25074/32128)/ 93.934% (30179/32128)
01/14/2023 06:31:28 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.873 | Acc: 78.001% (25160/32256)/ 93.902% (30289/32256)
01/14/2023 06:31:30 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.873 | Acc: 78.026% (25268/32384)/ 93.895% (30407/32384)
01/14/2023 06:31:33 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.874 | Acc: 77.999% (25359/32512)/ 93.879% (30522/32512)
01/14/2023 06:31:35 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.878 | Acc: 77.938% (25439/32640)/ 93.836% (30628/32640)
01/14/2023 06:31:38 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.880 | Acc: 77.905% (25528/32768)/ 93.826% (30745/32768)
01/14/2023 06:31:40 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.885 | Acc: 77.785% (25588/32896)/ 93.793% (30854/32896)
01/14/2023 06:31:43 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.886 | Acc: 77.774% (25684/33024)/ 93.780% (30970/33024)
01/14/2023 06:31:46 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.887 | Acc: 77.766% (25781/33152)/ 93.765% (31085/33152)
01/14/2023 06:31:48 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.891 | Acc: 77.647% (25841/33280)/ 93.753% (31201/33280)
01/14/2023 06:31:51 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.891 | Acc: 77.619% (25931/33408)/ 93.750% (31320/33408)
01/14/2023 06:31:53 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.889 | Acc: 77.666% (26046/33536)/ 93.771% (31447/33536)
01/14/2023 06:31:56 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.888 | Acc: 77.691% (26154/33664)/ 93.777% (31569/33664)
01/14/2023 06:31:59 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.891 | Acc: 77.616% (26228/33792)/ 93.750% (31680/33792)
01/14/2023 06:32:01 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.896 | Acc: 77.553% (26306/33920)/ 93.688% (31779/33920)
01/14/2023 06:32:04 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.896 | Acc: 77.582% (26415/34048)/ 93.688% (31899/34048)
01/14/2023 06:32:06 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.898 | Acc: 77.511% (26490/34176)/ 93.671% (32013/34176)
01/14/2023 06:32:09 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.898 | Acc: 77.539% (26599/34304)/ 93.671% (32133/34304)
01/14/2023 06:32:11 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.897 | Acc: 77.556% (26704/34432)/ 93.669% (32252/34432)
01/14/2023 06:32:14 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.899 | Acc: 77.500% (26784/34560)/ 93.649% (32365/34560)
01/14/2023 06:32:17 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.902 | Acc: 77.436% (26861/34688)/ 93.617% (32474/34688)
01/14/2023 06:32:19 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.902 | Acc: 77.447% (26964/34816)/ 93.612% (32592/34816)
01/14/2023 06:32:22 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.903 | Acc: 77.404% (27048/34944)/ 93.607% (32710/34944)
01/14/2023 06:32:25 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.903 | Acc: 77.418% (27152/35072)/ 93.596% (32826/35072)
01/14/2023 06:32:27 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.903 | Acc: 77.415% (27250/35200)/ 93.602% (32948/35200)
01/14/2023 06:32:30 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.905 | Acc: 77.386% (27339/35328)/ 93.597% (33066/35328)
01/14/2023 06:32:32 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.906 | Acc: 77.355% (27427/35456)/ 93.592% (33184/35456)
01/14/2023 06:32:35 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.906 | Acc: 77.327% (27516/35584)/ 93.581% (33300/35584)
01/14/2023 06:32:38 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.906 | Acc: 77.347% (27622/35712)/ 93.579% (33419/35712)
01/14/2023 06:32:40 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.906 | Acc: 77.355% (27724/35840)/ 93.569% (33535/35840)
01/14/2023 06:32:43 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.907 | Acc: 77.333% (27815/35968)/ 93.561% (33652/35968)
01/14/2023 06:32:46 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.907 | Acc: 77.341% (27917/36096)/ 93.556% (33770/36096)
01/14/2023 06:32:48 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.906 | Acc: 77.374% (28028/36224)/ 93.557% (33890/36224)
01/14/2023 06:32:51 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.907 | Acc: 77.347% (28117/36352)/ 93.552% (34008/36352)
01/14/2023 06:32:53 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.910 | Acc: 77.305% (28201/36480)/ 93.528% (34119/36480)
01/14/2023 06:32:56 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.913 | Acc: 77.265% (28285/36608)/ 93.485% (34223/36608)
01/14/2023 06:32:58 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.914 | Acc: 77.232% (28372/36736)/ 93.475% (34339/36736)
01/14/2023 06:33:01 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.914 | Acc: 77.233% (28471/36864)/ 93.468% (34456/36864)
01/14/2023 06:33:03 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.913 | Acc: 77.255% (28578/36992)/ 93.472% (34577/36992)
01/14/2023 06:33:06 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.915 | Acc: 77.220% (28664/37120)/ 93.440% (34685/37120)
01/14/2023 06:33:09 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.916 | Acc: 77.142% (28734/37248)/ 93.444% (34806/37248)
01/14/2023 06:33:11 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.916 | Acc: 77.159% (28839/37376)/ 93.434% (34922/37376)
01/14/2023 06:33:14 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.918 | Acc: 77.106% (28918/37504)/ 93.419% (35036/37504)
01/14/2023 06:33:16 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.918 | Acc: 77.105% (29016/37632)/ 93.413% (35153/37632)
01/14/2023 06:33:19 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.919 | Acc: 77.082% (29106/37760)/ 93.406% (35270/37760)
01/14/2023 06:33:22 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.918 | Acc: 77.114% (29217/37888)/ 93.412% (35392/37888)
01/14/2023 06:33:24 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.918 | Acc: 77.115% (29316/38016)/ 93.403% (35508/38016)
01/14/2023 06:33:27 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.920 | Acc: 77.095% (29407/38144)/ 93.378% (35618/38144)
01/14/2023 06:33:29 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.922 | Acc: 77.062% (29493/38272)/ 93.353% (35728/38272)
01/14/2023 06:33:32 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.923 | Acc: 77.049% (29587/38400)/ 93.333% (35840/38400)
01/14/2023 06:33:35 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.924 | Acc: 77.053% (29687/38528)/ 93.330% (35958/38528)
01/14/2023 06:33:37 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.924 | Acc: 77.038% (29780/38656)/ 93.315% (36072/38656)
01/14/2023 06:33:40 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.926 | Acc: 77.001% (29864/38784)/ 93.301% (36186/38784)
01/14/2023 06:33:43 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.927 | Acc: 76.981% (29955/38912)/ 93.287% (36300/38912)
01/14/2023 06:33:46 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.926 | Acc: 76.995% (30059/39040)/ 93.294% (36422/39040)
01/14/2023 06:33:48 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.927 | Acc: 76.951% (30140/39168)/ 93.290% (36540/39168)
01/14/2023 06:33:51 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.928 | Acc: 76.934% (30232/39296)/ 93.266% (36650/39296)
01/14/2023 06:33:53 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.929 | Acc: 76.930% (30329/39424)/ 93.253% (36764/39424)
01/14/2023 06:33:56 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.929 | Acc: 76.911% (30420/39552)/ 93.249% (36882/39552)
01/14/2023 06:33:58 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.930 | Acc: 76.908% (30517/39680)/ 93.231% (36994/39680)
01/14/2023 06:34:01 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.931 | Acc: 76.899% (30612/39808)/ 93.217% (37108/39808)
01/14/2023 06:34:04 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.932 | Acc: 76.878% (30702/39936)/ 93.207% (37223/39936)
01/14/2023 06:34:06 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.934 | Acc: 76.857% (30792/40064)/ 93.183% (37333/40064)
01/14/2023 06:34:09 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.932 | Acc: 76.896% (30906/40192)/ 93.200% (37459/40192)
01/14/2023 06:34:12 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.932 | Acc: 76.887% (31001/40320)/ 93.197% (37577/40320)
01/14/2023 06:34:14 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.933 | Acc: 76.872% (31093/40448)/ 93.181% (37690/40448)
01/14/2023 06:34:17 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.936 | Acc: 76.784% (31156/40576)/ 93.156% (37799/40576)
01/14/2023 06:34:19 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.938 | Acc: 76.744% (31238/40704)/ 93.133% (37909/40704)
01/14/2023 06:34:22 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.936 | Acc: 76.776% (31349/40832)/ 93.150% (38035/40832)
01/14/2023 06:34:24 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.939 | Acc: 76.719% (31424/40960)/ 93.120% (38142/40960)
01/14/2023 06:34:27 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.938 | Acc: 76.757% (31538/41088)/ 93.129% (38265/41088)
01/14/2023 06:34:30 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.938 | Acc: 76.778% (31645/41216)/ 93.129% (38384/41216)
01/14/2023 06:34:32 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.939 | Acc: 76.758% (31735/41344)/ 93.119% (38499/41344)
01/14/2023 06:34:35 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.941 | Acc: 76.722% (31818/41472)/ 93.097% (38609/41472)
01/14/2023 06:34:38 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.942 | Acc: 76.716% (31914/41600)/ 93.089% (38725/41600)
01/14/2023 06:34:40 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.941 | Acc: 76.723% (32015/41728)/ 93.089% (38844/41728)
01/14/2023 06:34:43 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.945 | Acc: 76.639% (32078/41856)/ 93.060% (38951/41856)
01/14/2023 06:34:46 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.948 | Acc: 76.555% (32141/41984)/ 93.028% (39057/41984)
01/14/2023 06:34:49 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.950 | Acc: 76.506% (32218/42112)/ 93.004% (39166/42112)
01/14/2023 06:34:51 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.950 | Acc: 76.499% (32313/42240)/ 93.004% (39285/42240)
01/14/2023 06:34:54 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.952 | Acc: 76.456% (32393/42368)/ 92.978% (39393/42368)
01/14/2023 06:34:57 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.952 | Acc: 76.424% (32477/42496)/ 92.992% (39518/42496)
01/14/2023 06:34:59 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.952 | Acc: 76.419% (32573/42624)/ 92.990% (39636/42624)
01/14/2023 06:35:02 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.951 | Acc: 76.448% (32683/42752)/ 92.999% (39759/42752)
01/14/2023 06:35:05 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.953 | Acc: 76.418% (32768/42880)/ 92.978% (39869/42880)
01/14/2023 06:35:07 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.954 | Acc: 76.397% (32857/43008)/ 92.966% (39983/43008)
01/14/2023 06:35:10 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.955 | Acc: 76.354% (32936/43136)/ 92.950% (40095/43136)
01/14/2023 06:35:12 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.956 | Acc: 76.350% (33032/43264)/ 92.948% (40213/43264)
01/14/2023 06:35:15 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.955 | Acc: 76.337% (33124/43392)/ 92.957% (40336/43392)
01/14/2023 06:35:17 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.958 | Acc: 76.301% (33206/43520)/ 92.932% (40444/43520)
01/14/2023 06:35:20 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.958 | Acc: 76.294% (33301/43648)/ 92.941% (40567/43648)
01/14/2023 06:35:23 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.956 | Acc: 76.334% (33416/43776)/ 92.960% (40694/43776)
01/14/2023 06:35:25 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.957 | Acc: 76.285% (33492/43904)/ 92.955% (40811/43904)
01/14/2023 06:35:28 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.956 | Acc: 76.281% (33588/44032)/ 92.960% (40932/44032)
01/14/2023 06:35:30 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.957 | Acc: 76.279% (33685/44160)/ 92.951% (41047/44160)
01/14/2023 06:35:33 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.960 | Acc: 76.210% (33752/44288)/ 92.910% (41148/44288)
01/14/2023 06:35:35 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.962 | Acc: 76.198% (33844/44416)/ 92.897% (41261/44416)
01/14/2023 06:35:38 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.961 | Acc: 76.210% (33947/44544)/ 92.906% (41384/44544)
01/14/2023 06:35:40 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.963 | Acc: 76.186% (34034/44672)/ 92.881% (41492/44672)
01/14/2023 06:35:43 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.962 | Acc: 76.185% (34131/44800)/ 92.891% (41615/44800)
01/14/2023 06:35:46 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.962 | Acc: 76.197% (34234/44928)/ 92.886% (41732/44928)
01/14/2023 06:35:48 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.965 | Acc: 76.139% (34305/45056)/ 92.869% (41843/45056)
01/14/2023 06:35:51 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.965 | Acc: 76.135% (34401/45184)/ 92.865% (41960/45184)
01/14/2023 06:35:53 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.967 | Acc: 76.092% (34479/45312)/ 92.823% (42060/45312)
01/14/2023 06:35:56 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.970 | Acc: 76.037% (34551/45440)/ 92.806% (42171/45440)
01/14/2023 06:35:59 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.972 | Acc: 75.972% (34619/45568)/ 92.795% (42285/45568)
01/14/2023 06:36:01 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.973 | Acc: 75.965% (34713/45696)/ 92.791% (42402/45696)
01/14/2023 06:36:04 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.971 | Acc: 75.999% (34826/45824)/ 92.805% (42527/45824)
01/14/2023 06:36:06 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.970 | Acc: 76.027% (34936/45952)/ 92.808% (42647/45952)
01/14/2023 06:36:09 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.971 | Acc: 76.037% (35038/46080)/ 92.802% (42763/46080)
01/14/2023 06:36:12 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.972 | Acc: 76.008% (35122/46208)/ 92.793% (42878/46208)
01/14/2023 06:36:14 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.972 | Acc: 76.010% (35220/46336)/ 92.800% (43000/46336)
01/14/2023 06:36:17 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.972 | Acc: 76.009% (35317/46464)/ 92.812% (43124/46464)
01/14/2023 06:36:19 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.972 | Acc: 76.000% (35410/46592)/ 92.801% (43238/46592)
01/14/2023 06:36:22 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.971 | Acc: 76.027% (35520/46720)/ 92.810% (43361/46720)
01/14/2023 06:36:25 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.970 | Acc: 76.042% (35624/46848)/ 92.817% (43483/46848)
01/14/2023 06:36:27 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.969 | Acc: 76.077% (35738/46976)/ 92.835% (43610/46976)
01/14/2023 06:36:30 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.968 | Acc: 76.102% (35847/47104)/ 92.848% (43735/47104)
01/14/2023 06:36:32 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.967 | Acc: 76.107% (35947/47232)/ 92.857% (43858/47232)
01/14/2023 06:36:35 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.967 | Acc: 76.128% (36054/47360)/ 92.865% (43981/47360)
01/14/2023 06:36:37 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.967 | Acc: 76.114% (36145/47488)/ 92.868% (44101/47488)
01/14/2023 06:36:40 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.967 | Acc: 76.124% (36247/47616)/ 92.872% (44222/47616)
01/14/2023 06:36:43 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.965 | Acc: 76.171% (36367/47744)/ 92.887% (44348/47744)
01/14/2023 06:36:45 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.963 | Acc: 76.209% (36483/47872)/ 92.896% (44471/47872)
01/14/2023 06:36:48 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.962 | Acc: 76.242% (36596/48000)/ 92.902% (44593/48000)
01/14/2023 06:36:50 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.965 | Acc: 76.178% (36663/48128)/ 92.863% (44693/48128)
01/14/2023 06:36:53 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.966 | Acc: 76.173% (36758/48256)/ 92.851% (44806/48256)
01/14/2023 06:36:56 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.966 | Acc: 76.162% (36850/48384)/ 92.847% (44923/48384)
01/14/2023 06:36:58 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.969 | Acc: 76.086% (36911/48512)/ 92.804% (45021/48512)
01/14/2023 06:37:01 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.970 | Acc: 76.071% (37001/48640)/ 92.808% (45142/48640)
01/14/2023 06:37:03 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.969 | Acc: 76.064% (37095/48768)/ 92.817% (45265/48768)
01/14/2023 06:37:06 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.971 | Acc: 76.014% (37168/48896)/ 92.813% (45382/48896)
01/14/2023 06:37:09 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.973 | Acc: 75.975% (37246/49024)/ 92.799% (45494/49024)
01/14/2023 06:37:11 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.973 | Acc: 75.981% (37346/49152)/ 92.796% (45611/49152)
01/14/2023 06:37:14 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.971 | Acc: 76.023% (37464/49280)/ 92.808% (45736/49280)
01/14/2023 06:37:16 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.970 | Acc: 76.032% (37566/49408)/ 92.817% (45859/49408)
01/14/2023 06:37:19 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.968 | Acc: 76.078% (37686/49536)/ 92.833% (45986/49536)
01/14/2023 06:37:22 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.966 | Acc: 76.118% (37803/49664)/ 92.844% (46110/49664)
01/14/2023 06:37:24 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.965 | Acc: 76.163% (37923/49792)/ 92.856% (46235/49792)
01/14/2023 06:37:27 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.964 | Acc: 76.164% (38021/49920)/ 92.861% (46356/49920)
01/14/2023 06:37:29 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.966 | Acc: 76.116% (38058/50000)/ 92.852% (46426/50000)
01/14/2023 06:37:29 - INFO - __main__ -   Final accuracy: 76.116
01/14/2023 06:37:29 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 2, '_step_count': 3, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [2.5e-05]}
01/14/2023 06:37:29 - INFO - __main__ -   
Epoch: 2
01/14/2023 06:37:32 - INFO - __main__ -   test: [epoch: 2 | batch: 0/10010 ] | Loss: 0.969 | Acc: 77.344% (99/128)
01/14/2023 06:41:55 - INFO - __main__ -   test: [epoch: 2 | batch: 100/10010 ] | Loss: 0.829 | Acc: 79.610% (10292/12928)
01/14/2023 06:46:19 - INFO - __main__ -   test: [epoch: 2 | batch: 200/10010 ] | Loss: 0.837 | Acc: 79.019% (20330/25728)
01/14/2023 06:50:40 - INFO - __main__ -   test: [epoch: 2 | batch: 300/10010 ] | Loss: 0.842 | Acc: 78.987% (30432/38528)
01/14/2023 06:55:03 - INFO - __main__ -   test: [epoch: 2 | batch: 400/10010 ] | Loss: 0.848 | Acc: 78.850% (40472/51328)
01/14/2023 06:59:22 - INFO - __main__ -   test: [epoch: 2 | batch: 500/10010 ] | Loss: 0.851 | Acc: 78.771% (50514/64128)
01/14/2023 07:03:43 - INFO - __main__ -   test: [epoch: 2 | batch: 600/10010 ] | Loss: 0.855 | Acc: 78.716% (60555/76928)
01/14/2023 07:08:03 - INFO - __main__ -   test: [epoch: 2 | batch: 700/10010 ] | Loss: 0.856 | Acc: 78.670% (70589/89728)
01/14/2023 07:12:25 - INFO - __main__ -   test: [epoch: 2 | batch: 800/10010 ] | Loss: 0.857 | Acc: 78.635% (80623/102528)
01/14/2023 07:16:48 - INFO - __main__ -   test: [epoch: 2 | batch: 900/10010 ] | Loss: 0.855 | Acc: 78.674% (90733/115328)
01/14/2023 07:21:09 - INFO - __main__ -   test: [epoch: 2 | batch: 1000/10010 ] | Loss: 0.857 | Acc: 78.623% (100738/128128)
01/14/2023 07:25:28 - INFO - __main__ -   test: [epoch: 2 | batch: 1100/10010 ] | Loss: 0.858 | Acc: 78.625% (110805/140928)
01/14/2023 07:29:48 - INFO - __main__ -   test: [epoch: 2 | batch: 1200/10010 ] | Loss: 0.860 | Acc: 78.581% (120801/153728)
01/14/2023 07:34:10 - INFO - __main__ -   test: [epoch: 2 | batch: 1300/10010 ] | Loss: 0.858 | Acc: 78.602% (130894/166528)
01/14/2023 07:38:31 - INFO - __main__ -   test: [epoch: 2 | batch: 1400/10010 ] | Loss: 0.858 | Acc: 78.623% (140993/179328)
01/14/2023 07:42:53 - INFO - __main__ -   test: [epoch: 2 | batch: 1500/10010 ] | Loss: 0.858 | Acc: 78.592% (150997/192128)
01/14/2023 07:47:14 - INFO - __main__ -   test: [epoch: 2 | batch: 1600/10010 ] | Loss: 0.859 | Acc: 78.571% (161014/204928)
01/14/2023 07:51:33 - INFO - __main__ -   test: [epoch: 2 | batch: 1700/10010 ] | Loss: 0.859 | Acc: 78.571% (171072/217728)
01/14/2023 07:55:54 - INFO - __main__ -   test: [epoch: 2 | batch: 1800/10010 ] | Loss: 0.858 | Acc: 78.578% (181145/230528)
01/14/2023 08:00:14 - INFO - __main__ -   test: [epoch: 2 | batch: 1900/10010 ] | Loss: 0.857 | Acc: 78.603% (191264/243328)
01/14/2023 08:04:35 - INFO - __main__ -   test: [epoch: 2 | batch: 2000/10010 ] | Loss: 0.856 | Acc: 78.622% (201372/256128)
01/14/2023 08:08:55 - INFO - __main__ -   test: [epoch: 2 | batch: 2100/10010 ] | Loss: 0.855 | Acc: 78.615% (211419/268928)
01/14/2023 08:13:16 - INFO - __main__ -   test: [epoch: 2 | batch: 2200/10010 ] | Loss: 0.857 | Acc: 78.603% (221448/281728)
01/14/2023 08:17:36 - INFO - __main__ -   test: [epoch: 2 | batch: 2300/10010 ] | Loss: 0.858 | Acc: 78.584% (231453/294528)
01/14/2023 08:21:57 - INFO - __main__ -   test: [epoch: 2 | batch: 2400/10010 ] | Loss: 0.858 | Acc: 78.590% (241529/307328)
01/14/2023 08:26:18 - INFO - __main__ -   test: [epoch: 2 | batch: 2500/10010 ] | Loss: 0.858 | Acc: 78.590% (251588/320128)
01/14/2023 08:30:38 - INFO - __main__ -   test: [epoch: 2 | batch: 2600/10010 ] | Loss: 0.858 | Acc: 78.605% (261699/332928)
01/14/2023 08:34:57 - INFO - __main__ -   test: [epoch: 2 | batch: 2700/10010 ] | Loss: 0.857 | Acc: 78.638% (271875/345728)
01/14/2023 08:39:16 - INFO - __main__ -   test: [epoch: 2 | batch: 2800/10010 ] | Loss: 0.857 | Acc: 78.635% (281927/358528)
01/14/2023 08:43:35 - INFO - __main__ -   test: [epoch: 2 | batch: 2900/10010 ] | Loss: 0.857 | Acc: 78.635% (291994/371328)
01/14/2023 08:47:56 - INFO - __main__ -   test: [epoch: 2 | batch: 3000/10010 ] | Loss: 0.857 | Acc: 78.640% (302080/384128)
01/14/2023 08:52:16 - INFO - __main__ -   test: [epoch: 2 | batch: 3100/10010 ] | Loss: 0.857 | Acc: 78.651% (312189/396928)
01/14/2023 08:56:36 - INFO - __main__ -   test: [epoch: 2 | batch: 3200/10010 ] | Loss: 0.856 | Acc: 78.659% (322289/409728)
01/14/2023 09:00:57 - INFO - __main__ -   test: [epoch: 2 | batch: 3300/10010 ] | Loss: 0.857 | Acc: 78.645% (332297/422528)
01/14/2023 09:05:19 - INFO - __main__ -   test: [epoch: 2 | batch: 3400/10010 ] | Loss: 0.857 | Acc: 78.656% (342411/435328)
01/14/2023 09:09:39 - INFO - __main__ -   test: [epoch: 2 | batch: 3500/10010 ] | Loss: 0.857 | Acc: 78.658% (352490/448128)
01/14/2023 09:13:58 - INFO - __main__ -   test: [epoch: 2 | batch: 3600/10010 ] | Loss: 0.856 | Acc: 78.678% (362648/460928)
01/14/2023 09:18:17 - INFO - __main__ -   test: [epoch: 2 | batch: 3700/10010 ] | Loss: 0.856 | Acc: 78.665% (372659/473728)
01/14/2023 09:22:35 - INFO - __main__ -   test: [epoch: 2 | batch: 3800/10010 ] | Loss: 0.856 | Acc: 78.687% (382832/486528)
01/14/2023 09:26:55 - INFO - __main__ -   test: [epoch: 2 | batch: 3900/10010 ] | Loss: 0.856 | Acc: 78.678% (392863/499328)
01/14/2023 09:31:14 - INFO - __main__ -   test: [epoch: 2 | batch: 4000/10010 ] | Loss: 0.856 | Acc: 78.660% (402839/512128)
01/14/2023 09:35:35 - INFO - __main__ -   test: [epoch: 2 | batch: 4100/10010 ] | Loss: 0.856 | Acc: 78.664% (412928/524928)
01/14/2023 09:39:56 - INFO - __main__ -   test: [epoch: 2 | batch: 4200/10010 ] | Loss: 0.856 | Acc: 78.658% (422965/537728)
01/14/2023 09:44:16 - INFO - __main__ -   test: [epoch: 2 | batch: 4300/10010 ] | Loss: 0.856 | Acc: 78.656% (433024/550528)
01/14/2023 09:48:36 - INFO - __main__ -   test: [epoch: 2 | batch: 4400/10010 ] | Loss: 0.856 | Acc: 78.671% (443176/563328)
01/14/2023 09:52:58 - INFO - __main__ -   test: [epoch: 2 | batch: 4500/10010 ] | Loss: 0.856 | Acc: 78.666% (453219/576128)
01/14/2023 09:57:20 - INFO - __main__ -   test: [epoch: 2 | batch: 4600/10010 ] | Loss: 0.857 | Acc: 78.655% (463221/588928)
01/14/2023 10:01:41 - INFO - __main__ -   test: [epoch: 2 | batch: 4700/10010 ] | Loss: 0.857 | Acc: 78.653% (473277/601728)
01/14/2023 10:06:01 - INFO - __main__ -   test: [epoch: 2 | batch: 4800/10010 ] | Loss: 0.857 | Acc: 78.658% (483378/614528)
01/14/2023 10:10:23 - INFO - __main__ -   test: [epoch: 2 | batch: 4900/10010 ] | Loss: 0.857 | Acc: 78.655% (493422/627328)
01/14/2023 10:14:42 - INFO - __main__ -   test: [epoch: 2 | batch: 5000/10010 ] | Loss: 0.856 | Acc: 78.671% (503593/640128)
01/14/2023 10:19:02 - INFO - __main__ -   test: [epoch: 2 | batch: 5100/10010 ] | Loss: 0.857 | Acc: 78.661% (513601/652928)
01/14/2023 10:23:24 - INFO - __main__ -   test: [epoch: 2 | batch: 5200/10010 ] | Loss: 0.857 | Acc: 78.654% (523620/665728)
01/14/2023 10:27:43 - INFO - __main__ -   test: [epoch: 2 | batch: 5300/10010 ] | Loss: 0.857 | Acc: 78.651% (533666/678528)
01/14/2023 10:32:03 - INFO - __main__ -   test: [epoch: 2 | batch: 5400/10010 ] | Loss: 0.857 | Acc: 78.642% (543675/691328)
01/14/2023 10:36:23 - INFO - __main__ -   test: [epoch: 2 | batch: 5500/10010 ] | Loss: 0.857 | Acc: 78.641% (553733/704128)
01/14/2023 10:40:44 - INFO - __main__ -   test: [epoch: 2 | batch: 5600/10010 ] | Loss: 0.857 | Acc: 78.646% (563835/716928)
01/14/2023 10:45:02 - INFO - __main__ -   test: [epoch: 2 | batch: 5700/10010 ] | Loss: 0.857 | Acc: 78.648% (573915/729728)
01/14/2023 10:49:23 - INFO - __main__ -   test: [epoch: 2 | batch: 5800/10010 ] | Loss: 0.857 | Acc: 78.655% (584038/742528)
01/14/2023 10:53:43 - INFO - __main__ -   test: [epoch: 2 | batch: 5900/10010 ] | Loss: 0.857 | Acc: 78.666% (594186/755328)
01/14/2023 10:58:05 - INFO - __main__ -   test: [epoch: 2 | batch: 6000/10010 ] | Loss: 0.857 | Acc: 78.666% (604257/768128)
01/14/2023 11:02:26 - INFO - __main__ -   test: [epoch: 2 | batch: 6100/10010 ] | Loss: 0.857 | Acc: 78.654% (614228/780928)
01/14/2023 11:06:47 - INFO - __main__ -   test: [epoch: 2 | batch: 6200/10010 ] | Loss: 0.857 | Acc: 78.651% (624277/793728)
01/14/2023 11:11:08 - INFO - __main__ -   test: [epoch: 2 | batch: 6300/10010 ] | Loss: 0.857 | Acc: 78.654% (634366/806528)
01/14/2023 11:15:28 - INFO - __main__ -   test: [epoch: 2 | batch: 6400/10010 ] | Loss: 0.857 | Acc: 78.647% (644377/819328)
01/14/2023 11:19:48 - INFO - __main__ -   test: [epoch: 2 | batch: 6500/10010 ] | Loss: 0.857 | Acc: 78.655% (654508/832128)
01/14/2023 11:24:08 - INFO - __main__ -   test: [epoch: 2 | batch: 6600/10010 ] | Loss: 0.857 | Acc: 78.651% (664545/844928)
01/14/2023 11:28:27 - INFO - __main__ -   test: [epoch: 2 | batch: 6700/10010 ] | Loss: 0.857 | Acc: 78.644% (674555/857728)
01/14/2023 11:32:47 - INFO - __main__ -   test: [epoch: 2 | batch: 6800/10010 ] | Loss: 0.857 | Acc: 78.645% (684625/870528)
01/14/2023 11:37:08 - INFO - __main__ -   test: [epoch: 2 | batch: 6900/10010 ] | Loss: 0.857 | Acc: 78.648% (694723/883328)
01/14/2023 11:41:29 - INFO - __main__ -   test: [epoch: 2 | batch: 7000/10010 ] | Loss: 0.857 | Acc: 78.640% (704711/896128)
01/14/2023 11:45:49 - INFO - __main__ -   test: [epoch: 2 | batch: 7100/10010 ] | Loss: 0.857 | Acc: 78.643% (714807/908928)
01/14/2023 11:50:09 - INFO - __main__ -   test: [epoch: 2 | batch: 7200/10010 ] | Loss: 0.857 | Acc: 78.645% (724895/921728)
01/14/2023 11:54:28 - INFO - __main__ -   test: [epoch: 2 | batch: 7300/10010 ] | Loss: 0.857 | Acc: 78.644% (734946/934528)
01/14/2023 11:58:49 - INFO - __main__ -   test: [epoch: 2 | batch: 7400/10010 ] | Loss: 0.857 | Acc: 78.651% (745083/947328)
01/14/2023 12:03:10 - INFO - __main__ -   test: [epoch: 2 | batch: 7500/10010 ] | Loss: 0.856 | Acc: 78.658% (755220/960128)
01/14/2023 12:07:29 - INFO - __main__ -   test: [epoch: 2 | batch: 7600/10010 ] | Loss: 0.856 | Acc: 78.665% (765349/972928)
01/14/2023 12:11:49 - INFO - __main__ -   test: [epoch: 2 | batch: 7700/10010 ] | Loss: 0.856 | Acc: 78.659% (775366/985728)
01/14/2023 12:16:09 - INFO - __main__ -   test: [epoch: 2 | batch: 7800/10010 ] | Loss: 0.857 | Acc: 78.655% (785396/998528)
01/14/2023 12:20:28 - INFO - __main__ -   test: [epoch: 2 | batch: 7900/10010 ] | Loss: 0.857 | Acc: 78.659% (795498/1011328)
01/14/2023 12:24:49 - INFO - __main__ -   test: [epoch: 2 | batch: 8000/10010 ] | Loss: 0.857 | Acc: 78.657% (805551/1024128)
01/14/2023 12:29:09 - INFO - __main__ -   test: [epoch: 2 | batch: 8100/10010 ] | Loss: 0.857 | Acc: 78.663% (815678/1036928)
01/14/2023 12:33:29 - INFO - __main__ -   test: [epoch: 2 | batch: 8200/10010 ] | Loss: 0.857 | Acc: 78.660% (825717/1049728)
01/14/2023 12:37:48 - INFO - __main__ -   test: [epoch: 2 | batch: 8300/10010 ] | Loss: 0.857 | Acc: 78.657% (835750/1062528)
01/14/2023 12:42:11 - INFO - __main__ -   test: [epoch: 2 | batch: 8400/10010 ] | Loss: 0.857 | Acc: 78.659% (845843/1075328)
01/14/2023 12:46:34 - INFO - __main__ -   test: [epoch: 2 | batch: 8500/10010 ] | Loss: 0.857 | Acc: 78.663% (855958/1088128)
01/14/2023 12:50:54 - INFO - __main__ -   test: [epoch: 2 | batch: 8600/10010 ] | Loss: 0.857 | Acc: 78.670% (866100/1100928)
01/14/2023 12:55:14 - INFO - __main__ -   test: [epoch: 2 | batch: 8700/10010 ] | Loss: 0.856 | Acc: 78.673% (876205/1113728)
01/14/2023 12:59:34 - INFO - __main__ -   test: [epoch: 2 | batch: 8800/10010 ] | Loss: 0.856 | Acc: 78.679% (886345/1126528)
01/14/2023 13:03:54 - INFO - __main__ -   test: [epoch: 2 | batch: 8900/10010 ] | Loss: 0.856 | Acc: 78.679% (896409/1139328)
01/14/2023 13:08:16 - INFO - __main__ -   test: [epoch: 2 | batch: 9000/10010 ] | Loss: 0.857 | Acc: 78.671% (906393/1152128)
01/14/2023 13:12:36 - INFO - __main__ -   test: [epoch: 2 | batch: 9100/10010 ] | Loss: 0.857 | Acc: 78.666% (916408/1164928)
01/14/2023 13:16:57 - INFO - __main__ -   test: [epoch: 2 | batch: 9200/10010 ] | Loss: 0.856 | Acc: 78.670% (926523/1177728)
01/14/2023 13:21:18 - INFO - __main__ -   test: [epoch: 2 | batch: 9300/10010 ] | Loss: 0.857 | Acc: 78.668% (936569/1190528)
01/14/2023 13:25:37 - INFO - __main__ -   test: [epoch: 2 | batch: 9400/10010 ] | Loss: 0.857 | Acc: 78.672% (946680/1203328)
01/14/2023 13:29:57 - INFO - __main__ -   test: [epoch: 2 | batch: 9500/10010 ] | Loss: 0.857 | Acc: 78.668% (956704/1216128)
01/14/2023 13:34:17 - INFO - __main__ -   test: [epoch: 2 | batch: 9600/10010 ] | Loss: 0.857 | Acc: 78.667% (966763/1228928)
01/14/2023 13:38:38 - INFO - __main__ -   test: [epoch: 2 | batch: 9700/10010 ] | Loss: 0.857 | Acc: 78.663% (976780/1241728)
01/14/2023 13:42:59 - INFO - __main__ -   test: [epoch: 2 | batch: 9800/10010 ] | Loss: 0.857 | Acc: 78.661% (986820/1254528)
01/14/2023 13:47:20 - INFO - __main__ -   test: [epoch: 2 | batch: 9900/10010 ] | Loss: 0.857 | Acc: 78.662% (996910/1267328)
01/14/2023 13:51:41 - INFO - __main__ -   test: [epoch: 2 | batch: 10000/10010 ] | Loss: 0.857 | Acc: 78.659% (1006940/1280128)
01/14/2023 13:52:04 - INFO - __main__ -   Saving Checkpoint
01/14/2023 13:52:07 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.475 | Acc: 85.156% (109/128)/ 96.875% (124/128)
01/14/2023 13:52:10 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.474 | Acc: 85.938% (220/256)/ 97.656% (250/256)
01/14/2023 13:52:12 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.627 | Acc: 82.031% (315/384)/ 95.573% (367/384)
01/14/2023 13:52:15 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.584 | Acc: 83.984% (430/512)/ 96.289% (493/512)
01/14/2023 13:52:17 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.499 | Acc: 86.406% (553/640)/ 97.031% (621/640)
01/14/2023 13:52:20 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.441 | Acc: 87.760% (674/768)/ 97.526% (749/768)
01/14/2023 13:52:22 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.433 | Acc: 88.281% (791/896)/ 97.433% (873/896)
01/14/2023 13:52:25 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.413 | Acc: 89.258% (914/1024)/ 97.559% (999/1024)
01/14/2023 13:52:27 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.431 | Acc: 89.149% (1027/1152)/ 97.483% (1123/1152)
01/14/2023 13:52:30 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.410 | Acc: 89.688% (1148/1280)/ 97.578% (1249/1280)
01/14/2023 13:52:33 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.460 | Acc: 88.352% (1244/1408)/ 97.656% (1375/1408)
01/14/2023 13:52:35 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.462 | Acc: 88.542% (1360/1536)/ 97.591% (1499/1536)
01/14/2023 13:52:38 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.507 | Acc: 87.440% (1455/1664)/ 97.296% (1619/1664)
01/14/2023 13:52:41 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.555 | Acc: 85.993% (1541/1792)/ 96.819% (1735/1792)
01/14/2023 13:52:44 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.575 | Acc: 85.208% (1636/1920)/ 96.875% (1860/1920)
01/14/2023 13:52:46 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.584 | Acc: 84.814% (1737/2048)/ 96.973% (1986/2048)
01/14/2023 13:52:49 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.593 | Acc: 84.605% (1841/2176)/ 96.783% (2106/2176)
01/14/2023 13:52:51 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.619 | Acc: 84.158% (1939/2304)/ 96.311% (2219/2304)
01/14/2023 13:52:54 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.642 | Acc: 83.594% (2033/2432)/ 96.135% (2338/2432)
01/14/2023 13:52:57 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.649 | Acc: 83.320% (2133/2560)/ 96.094% (2460/2560)
01/14/2023 13:52:59 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.647 | Acc: 83.408% (2242/2688)/ 96.019% (2581/2688)
01/14/2023 13:53:02 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.679 | Acc: 82.599% (2326/2816)/ 95.845% (2699/2816)
01/14/2023 13:53:04 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.678 | Acc: 82.541% (2430/2944)/ 95.822% (2821/2944)
01/14/2023 13:53:07 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.722 | Acc: 81.673% (2509/3072)/ 95.540% (2935/3072)
01/14/2023 13:53:10 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.741 | Acc: 81.250% (2600/3200)/ 95.344% (3051/3200)
01/14/2023 13:53:12 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.763 | Acc: 80.679% (2685/3328)/ 95.102% (3165/3328)
01/14/2023 13:53:15 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.777 | Acc: 79.977% (2764/3456)/ 95.052% (3285/3456)
01/14/2023 13:53:18 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.759 | Acc: 80.497% (2885/3584)/ 95.089% (3408/3584)
01/14/2023 13:53:20 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.768 | Acc: 79.930% (2967/3712)/ 95.151% (3532/3712)
01/14/2023 13:53:23 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.761 | Acc: 80.078% (3075/3840)/ 95.260% (3658/3840)
01/14/2023 13:53:25 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.774 | Acc: 80.015% (3175/3968)/ 95.136% (3775/3968)
01/14/2023 13:53:28 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.769 | Acc: 80.225% (3286/4096)/ 95.190% (3899/4096)
01/14/2023 13:53:31 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.755 | Acc: 80.540% (3402/4224)/ 95.289% (4025/4224)
01/14/2023 13:53:33 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.749 | Acc: 80.722% (3513/4352)/ 95.335% (4149/4352)
01/14/2023 13:53:36 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.736 | Acc: 81.116% (3634/4480)/ 95.379% (4273/4480)
01/14/2023 13:53:39 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.723 | Acc: 81.489% (3755/4608)/ 95.399% (4396/4608)
01/14/2023 13:53:41 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.709 | Acc: 81.926% (3880/4736)/ 95.503% (4523/4736)
01/14/2023 13:53:44 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.700 | Acc: 82.216% (3999/4864)/ 95.559% (4648/4864)
01/14/2023 13:53:47 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.692 | Acc: 82.352% (4111/4992)/ 95.613% (4773/4992)
01/14/2023 13:53:49 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.688 | Acc: 82.383% (4218/5120)/ 95.645% (4897/5120)
01/14/2023 13:53:52 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.686 | Acc: 82.508% (4330/5248)/ 95.579% (5016/5248)
01/14/2023 13:53:54 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.689 | Acc: 82.571% (4439/5376)/ 95.517% (5135/5376)
01/14/2023 13:53:57 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.689 | Acc: 82.540% (4543/5504)/ 95.531% (5258/5504)
01/14/2023 13:53:59 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.687 | Acc: 82.617% (4653/5632)/ 95.490% (5378/5632)
01/14/2023 13:54:02 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.690 | Acc: 82.622% (4759/5760)/ 95.417% (5496/5760)
01/14/2023 13:54:05 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.687 | Acc: 82.796% (4875/5888)/ 95.414% (5618/5888)
01/14/2023 13:54:07 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.690 | Acc: 82.779% (4980/6016)/ 95.445% (5742/6016)
01/14/2023 13:54:10 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.691 | Acc: 82.699% (5081/6144)/ 95.508% (5868/6144)
01/14/2023 13:54:12 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.697 | Acc: 82.573% (5179/6272)/ 95.472% (5988/6272)
01/14/2023 13:54:15 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.700 | Acc: 82.625% (5288/6400)/ 95.391% (6105/6400)
01/14/2023 13:54:17 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.692 | Acc: 82.828% (5407/6528)/ 95.435% (6230/6528)
01/14/2023 13:54:20 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.684 | Acc: 83.023% (5526/6656)/ 95.493% (6356/6656)
01/14/2023 13:54:22 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.682 | Acc: 83.107% (5638/6784)/ 95.519% (6480/6784)
01/14/2023 13:54:25 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.673 | Acc: 83.319% (5759/6912)/ 95.587% (6607/6912)
01/14/2023 13:54:28 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.666 | Acc: 83.466% (5876/7040)/ 95.611% (6731/7040)
01/14/2023 13:54:30 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.659 | Acc: 83.608% (5993/7168)/ 95.647% (6856/7168)
01/14/2023 13:54:33 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.651 | Acc: 83.813% (6115/7296)/ 95.696% (6982/7296)
01/14/2023 13:54:35 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.644 | Acc: 83.998% (6236/7424)/ 95.744% (7108/7424)
01/14/2023 13:54:38 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.642 | Acc: 84.057% (6348/7552)/ 95.736% (7230/7552)
01/14/2023 13:54:40 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.644 | Acc: 83.971% (6449/7680)/ 95.755% (7354/7680)
01/14/2023 13:54:43 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.649 | Acc: 83.863% (6548/7808)/ 95.722% (7474/7808)
01/14/2023 13:54:46 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.649 | Acc: 83.871% (6656/7936)/ 95.754% (7599/7936)
01/14/2023 13:54:48 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.649 | Acc: 83.829% (6760/8064)/ 95.771% (7723/8064)
01/14/2023 13:54:51 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.657 | Acc: 83.691% (6856/8192)/ 95.715% (7841/8192)
01/14/2023 13:54:53 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.665 | Acc: 83.498% (6947/8320)/ 95.673% (7960/8320)
01/14/2023 13:54:56 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.678 | Acc: 83.014% (7013/8448)/ 95.585% (8075/8448)
01/14/2023 13:54:58 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.683 | Acc: 82.999% (7118/8576)/ 95.546% (8194/8576)
01/14/2023 13:55:01 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.686 | Acc: 82.939% (7219/8704)/ 95.565% (8318/8704)
01/14/2023 13:55:04 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.686 | Acc: 82.892% (7321/8832)/ 95.584% (8442/8832)
01/14/2023 13:55:06 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.681 | Acc: 82.980% (7435/8960)/ 95.625% (8568/8960)
01/14/2023 13:55:09 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.683 | Acc: 82.912% (7535/9088)/ 95.621% (8690/9088)
01/14/2023 13:55:11 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.681 | Acc: 82.943% (7644/9216)/ 95.627% (8813/9216)
01/14/2023 13:55:14 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.683 | Acc: 82.834% (7740/9344)/ 95.634% (8936/9344)
01/14/2023 13:55:16 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.687 | Acc: 82.717% (7835/9472)/ 95.640% (9059/9472)
01/14/2023 13:55:19 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.688 | Acc: 82.688% (7938/9600)/ 95.615% (9179/9600)
01/14/2023 13:55:21 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.694 | Acc: 82.514% (8027/9728)/ 95.611% (9301/9728)
01/14/2023 13:55:24 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.693 | Acc: 82.498% (8131/9856)/ 95.607% (9423/9856)
01/14/2023 13:55:27 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.694 | Acc: 82.472% (8234/9984)/ 95.633% (9548/9984)
01/14/2023 13:55:29 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.694 | Acc: 82.358% (8328/10112)/ 95.669% (9674/10112)
01/14/2023 13:55:32 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.692 | Acc: 82.363% (8434/10240)/ 95.693% (9799/10240)
01/14/2023 13:55:34 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.692 | Acc: 82.330% (8536/10368)/ 95.698% (9922/10368)
01/14/2023 13:55:37 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.691 | Acc: 82.336% (8642/10496)/ 95.713% (10046/10496)
01/14/2023 13:55:40 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.691 | Acc: 82.351% (8749/10624)/ 95.708% (10168/10624)
01/14/2023 13:55:42 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.691 | Acc: 82.385% (8858/10752)/ 95.694% (10289/10752)
01/14/2023 13:55:45 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.687 | Acc: 82.491% (8975/10880)/ 95.726% (10415/10880)
01/14/2023 13:55:47 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.685 | Acc: 82.495% (9081/11008)/ 95.767% (10542/11008)
01/14/2023 13:55:50 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.689 | Acc: 82.426% (9179/11136)/ 95.744% (10662/11136)
01/14/2023 13:55:53 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.687 | Acc: 82.475% (9290/11264)/ 95.748% (10785/11264)
01/14/2023 13:55:55 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.694 | Acc: 82.426% (9390/11392)/ 95.681% (10900/11392)
01/14/2023 13:55:58 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.692 | Acc: 82.474% (9501/11520)/ 95.694% (11024/11520)
01/14/2023 13:56:00 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.693 | Acc: 82.392% (9597/11648)/ 95.699% (11147/11648)
01/14/2023 13:56:03 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.692 | Acc: 82.422% (9706/11776)/ 95.703% (11270/11776)
01/14/2023 13:56:06 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.693 | Acc: 82.401% (9809/11904)/ 95.674% (11389/11904)
01/14/2023 13:56:08 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.697 | Acc: 82.197% (9890/12032)/ 95.703% (11515/12032)
01/14/2023 13:56:11 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.699 | Acc: 82.072% (9980/12160)/ 95.715% (11639/12160)
01/14/2023 13:56:13 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.697 | Acc: 82.129% (10092/12288)/ 95.719% (11762/12288)
01/14/2023 13:56:16 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.700 | Acc: 82.023% (10184/12416)/ 95.731% (11886/12416)
01/14/2023 13:56:18 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.702 | Acc: 81.848% (10267/12544)/ 95.751% (12011/12544)
01/14/2023 13:56:21 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.698 | Acc: 81.952% (10385/12672)/ 95.778% (12137/12672)
01/14/2023 13:56:24 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.693 | Acc: 82.094% (10508/12800)/ 95.820% (12265/12800)
01/14/2023 13:56:26 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.692 | Acc: 82.147% (10620/12928)/ 95.838% (12390/12928)
01/14/2023 13:56:29 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.688 | Acc: 82.246% (10738/13056)/ 95.872% (12517/13056)
01/14/2023 13:56:31 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.684 | Acc: 82.365% (10859/13184)/ 95.897% (12643/13184)
01/14/2023 13:56:34 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.685 | Acc: 82.189% (10941/13312)/ 95.928% (12770/13312)
01/14/2023 13:56:36 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.685 | Acc: 82.128% (11038/13440)/ 95.923% (12892/13440)
01/14/2023 13:56:39 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.686 | Acc: 82.105% (11140/13568)/ 95.924% (13015/13568)
01/14/2023 13:56:41 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.694 | Acc: 81.987% (11229/13696)/ 95.860% (13129/13696)
01/14/2023 13:56:44 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.690 | Acc: 82.111% (11351/13824)/ 95.891% (13256/13824)
01/14/2023 13:56:46 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.693 | Acc: 81.981% (11438/13952)/ 95.893% (13379/13952)
01/14/2023 13:56:49 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.695 | Acc: 81.953% (11539/14080)/ 95.895% (13502/14080)
01/14/2023 13:56:51 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.697 | Acc: 81.771% (11618/14208)/ 95.904% (13626/14208)
01/14/2023 13:56:54 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.700 | Acc: 81.731% (11717/14336)/ 95.864% (13743/14336)
01/14/2023 13:56:57 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.701 | Acc: 81.755% (11825/14464)/ 95.879% (13868/14464)
01/14/2023 13:56:59 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.700 | Acc: 81.791% (11935/14592)/ 95.888% (13992/14592)
01/14/2023 13:57:02 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.697 | Acc: 81.882% (12053/14720)/ 95.917% (14119/14720)
01/14/2023 13:57:05 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.694 | Acc: 81.964% (12170/14848)/ 95.939% (14245/14848)
01/14/2023 13:57:07 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.697 | Acc: 81.931% (12270/14976)/ 95.907% (14363/14976)
01/14/2023 13:57:10 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.695 | Acc: 81.945% (12377/15104)/ 95.922% (14488/15104)
01/14/2023 13:57:13 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.699 | Acc: 81.841% (12466/15232)/ 95.936% (14613/15232)
01/14/2023 13:57:15 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.697 | Acc: 81.895% (12579/15360)/ 95.957% (14739/15360)
01/14/2023 13:57:18 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.695 | Acc: 81.934% (12690/15488)/ 95.971% (14864/15488)
01/14/2023 13:57:20 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.700 | Acc: 81.794% (12773/15616)/ 95.940% (14982/15616)
01/14/2023 13:57:23 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.702 | Acc: 81.739% (12869/15744)/ 95.910% (15100/15744)
01/14/2023 13:57:26 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.703 | Acc: 81.754% (12976/15872)/ 95.911% (15223/15872)
01/14/2023 13:57:28 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.702 | Acc: 81.769% (13083/16000)/ 95.925% (15348/16000)
01/14/2023 13:57:31 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.698 | Acc: 81.882% (13206/16128)/ 95.951% (15475/16128)
01/14/2023 13:57:34 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.694 | Acc: 81.976% (13326/16256)/ 95.965% (15600/16256)
01/14/2023 13:57:36 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.692 | Acc: 82.056% (13444/16384)/ 95.972% (15724/16384)
01/14/2023 13:57:39 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.693 | Acc: 82.043% (13547/16512)/ 95.948% (15843/16512)
01/14/2023 13:57:41 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.691 | Acc: 82.055% (13654/16640)/ 95.956% (15967/16640)
01/14/2023 13:57:44 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.688 | Acc: 82.151% (13775/16768)/ 95.974% (16093/16768)
01/14/2023 13:57:46 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.688 | Acc: 82.191% (13887/16896)/ 95.981% (16217/16896)
01/14/2023 13:57:49 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.685 | Acc: 82.254% (14003/17024)/ 95.994% (16342/17024)
01/14/2023 13:57:52 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.687 | Acc: 82.200% (14099/17152)/ 95.983% (16463/17152)
01/14/2023 13:57:54 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.685 | Acc: 82.234% (14210/17280)/ 96.007% (16590/17280)
01/14/2023 13:57:57 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.685 | Acc: 82.227% (14314/17408)/ 96.002% (16712/17408)
01/14/2023 13:58:00 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.683 | Acc: 82.185% (14412/17536)/ 96.025% (16839/17536)
01/14/2023 13:58:02 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.681 | Acc: 82.235% (14526/17664)/ 96.054% (16967/17664)
01/14/2023 13:58:05 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.680 | Acc: 82.262% (14636/17792)/ 96.066% (17092/17792)
01/14/2023 13:58:07 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.686 | Acc: 82.104% (14713/17920)/ 96.055% (17213/17920)
01/14/2023 13:58:10 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.688 | Acc: 82.026% (14804/18048)/ 96.049% (17335/18048)
01/14/2023 13:58:13 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.686 | Acc: 82.064% (14916/18176)/ 96.061% (17460/18176)
01/14/2023 13:58:15 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.684 | Acc: 82.141% (15035/18304)/ 96.077% (17586/18304)
01/14/2023 13:58:18 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.685 | Acc: 82.156% (15143/18432)/ 96.056% (17705/18432)
01/14/2023 13:58:20 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.687 | Acc: 82.128% (15243/18560)/ 96.024% (17822/18560)
01/14/2023 13:58:23 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.690 | Acc: 82.112% (15345/18688)/ 95.997% (17940/18688)
01/14/2023 13:58:25 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.691 | Acc: 82.090% (15446/18816)/ 95.977% (18059/18816)
01/14/2023 13:58:28 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.691 | Acc: 82.089% (15551/18944)/ 95.957% (18178/18944)
01/14/2023 13:58:30 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.693 | Acc: 82.026% (15644/19072)/ 95.947% (18299/19072)
01/14/2023 13:58:33 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.697 | Acc: 81.938% (15732/19200)/ 95.911% (18415/19200)
01/14/2023 13:58:36 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.697 | Acc: 81.871% (15824/19328)/ 95.918% (18539/19328)
01/14/2023 13:58:39 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.697 | Acc: 81.903% (15935/19456)/ 95.919% (18662/19456)
01/14/2023 13:58:41 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.698 | Acc: 81.893% (16038/19584)/ 95.910% (18783/19584)
01/14/2023 13:58:44 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.696 | Acc: 81.955% (16155/19712)/ 95.916% (18907/19712)
01/14/2023 13:58:46 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.696 | Acc: 81.941% (16257/19840)/ 95.892% (19025/19840)
01/14/2023 13:58:49 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.697 | Acc: 81.951% (16364/19968)/ 95.888% (19147/19968)
01/14/2023 13:58:51 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.699 | Acc: 81.867% (16452/20096)/ 95.865% (19265/20096)
01/14/2023 13:58:54 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.701 | Acc: 81.853% (16554/20224)/ 95.847% (19384/20224)
01/14/2023 13:58:56 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.702 | Acc: 81.820% (16652/20352)/ 95.819% (19501/20352)
01/14/2023 13:58:59 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.703 | Acc: 81.787% (16750/20480)/ 95.815% (19623/20480)
01/14/2023 13:59:01 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.704 | Acc: 81.760% (16849/20608)/ 95.803% (19743/20608)
01/14/2023 13:59:04 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.713 | Acc: 81.539% (16908/20736)/ 95.708% (19846/20736)
01/14/2023 13:59:07 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.719 | Acc: 81.432% (16990/20864)/ 95.648% (19956/20864)
01/14/2023 13:59:09 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.721 | Acc: 81.388% (17085/20992)/ 95.641% (20077/20992)
01/14/2023 13:59:12 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.721 | Acc: 81.378% (17187/21120)/ 95.658% (20203/21120)
01/14/2023 13:59:14 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.723 | Acc: 81.297% (17274/21248)/ 95.656% (20325/21248)
01/14/2023 13:59:17 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.723 | Acc: 81.306% (17380/21376)/ 95.640% (20444/21376)
01/14/2023 13:59:20 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.725 | Acc: 81.250% (17472/21504)/ 95.619% (20562/21504)
01/14/2023 13:59:22 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.724 | Acc: 81.255% (17577/21632)/ 95.618% (20684/21632)
01/14/2023 13:59:25 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.726 | Acc: 81.218% (17673/21760)/ 95.588% (20800/21760)
01/14/2023 13:59:27 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.731 | Acc: 81.104% (17752/21888)/ 95.550% (20914/21888)
01/14/2023 13:59:30 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.734 | Acc: 81.050% (17844/22016)/ 95.517% (21029/22016)
01/14/2023 13:59:33 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.735 | Acc: 81.006% (17938/22144)/ 95.520% (21152/22144)
01/14/2023 13:59:35 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.737 | Acc: 80.958% (18031/22272)/ 95.492% (21268/22272)
01/14/2023 13:59:38 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.741 | Acc: 80.866% (18114/22400)/ 95.451% (21381/22400)
01/14/2023 13:59:41 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.740 | Acc: 80.913% (18228/22528)/ 95.455% (21504/22528)
01/14/2023 13:59:43 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.740 | Acc: 80.906% (18330/22656)/ 95.436% (21622/22656)
01/14/2023 13:59:46 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.744 | Acc: 80.833% (18417/22784)/ 95.396% (21735/22784)
01/14/2023 13:59:48 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.745 | Acc: 80.809% (18515/22912)/ 95.365% (21850/22912)
01/14/2023 13:59:51 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.749 | Acc: 80.760% (18607/23040)/ 95.330% (21964/23040)
01/14/2023 13:59:53 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.755 | Acc: 80.633% (18681/23168)/ 95.291% (22077/23168)
01/14/2023 13:59:56 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.761 | Acc: 80.499% (18753/23296)/ 95.235% (22186/23296)
01/14/2023 13:59:59 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.760 | Acc: 80.511% (18859/23424)/ 95.236% (22308/23424)
01/14/2023 14:00:01 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.767 | Acc: 80.388% (18933/23552)/ 95.151% (22410/23552)
01/14/2023 14:00:04 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.766 | Acc: 80.410% (19041/23680)/ 95.135% (22528/23680)
01/14/2023 14:00:07 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.766 | Acc: 80.423% (19147/23808)/ 95.128% (22648/23808)
01/14/2023 14:00:09 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.769 | Acc: 80.381% (19240/23936)/ 95.095% (22762/23936)
01/14/2023 14:00:12 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.774 | Acc: 80.265% (19315/24064)/ 95.076% (22879/24064)
01/14/2023 14:00:14 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.777 | Acc: 80.134% (19386/24192)/ 95.056% (22996/24192)
01/14/2023 14:00:17 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.779 | Acc: 80.066% (19472/24320)/ 95.058% (23118/24320)
01/14/2023 14:00:19 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.784 | Acc: 79.978% (19553/24448)/ 95.030% (23233/24448)
01/14/2023 14:00:22 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.786 | Acc: 79.944% (19647/24576)/ 95.011% (23350/24576)
01/14/2023 14:00:25 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.792 | Acc: 79.833% (19722/24704)/ 94.928% (23451/24704)
01/14/2023 14:00:27 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.792 | Acc: 79.857% (19830/24832)/ 94.922% (23571/24832)
01/14/2023 14:00:30 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.794 | Acc: 79.800% (19918/24960)/ 94.904% (23688/24960)
01/14/2023 14:00:33 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.799 | Acc: 79.723% (20001/25088)/ 94.842% (23794/25088)
01/14/2023 14:00:35 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.803 | Acc: 79.616% (20076/25216)/ 94.801% (23905/25216)
01/14/2023 14:00:38 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.807 | Acc: 79.542% (20159/25344)/ 94.780% (24021/25344)
01/14/2023 14:00:40 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.809 | Acc: 79.507% (20252/25472)/ 94.747% (24134/25472)
01/14/2023 14:00:43 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.809 | Acc: 79.496% (20351/25600)/ 94.750% (24256/25600)
01/14/2023 14:00:46 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.809 | Acc: 79.458% (20443/25728)/ 94.749% (24377/25728)
01/14/2023 14:00:48 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.812 | Acc: 79.366% (20521/25856)/ 94.713% (24489/25856)
01/14/2023 14:00:51 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.813 | Acc: 79.349% (20618/25984)/ 94.704% (24608/25984)
01/14/2023 14:00:53 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.814 | Acc: 79.339% (20717/26112)/ 94.692% (24726/26112)
01/14/2023 14:00:56 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.817 | Acc: 79.245% (20794/26240)/ 94.672% (24842/26240)
01/14/2023 14:00:59 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.820 | Acc: 79.164% (20874/26368)/ 94.641% (24955/26368)
01/14/2023 14:01:01 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.821 | Acc: 79.140% (20969/26496)/ 94.637% (25075/26496)
01/14/2023 14:01:04 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.825 | Acc: 79.056% (21048/26624)/ 94.599% (25186/26624)
01/14/2023 14:01:06 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.827 | Acc: 79.018% (21139/26752)/ 94.576% (25301/26752)
01/14/2023 14:01:09 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.827 | Acc: 79.018% (21240/26880)/ 94.594% (25427/26880)
01/14/2023 14:01:12 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.828 | Acc: 79.003% (21337/27008)/ 94.576% (25543/27008)
01/14/2023 14:01:14 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.830 | Acc: 78.947% (21423/27136)/ 94.557% (25659/27136)
01/14/2023 14:01:17 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.832 | Acc: 78.899% (21511/27264)/ 94.535% (25774/27264)
01/14/2023 14:01:19 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.832 | Acc: 78.899% (21612/27392)/ 94.539% (25896/27392)
01/14/2023 14:01:22 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.832 | Acc: 78.874% (21706/27520)/ 94.539% (26017/27520)
01/14/2023 14:01:25 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.832 | Acc: 78.888% (21811/27648)/ 94.531% (26136/27648)
01/14/2023 14:01:27 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.830 | Acc: 78.928% (21923/27776)/ 94.549% (26262/27776)
01/14/2023 14:01:30 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.835 | Acc: 78.856% (22004/27904)/ 94.492% (26367/27904)
01/14/2023 14:01:32 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.838 | Acc: 78.803% (22090/28032)/ 94.456% (26478/28032)
01/14/2023 14:01:35 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.837 | Acc: 78.832% (22199/28160)/ 94.460% (26600/28160)
01/14/2023 14:01:38 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.835 | Acc: 78.867% (22310/28288)/ 94.478% (26726/28288)
01/14/2023 14:01:40 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.837 | Acc: 78.822% (22398/28416)/ 94.461% (26842/28416)
01/14/2023 14:01:43 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.835 | Acc: 78.878% (22515/28544)/ 94.475% (26967/28544)
01/14/2023 14:01:45 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.835 | Acc: 78.878% (22616/28672)/ 94.465% (27085/28672)
01/14/2023 14:01:48 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.835 | Acc: 78.896% (22722/28800)/ 94.458% (27204/28800)
01/14/2023 14:01:51 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.834 | Acc: 78.896% (22823/28928)/ 94.459% (27325/28928)
01/14/2023 14:01:53 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.834 | Acc: 78.872% (22917/29056)/ 94.469% (27449/29056)
01/14/2023 14:01:56 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.836 | Acc: 78.855% (23013/29184)/ 94.459% (27567/29184)
01/14/2023 14:01:58 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.841 | Acc: 78.783% (23093/29312)/ 94.398% (27670/29312)
01/14/2023 14:02:01 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.844 | Acc: 78.723% (23176/29440)/ 94.355% (27778/29440)
01/14/2023 14:02:04 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.847 | Acc: 78.666% (23260/29568)/ 94.315% (27887/29568)
01/14/2023 14:02:06 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.847 | Acc: 78.654% (23357/29696)/ 94.299% (28003/29696)
01/14/2023 14:02:09 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.846 | Acc: 78.682% (23466/29824)/ 94.313% (28128/29824)
01/14/2023 14:02:11 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.848 | Acc: 78.629% (23551/29952)/ 94.291% (28242/29952)
01/14/2023 14:02:14 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.854 | Acc: 78.511% (23616/30080)/ 94.219% (28341/30080)
01/14/2023 14:02:16 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.854 | Acc: 78.496% (23712/30208)/ 94.213% (28460/30208)
01/14/2023 14:02:19 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.853 | Acc: 78.540% (23826/30336)/ 94.221% (28583/30336)
01/14/2023 14:02:21 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.853 | Acc: 78.545% (23928/30464)/ 94.193% (28695/30464)
01/14/2023 14:02:24 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.852 | Acc: 78.586% (24041/30592)/ 94.201% (28818/30592)
01/14/2023 14:02:26 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.851 | Acc: 78.623% (24153/30720)/ 94.206% (28940/30720)
01/14/2023 14:02:29 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.851 | Acc: 78.640% (24259/30848)/ 94.194% (29057/30848)
01/14/2023 14:02:31 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.854 | Acc: 78.545% (24330/30976)/ 94.154% (29165/30976)
01/14/2023 14:02:34 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.856 | Acc: 78.440% (24398/31104)/ 94.133% (29279/31104)
01/14/2023 14:02:37 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.862 | Acc: 78.308% (24457/31232)/ 94.067% (29379/31232)
01/14/2023 14:02:39 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.862 | Acc: 78.316% (24560/31360)/ 94.062% (29498/31360)
01/14/2023 14:02:42 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.862 | Acc: 78.331% (24665/31488)/ 94.055% (29616/31488)
01/14/2023 14:02:45 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.862 | Acc: 78.305% (24757/31616)/ 94.044% (29733/31616)
01/14/2023 14:02:47 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.868 | Acc: 78.213% (24828/31744)/ 93.971% (29830/31744)
01/14/2023 14:02:50 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.869 | Acc: 78.172% (24915/31872)/ 93.957% (29946/31872)
01/14/2023 14:02:53 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.871 | Acc: 78.044% (24974/32000)/ 93.947% (30063/32000)
01/14/2023 14:02:55 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.869 | Acc: 78.078% (25085/32128)/ 93.962% (30188/32128)
01/14/2023 14:02:58 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.872 | Acc: 78.047% (25175/32256)/ 93.933% (30299/32256)
01/14/2023 14:03:01 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.871 | Acc: 78.073% (25283/32384)/ 93.926% (30417/32384)
01/14/2023 14:03:04 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.872 | Acc: 78.048% (25375/32512)/ 93.913% (30533/32512)
01/14/2023 14:03:06 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.876 | Acc: 77.981% (25453/32640)/ 93.866% (30638/32640)
01/14/2023 14:03:09 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.879 | Acc: 77.945% (25541/32768)/ 93.857% (30755/32768)
01/14/2023 14:03:11 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.884 | Acc: 77.830% (25603/32896)/ 93.820% (30863/32896)
01/14/2023 14:03:14 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.884 | Acc: 77.816% (25698/33024)/ 93.808% (30979/33024)
01/14/2023 14:03:17 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.885 | Acc: 77.802% (25793/33152)/ 93.795% (31095/33152)
01/14/2023 14:03:19 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.889 | Acc: 77.677% (25851/33280)/ 93.783% (31211/33280)
01/14/2023 14:03:22 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.890 | Acc: 77.646% (25940/33408)/ 93.777% (31329/33408)
01/14/2023 14:03:25 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.888 | Acc: 77.693% (26055/33536)/ 93.798% (31456/33536)
01/14/2023 14:03:27 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.887 | Acc: 77.715% (26162/33664)/ 93.803% (31578/33664)
01/14/2023 14:03:30 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.889 | Acc: 77.646% (26238/33792)/ 93.777% (31689/33792)
01/14/2023 14:03:32 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.895 | Acc: 77.588% (26318/33920)/ 93.715% (31788/33920)
01/14/2023 14:03:35 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.894 | Acc: 77.617% (26427/34048)/ 93.712% (31907/34048)
01/14/2023 14:03:37 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.896 | Acc: 77.546% (26502/34176)/ 93.694% (32021/34176)
01/14/2023 14:03:40 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.896 | Acc: 77.577% (26612/34304)/ 93.695% (32141/34304)
01/14/2023 14:03:43 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.895 | Acc: 77.596% (26718/34432)/ 93.689% (32259/34432)
01/14/2023 14:03:45 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.897 | Acc: 77.546% (26800/34560)/ 93.669% (32372/34560)
01/14/2023 14:03:48 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.900 | Acc: 77.482% (26877/34688)/ 93.638% (32481/34688)
01/14/2023 14:03:50 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.900 | Acc: 77.496% (26981/34816)/ 93.632% (32599/34816)
01/14/2023 14:03:53 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.901 | Acc: 77.455% (27066/34944)/ 93.627% (32717/34944)
01/14/2023 14:03:55 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.902 | Acc: 77.464% (27168/35072)/ 93.616% (32833/35072)
01/14/2023 14:03:58 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.901 | Acc: 77.469% (27269/35200)/ 93.622% (32955/35200)
01/14/2023 14:04:01 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.903 | Acc: 77.440% (27358/35328)/ 93.617% (33073/35328)
01/14/2023 14:04:03 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.904 | Acc: 77.392% (27440/35456)/ 93.615% (33192/35456)
01/14/2023 14:04:06 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.905 | Acc: 77.358% (27527/35584)/ 93.601% (33307/35584)
01/14/2023 14:04:09 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.905 | Acc: 77.363% (27628/35712)/ 93.599% (33426/35712)
01/14/2023 14:04:11 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.905 | Acc: 77.374% (27731/35840)/ 93.594% (33544/35840)
01/14/2023 14:04:14 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.906 | Acc: 77.355% (27823/35968)/ 93.586% (33661/35968)
01/14/2023 14:04:17 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.906 | Acc: 77.369% (27927/36096)/ 93.581% (33779/36096)
01/14/2023 14:04:19 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.905 | Acc: 77.404% (28039/36224)/ 93.584% (33900/36224)
01/14/2023 14:04:22 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.906 | Acc: 77.380% (28129/36352)/ 93.579% (34018/36352)
01/14/2023 14:04:25 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.909 | Acc: 77.330% (28210/36480)/ 93.547% (34126/36480)
01/14/2023 14:04:27 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.912 | Acc: 77.289% (28294/36608)/ 93.501% (34229/36608)
01/14/2023 14:04:30 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.913 | Acc: 77.257% (28381/36736)/ 93.491% (34345/36736)
01/14/2023 14:04:33 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.913 | Acc: 77.257% (28480/36864)/ 93.487% (34463/36864)
01/14/2023 14:04:35 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.912 | Acc: 77.276% (28586/36992)/ 93.490% (34584/36992)
01/14/2023 14:04:38 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.914 | Acc: 77.236% (28670/37120)/ 93.456% (34691/37120)
01/14/2023 14:04:41 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.915 | Acc: 77.161% (28741/37248)/ 93.457% (34811/37248)
01/14/2023 14:04:43 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.915 | Acc: 77.170% (28843/37376)/ 93.453% (34929/37376)
01/14/2023 14:04:46 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.917 | Acc: 77.117% (28922/37504)/ 93.435% (35042/37504)
01/14/2023 14:04:48 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.917 | Acc: 77.105% (29016/37632)/ 93.431% (35160/37632)
01/14/2023 14:04:51 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.918 | Acc: 77.084% (29107/37760)/ 93.427% (35278/37760)
01/14/2023 14:04:53 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.917 | Acc: 77.117% (29218/37888)/ 93.433% (35400/37888)
01/14/2023 14:04:56 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.917 | Acc: 77.115% (29316/38016)/ 93.424% (35516/38016)
01/14/2023 14:04:59 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.919 | Acc: 77.089% (29405/38144)/ 93.401% (35627/38144)
01/14/2023 14:05:01 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.921 | Acc: 77.062% (29493/38272)/ 93.376% (35737/38272)
01/14/2023 14:05:04 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.922 | Acc: 77.052% (29588/38400)/ 93.354% (35848/38400)
01/14/2023 14:05:07 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.923 | Acc: 77.056% (29688/38528)/ 93.348% (35965/38528)
01/14/2023 14:05:09 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.923 | Acc: 77.041% (29781/38656)/ 93.331% (36078/38656)
01/14/2023 14:05:12 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.925 | Acc: 77.006% (29866/38784)/ 93.317% (36192/38784)
01/14/2023 14:05:15 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.926 | Acc: 76.979% (29954/38912)/ 93.303% (36306/38912)
01/14/2023 14:05:17 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.925 | Acc: 76.998% (30060/39040)/ 93.307% (36427/39040)
01/14/2023 14:05:20 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.926 | Acc: 76.953% (30141/39168)/ 93.301% (36544/39168)
01/14/2023 14:05:22 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.927 | Acc: 76.937% (30233/39296)/ 93.277% (36654/39296)
01/14/2023 14:05:25 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.928 | Acc: 76.933% (30330/39424)/ 93.258% (36766/39424)
01/14/2023 14:05:28 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.928 | Acc: 76.919% (30423/39552)/ 93.249% (36882/39552)
01/14/2023 14:05:30 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.929 | Acc: 76.915% (30520/39680)/ 93.231% (36994/39680)
01/14/2023 14:05:33 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.930 | Acc: 76.912% (30617/39808)/ 93.217% (37108/39808)
01/14/2023 14:05:35 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.932 | Acc: 76.881% (30703/39936)/ 93.207% (37223/39936)
01/14/2023 14:05:38 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.933 | Acc: 76.862% (30794/40064)/ 93.186% (37334/40064)
01/14/2023 14:05:41 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.931 | Acc: 76.901% (30908/40192)/ 93.203% (37460/40192)
01/14/2023 14:05:43 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.932 | Acc: 76.897% (31005/40320)/ 93.199% (37578/40320)
01/14/2023 14:05:46 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.933 | Acc: 76.876% (31095/40448)/ 93.186% (37692/40448)
01/14/2023 14:05:48 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.935 | Acc: 76.784% (31156/40576)/ 93.161% (37801/40576)
01/14/2023 14:05:51 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.937 | Acc: 76.739% (31236/40704)/ 93.138% (37911/40704)
01/14/2023 14:05:53 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.936 | Acc: 76.771% (31347/40832)/ 93.155% (38037/40832)
01/14/2023 14:05:56 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.938 | Acc: 76.716% (31423/40960)/ 93.123% (38143/40960)
01/14/2023 14:05:59 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.937 | Acc: 76.755% (31537/41088)/ 93.132% (38266/41088)
01/14/2023 14:06:01 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.937 | Acc: 76.771% (31642/41216)/ 93.126% (38383/41216)
01/14/2023 14:06:04 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.938 | Acc: 76.746% (31730/41344)/ 93.121% (38500/41344)
01/14/2023 14:06:07 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.940 | Acc: 76.712% (31814/41472)/ 93.097% (38609/41472)
01/14/2023 14:06:09 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.941 | Acc: 76.707% (31910/41600)/ 93.089% (38725/41600)
01/14/2023 14:06:12 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.940 | Acc: 76.711% (32010/41728)/ 93.086% (38843/41728)
01/14/2023 14:06:14 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.944 | Acc: 76.632% (32075/41856)/ 93.057% (38950/41856)
01/14/2023 14:06:17 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.947 | Acc: 76.548% (32138/41984)/ 93.028% (39057/41984)
01/14/2023 14:06:19 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.949 | Acc: 76.503% (32217/42112)/ 93.007% (39167/42112)
01/14/2023 14:06:22 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.949 | Acc: 76.499% (32313/42240)/ 93.004% (39285/42240)
01/14/2023 14:06:24 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.951 | Acc: 76.456% (32393/42368)/ 92.978% (39393/42368)
01/14/2023 14:06:27 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.951 | Acc: 76.421% (32476/42496)/ 92.992% (39518/42496)
01/14/2023 14:06:29 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.951 | Acc: 76.415% (32571/42624)/ 92.992% (39637/42624)
01/14/2023 14:06:32 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.950 | Acc: 76.446% (32682/42752)/ 93.001% (39760/42752)
01/14/2023 14:06:35 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.951 | Acc: 76.413% (32766/42880)/ 92.980% (39870/42880)
01/14/2023 14:06:37 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.952 | Acc: 76.393% (32855/43008)/ 92.969% (39984/43008)
01/14/2023 14:06:40 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.954 | Acc: 76.347% (32933/43136)/ 92.955% (40097/43136)
01/14/2023 14:06:43 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.954 | Acc: 76.338% (33027/43264)/ 92.950% (40214/43264)
01/14/2023 14:06:45 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.954 | Acc: 76.325% (33119/43392)/ 92.960% (40337/43392)
01/14/2023 14:06:48 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.957 | Acc: 76.294% (33203/43520)/ 92.937% (40446/43520)
01/14/2023 14:06:50 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.956 | Acc: 76.285% (33297/43648)/ 92.946% (40569/43648)
01/14/2023 14:06:53 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.955 | Acc: 76.325% (33412/43776)/ 92.964% (40696/43776)
01/14/2023 14:06:55 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.955 | Acc: 76.273% (33487/43904)/ 92.957% (40812/43904)
01/14/2023 14:06:58 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.955 | Acc: 76.274% (33585/44032)/ 92.962% (40933/44032)
01/14/2023 14:07:01 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.956 | Acc: 76.270% (33681/44160)/ 92.951% (41047/44160)
01/14/2023 14:07:03 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.959 | Acc: 76.203% (33749/44288)/ 92.908% (41147/44288)
01/14/2023 14:07:06 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.961 | Acc: 76.187% (33839/44416)/ 92.892% (41259/44416)
01/14/2023 14:07:09 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.960 | Acc: 76.201% (33943/44544)/ 92.901% (41382/44544)
01/14/2023 14:07:11 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.962 | Acc: 76.175% (34029/44672)/ 92.875% (41489/44672)
01/14/2023 14:07:14 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.961 | Acc: 76.174% (34126/44800)/ 92.882% (41611/44800)
01/14/2023 14:07:17 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.961 | Acc: 76.189% (34230/44928)/ 92.880% (41729/44928)
01/14/2023 14:07:19 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.963 | Acc: 76.134% (34303/45056)/ 92.862% (41840/45056)
01/14/2023 14:07:22 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.964 | Acc: 76.133% (34400/45184)/ 92.858% (41957/45184)
01/14/2023 14:07:24 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.966 | Acc: 76.092% (34479/45312)/ 92.821% (42059/45312)
01/14/2023 14:07:27 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.968 | Acc: 76.034% (34550/45440)/ 92.801% (42169/45440)
01/14/2023 14:07:30 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.971 | Acc: 75.970% (34618/45568)/ 92.793% (42284/45568)
01/14/2023 14:07:32 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.971 | Acc: 75.963% (34712/45696)/ 92.794% (42403/45696)
01/14/2023 14:07:35 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.970 | Acc: 75.997% (34825/45824)/ 92.807% (42528/45824)
01/14/2023 14:07:37 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.969 | Acc: 76.025% (34935/45952)/ 92.810% (42648/45952)
01/14/2023 14:07:40 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.969 | Acc: 76.033% (35036/46080)/ 92.806% (42765/46080)
01/14/2023 14:07:43 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.971 | Acc: 76.002% (35119/46208)/ 92.796% (42879/46208)
01/14/2023 14:07:45 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.971 | Acc: 75.999% (35215/46336)/ 92.800% (43000/46336)
01/14/2023 14:07:48 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.971 | Acc: 75.999% (35312/46464)/ 92.814% (43125/46464)
01/14/2023 14:07:50 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.971 | Acc: 75.992% (35406/46592)/ 92.803% (43239/46592)
01/14/2023 14:07:53 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.970 | Acc: 76.019% (35516/46720)/ 92.815% (43363/46720)
01/14/2023 14:07:56 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.970 | Acc: 76.035% (35621/46848)/ 92.821% (43485/46848)
01/14/2023 14:07:58 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.968 | Acc: 76.073% (35736/46976)/ 92.839% (43612/46976)
01/14/2023 14:08:01 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.967 | Acc: 76.095% (35844/47104)/ 92.852% (43737/47104)
01/14/2023 14:08:04 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.967 | Acc: 76.101% (35944/47232)/ 92.859% (43859/47232)
01/14/2023 14:08:06 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.966 | Acc: 76.119% (36050/47360)/ 92.867% (43982/47360)
01/14/2023 14:08:09 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.966 | Acc: 76.103% (36140/47488)/ 92.870% (44102/47488)
01/14/2023 14:08:11 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.966 | Acc: 76.107% (36239/47616)/ 92.874% (44223/47616)
01/14/2023 14:08:14 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.964 | Acc: 76.152% (36358/47744)/ 92.889% (44349/47744)
01/14/2023 14:08:16 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.963 | Acc: 76.189% (36473/47872)/ 92.898% (44472/47872)
01/14/2023 14:08:19 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.962 | Acc: 76.217% (36584/48000)/ 92.904% (44594/48000)
01/14/2023 14:08:22 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.964 | Acc: 76.153% (36651/48128)/ 92.869% (44696/48128)
01/14/2023 14:08:24 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.965 | Acc: 76.148% (36746/48256)/ 92.855% (44808/48256)
01/14/2023 14:08:27 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.965 | Acc: 76.131% (36835/48384)/ 92.849% (44924/48384)
01/14/2023 14:08:30 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.969 | Acc: 76.057% (36897/48512)/ 92.812% (45025/48512)
01/14/2023 14:08:32 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.969 | Acc: 76.038% (36985/48640)/ 92.821% (45148/48640)
01/14/2023 14:08:35 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.969 | Acc: 76.036% (37081/48768)/ 92.831% (45272/48768)
01/14/2023 14:08:38 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.970 | Acc: 75.992% (37157/48896)/ 92.828% (45389/48896)
01/14/2023 14:08:40 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.972 | Acc: 75.957% (37237/49024)/ 92.816% (45502/49024)
01/14/2023 14:08:43 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.972 | Acc: 75.966% (37339/49152)/ 92.816% (45621/49152)
01/14/2023 14:08:45 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.970 | Acc: 76.006% (37456/49280)/ 92.829% (45746/49280)
01/14/2023 14:08:48 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.969 | Acc: 76.016% (37558/49408)/ 92.839% (45870/49408)
01/14/2023 14:08:51 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.967 | Acc: 76.062% (37678/49536)/ 92.856% (45997/49536)
01/14/2023 14:08:53 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.965 | Acc: 76.101% (37795/49664)/ 92.866% (46121/49664)
01/14/2023 14:08:56 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.964 | Acc: 76.147% (37915/49792)/ 92.878% (46246/49792)
01/14/2023 14:08:58 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.963 | Acc: 76.152% (38015/49920)/ 92.879% (46365/49920)
01/14/2023 14:09:01 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.965 | Acc: 76.106% (38053/50000)/ 92.870% (46435/50000)
01/14/2023 14:09:01 - INFO - __main__ -   Final accuracy: 76.106
