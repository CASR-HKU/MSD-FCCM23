/home/jjc/miniconda3/envs/ant_quant/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb2', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:43:48 - INFO - __main__ -   output/resnet50_imagenet/int_W8A8_61717/gpu_0
01/13/2023 15:43:48 - INFO - __main__ -   Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb2', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:43:48 - INFO - __main__ -   ==> Preparing data..
01/13/2023 15:43:50 - INFO - __main__ -   ==> Setting quantizer..
Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb2', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:43:50 - INFO - __main__ -   Namespace(a_low=75, a_up=150, abit=8, batch_size=128, ckpt_path=None, dataset='imagenet', dataset_path='/home/mnt/data/imagenet', disable_input_quantization=False, disable_quant=False, eb='csd_eb2', epoch=3, layer_4bit_l=None, layer_8bit_l=None, layer_8bit_n=0, local_rank=0, lr=0.0005, mode='int', model='resnet50', percent=100, ptq=False, resume=False, search=False, tag='', train=True, w_low=75, w_up=150, wbit=8)
01/13/2023 15:43:50 - INFO - __main__ -   ==> Building model..
ResNet(
  (conv1): Conv2dQuantizer(
    (quant_weight): TensorQuantizer()
    (quant_input): TensorQuantizer()
  )
  (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2dQuantizer(
          (quant_weight): TensorQuantizer()
          (quant_input): TensorQuantizer()
        )
        (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2dQuantizer(
        (quant_weight): TensorQuantizer()
        (quant_input): TensorQuantizer()
      )
      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): LinearQuantizer(
    (quant_weight): TensorQuantizer()
    (quant_input): TensorQuantizer()
  )
)
01/13/2023 15:43:51 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00025]}
01/13/2023 15:43:51 - INFO - __main__ -   
Epoch: 0
Layer quant EB csd_eb2
int	8-bit 	 conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer1.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer1.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.3.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.3.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer2.3.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer2.3.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.3.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.3.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.3.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.3.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.4.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.4.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.4.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.4.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.5.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.5.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer3.5.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer3.5.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.0.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.0.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.0.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.0.downsample.0.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.0.downsample.0.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.1.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.1.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.1.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.1.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.2.conv1.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv1.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.2.conv2.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv2.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 layer4.2.conv3.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 layer4.2.conv3.quant_input,
set init to 1
Layer quant EB csd_eb2
int	8-bit 	 fc.quant_weight,
set init to 1
Layer quant EB abit-1
int	8-bit 	 fc.quant_input,
set init to 1
01/13/2023 15:44:29 - INFO - __main__ -   test: [epoch: 0 | batch: 0/10010 ] | Loss: 0.683 | Acc: 82.031% (105/128)
01/13/2023 15:46:47 - INFO - __main__ -   test: [epoch: 0 | batch: 100/10010 ] | Loss: 0.843 | Acc: 79.069% (10222/12928)
01/13/2023 15:51:04 - INFO - __main__ -   test: [epoch: 0 | batch: 200/10010 ] | Loss: 0.828 | Acc: 79.291% (20400/25728)
01/13/2023 15:55:25 - INFO - __main__ -   test: [epoch: 0 | batch: 300/10010 ] | Loss: 0.841 | Acc: 79.054% (30458/38528)
01/13/2023 15:59:46 - INFO - __main__ -   test: [epoch: 0 | batch: 400/10010 ] | Loss: 0.852 | Acc: 78.768% (40430/51328)
01/13/2023 16:04:06 - INFO - __main__ -   test: [epoch: 0 | batch: 500/10010 ] | Loss: 0.854 | Acc: 78.652% (50438/64128)
01/13/2023 16:08:27 - INFO - __main__ -   test: [epoch: 0 | batch: 600/10010 ] | Loss: 0.855 | Acc: 78.632% (60490/76928)
01/13/2023 16:12:47 - INFO - __main__ -   test: [epoch: 0 | batch: 700/10010 ] | Loss: 0.855 | Acc: 78.667% (70586/89728)
01/13/2023 16:17:07 - INFO - __main__ -   test: [epoch: 0 | batch: 800/10010 ] | Loss: 0.857 | Acc: 78.615% (80602/102528)
01/13/2023 16:21:27 - INFO - __main__ -   test: [epoch: 0 | batch: 900/10010 ] | Loss: 0.858 | Acc: 78.612% (90662/115328)
01/13/2023 16:25:48 - INFO - __main__ -   test: [epoch: 0 | batch: 1000/10010 ] | Loss: 0.859 | Acc: 78.598% (100706/128128)
01/13/2023 16:30:09 - INFO - __main__ -   test: [epoch: 0 | batch: 1100/10010 ] | Loss: 0.861 | Acc: 78.605% (110776/140928)
01/13/2023 16:34:32 - INFO - __main__ -   test: [epoch: 0 | batch: 1200/10010 ] | Loss: 0.862 | Acc: 78.574% (120790/153728)
01/13/2023 16:38:53 - INFO - __main__ -   test: [epoch: 0 | batch: 1300/10010 ] | Loss: 0.860 | Acc: 78.624% (130931/166528)
01/13/2023 16:43:15 - INFO - __main__ -   test: [epoch: 0 | batch: 1400/10010 ] | Loss: 0.861 | Acc: 78.630% (141005/179328)
01/13/2023 16:47:35 - INFO - __main__ -   test: [epoch: 0 | batch: 1500/10010 ] | Loss: 0.860 | Acc: 78.675% (151157/192128)
01/13/2023 16:51:58 - INFO - __main__ -   test: [epoch: 0 | batch: 1600/10010 ] | Loss: 0.860 | Acc: 78.662% (161201/204928)
01/13/2023 16:56:19 - INFO - __main__ -   test: [epoch: 0 | batch: 1700/10010 ] | Loss: 0.861 | Acc: 78.659% (171263/217728)
01/13/2023 17:00:39 - INFO - __main__ -   test: [epoch: 0 | batch: 1800/10010 ] | Loss: 0.859 | Acc: 78.700% (181426/230528)
01/13/2023 17:05:02 - INFO - __main__ -   test: [epoch: 0 | batch: 1900/10010 ] | Loss: 0.857 | Acc: 78.702% (191503/243328)
01/13/2023 17:09:22 - INFO - __main__ -   test: [epoch: 0 | batch: 2000/10010 ] | Loss: 0.857 | Acc: 78.704% (201582/256128)
01/13/2023 17:13:43 - INFO - __main__ -   test: [epoch: 0 | batch: 2100/10010 ] | Loss: 0.858 | Acc: 78.688% (211613/268928)
01/13/2023 17:18:04 - INFO - __main__ -   test: [epoch: 0 | batch: 2200/10010 ] | Loss: 0.858 | Acc: 78.672% (221640/281728)
01/13/2023 17:22:25 - INFO - __main__ -   test: [epoch: 0 | batch: 2300/10010 ] | Loss: 0.859 | Acc: 78.664% (231687/294528)
01/13/2023 17:26:47 - INFO - __main__ -   test: [epoch: 0 | batch: 2400/10010 ] | Loss: 0.859 | Acc: 78.666% (241763/307328)
01/13/2023 17:31:09 - INFO - __main__ -   test: [epoch: 0 | batch: 2500/10010 ] | Loss: 0.859 | Acc: 78.668% (251837/320128)
01/13/2023 17:35:29 - INFO - __main__ -   test: [epoch: 0 | batch: 2600/10010 ] | Loss: 0.860 | Acc: 78.670% (261913/332928)
01/13/2023 17:39:49 - INFO - __main__ -   test: [epoch: 0 | batch: 2700/10010 ] | Loss: 0.859 | Acc: 78.671% (271986/345728)
01/13/2023 17:44:09 - INFO - __main__ -   test: [epoch: 0 | batch: 2800/10010 ] | Loss: 0.859 | Acc: 78.659% (282015/358528)
01/13/2023 17:48:31 - INFO - __main__ -   test: [epoch: 0 | batch: 2900/10010 ] | Loss: 0.859 | Acc: 78.651% (292055/371328)
01/13/2023 17:52:52 - INFO - __main__ -   test: [epoch: 0 | batch: 3000/10010 ] | Loss: 0.859 | Acc: 78.651% (302120/384128)
01/13/2023 17:57:11 - INFO - __main__ -   test: [epoch: 0 | batch: 3100/10010 ] | Loss: 0.859 | Acc: 78.655% (312202/396928)
01/13/2023 18:01:33 - INFO - __main__ -   test: [epoch: 0 | batch: 3200/10010 ] | Loss: 0.859 | Acc: 78.652% (322261/409728)
01/13/2023 18:05:55 - INFO - __main__ -   test: [epoch: 0 | batch: 3300/10010 ] | Loss: 0.860 | Acc: 78.634% (332251/422528)
01/13/2023 18:10:16 - INFO - __main__ -   test: [epoch: 0 | batch: 3400/10010 ] | Loss: 0.860 | Acc: 78.643% (342356/435328)
01/13/2023 18:14:38 - INFO - __main__ -   test: [epoch: 0 | batch: 3500/10010 ] | Loss: 0.859 | Acc: 78.647% (352441/448128)
01/13/2023 18:18:59 - INFO - __main__ -   test: [epoch: 0 | batch: 3600/10010 ] | Loss: 0.859 | Acc: 78.640% (362472/460928)
01/13/2023 18:23:19 - INFO - __main__ -   test: [epoch: 0 | batch: 3700/10010 ] | Loss: 0.860 | Acc: 78.622% (372455/473728)
01/13/2023 18:27:42 - INFO - __main__ -   test: [epoch: 0 | batch: 3800/10010 ] | Loss: 0.860 | Acc: 78.621% (382515/486528)
01/13/2023 18:32:03 - INFO - __main__ -   test: [epoch: 0 | batch: 3900/10010 ] | Loss: 0.860 | Acc: 78.604% (392493/499328)
01/13/2023 18:36:23 - INFO - __main__ -   test: [epoch: 0 | batch: 4000/10010 ] | Loss: 0.860 | Acc: 78.600% (402531/512128)
01/13/2023 18:40:42 - INFO - __main__ -   test: [epoch: 0 | batch: 4100/10010 ] | Loss: 0.860 | Acc: 78.598% (412585/524928)
01/13/2023 18:45:02 - INFO - __main__ -   test: [epoch: 0 | batch: 4200/10010 ] | Loss: 0.861 | Acc: 78.594% (422623/537728)
01/13/2023 18:49:23 - INFO - __main__ -   test: [epoch: 0 | batch: 4300/10010 ] | Loss: 0.861 | Acc: 78.594% (432680/550528)
01/13/2023 18:53:43 - INFO - __main__ -   test: [epoch: 0 | batch: 4400/10010 ] | Loss: 0.860 | Acc: 78.603% (442795/563328)
01/13/2023 18:58:03 - INFO - __main__ -   test: [epoch: 0 | batch: 4500/10010 ] | Loss: 0.860 | Acc: 78.592% (452790/576128)
01/13/2023 19:02:25 - INFO - __main__ -   test: [epoch: 0 | batch: 4600/10010 ] | Loss: 0.860 | Acc: 78.596% (462876/588928)
01/13/2023 19:06:46 - INFO - __main__ -   test: [epoch: 0 | batch: 4700/10010 ] | Loss: 0.860 | Acc: 78.593% (472916/601728)
01/13/2023 19:11:07 - INFO - __main__ -   test: [epoch: 0 | batch: 4800/10010 ] | Loss: 0.860 | Acc: 78.591% (482962/614528)
01/13/2023 19:15:28 - INFO - __main__ -   test: [epoch: 0 | batch: 4900/10010 ] | Loss: 0.860 | Acc: 78.592% (493032/627328)
01/13/2023 19:19:50 - INFO - __main__ -   test: [epoch: 0 | batch: 5000/10010 ] | Loss: 0.860 | Acc: 78.604% (503169/640128)
01/13/2023 19:24:11 - INFO - __main__ -   test: [epoch: 0 | batch: 5100/10010 ] | Loss: 0.860 | Acc: 78.608% (513252/652928)
01/13/2023 19:28:31 - INFO - __main__ -   test: [epoch: 0 | batch: 5200/10010 ] | Loss: 0.860 | Acc: 78.603% (523283/665728)
01/13/2023 19:32:52 - INFO - __main__ -   test: [epoch: 0 | batch: 5300/10010 ] | Loss: 0.860 | Acc: 78.609% (533382/678528)
01/13/2023 19:37:14 - INFO - __main__ -   test: [epoch: 0 | batch: 5400/10010 ] | Loss: 0.860 | Acc: 78.599% (543374/691328)
01/13/2023 19:41:35 - INFO - __main__ -   test: [epoch: 0 | batch: 5500/10010 ] | Loss: 0.861 | Acc: 78.588% (553362/704128)
01/13/2023 19:45:55 - INFO - __main__ -   test: [epoch: 0 | batch: 5600/10010 ] | Loss: 0.860 | Acc: 78.597% (563482/716928)
01/13/2023 19:50:14 - INFO - __main__ -   test: [epoch: 0 | batch: 5700/10010 ] | Loss: 0.860 | Acc: 78.601% (573571/729728)
01/13/2023 19:54:34 - INFO - __main__ -   test: [epoch: 0 | batch: 5800/10010 ] | Loss: 0.860 | Acc: 78.601% (583635/742528)
01/13/2023 19:58:54 - INFO - __main__ -   test: [epoch: 0 | batch: 5900/10010 ] | Loss: 0.860 | Acc: 78.603% (593708/755328)
01/13/2023 20:03:14 - INFO - __main__ -   test: [epoch: 0 | batch: 6000/10010 ] | Loss: 0.860 | Acc: 78.598% (603737/768128)
01/13/2023 20:07:35 - INFO - __main__ -   test: [epoch: 0 | batch: 6100/10010 ] | Loss: 0.860 | Acc: 78.596% (613781/780928)
01/13/2023 20:11:56 - INFO - __main__ -   test: [epoch: 0 | batch: 6200/10010 ] | Loss: 0.861 | Acc: 78.587% (623769/793728)
01/13/2023 20:16:18 - INFO - __main__ -   test: [epoch: 0 | batch: 6300/10010 ] | Loss: 0.861 | Acc: 78.586% (633815/806528)
01/13/2023 20:20:38 - INFO - __main__ -   test: [epoch: 0 | batch: 6400/10010 ] | Loss: 0.861 | Acc: 78.582% (643847/819328)
01/13/2023 20:25:00 - INFO - __main__ -   test: [epoch: 0 | batch: 6500/10010 ] | Loss: 0.861 | Acc: 78.581% (653895/832128)
01/13/2023 20:29:21 - INFO - __main__ -   test: [epoch: 0 | batch: 6600/10010 ] | Loss: 0.861 | Acc: 78.578% (663929/844928)
01/13/2023 20:33:44 - INFO - __main__ -   test: [epoch: 0 | batch: 6700/10010 ] | Loss: 0.861 | Acc: 78.581% (674012/857728)
01/13/2023 20:38:06 - INFO - __main__ -   test: [epoch: 0 | batch: 6800/10010 ] | Loss: 0.861 | Acc: 78.578% (684043/870528)
01/13/2023 20:42:27 - INFO - __main__ -   test: [epoch: 0 | batch: 6900/10010 ] | Loss: 0.861 | Acc: 78.583% (694143/883328)
01/13/2023 20:46:48 - INFO - __main__ -   test: [epoch: 0 | batch: 7000/10010 ] | Loss: 0.861 | Acc: 78.578% (704162/896128)
01/13/2023 20:51:10 - INFO - __main__ -   test: [epoch: 0 | batch: 7100/10010 ] | Loss: 0.861 | Acc: 78.586% (714294/908928)
01/13/2023 20:55:33 - INFO - __main__ -   test: [epoch: 0 | batch: 7200/10010 ] | Loss: 0.860 | Acc: 78.594% (724422/921728)
01/13/2023 20:59:56 - INFO - __main__ -   test: [epoch: 0 | batch: 7300/10010 ] | Loss: 0.861 | Acc: 78.586% (734408/934528)
01/13/2023 21:04:19 - INFO - __main__ -   test: [epoch: 0 | batch: 7400/10010 ] | Loss: 0.861 | Acc: 78.580% (744410/947328)
01/13/2023 21:08:41 - INFO - __main__ -   test: [epoch: 0 | batch: 7500/10010 ] | Loss: 0.861 | Acc: 78.582% (754485/960128)
01/13/2023 21:13:03 - INFO - __main__ -   test: [epoch: 0 | batch: 7600/10010 ] | Loss: 0.861 | Acc: 78.582% (764548/972928)
01/13/2023 21:17:23 - INFO - __main__ -   test: [epoch: 0 | batch: 7700/10010 ] | Loss: 0.861 | Acc: 78.573% (774520/985728)
01/13/2023 21:21:45 - INFO - __main__ -   test: [epoch: 0 | batch: 7800/10010 ] | Loss: 0.861 | Acc: 78.571% (784557/998528)
01/13/2023 21:26:07 - INFO - __main__ -   test: [epoch: 0 | batch: 7900/10010 ] | Loss: 0.861 | Acc: 78.574% (794641/1011328)
01/13/2023 21:30:29 - INFO - __main__ -   test: [epoch: 0 | batch: 8000/10010 ] | Loss: 0.862 | Acc: 78.571% (804668/1024128)
01/13/2023 21:34:51 - INFO - __main__ -   test: [epoch: 0 | batch: 8100/10010 ] | Loss: 0.861 | Acc: 78.578% (814798/1036928)
01/13/2023 21:39:12 - INFO - __main__ -   test: [epoch: 0 | batch: 8200/10010 ] | Loss: 0.861 | Acc: 78.571% (824777/1049728)
01/13/2023 21:43:34 - INFO - __main__ -   test: [epoch: 0 | batch: 8300/10010 ] | Loss: 0.861 | Acc: 78.573% (834857/1062528)
01/13/2023 21:47:54 - INFO - __main__ -   test: [epoch: 0 | batch: 8400/10010 ] | Loss: 0.861 | Acc: 78.575% (844942/1075328)
01/13/2023 21:52:14 - INFO - __main__ -   test: [epoch: 0 | batch: 8500/10010 ] | Loss: 0.861 | Acc: 78.579% (855036/1088128)
01/13/2023 21:56:38 - INFO - __main__ -   test: [epoch: 0 | batch: 8600/10010 ] | Loss: 0.861 | Acc: 78.573% (865031/1100928)
01/13/2023 22:01:00 - INFO - __main__ -   test: [epoch: 0 | batch: 8700/10010 ] | Loss: 0.861 | Acc: 78.572% (875080/1113728)
01/13/2023 22:05:21 - INFO - __main__ -   test: [epoch: 0 | batch: 8800/10010 ] | Loss: 0.861 | Acc: 78.574% (885158/1126528)
01/13/2023 22:09:42 - INFO - __main__ -   test: [epoch: 0 | batch: 8900/10010 ] | Loss: 0.861 | Acc: 78.578% (895258/1139328)
01/13/2023 22:14:04 - INFO - __main__ -   test: [epoch: 0 | batch: 9000/10010 ] | Loss: 0.861 | Acc: 78.582% (905366/1152128)
01/13/2023 22:18:26 - INFO - __main__ -   test: [epoch: 0 | batch: 9100/10010 ] | Loss: 0.861 | Acc: 78.582% (915418/1164928)
01/13/2023 22:22:46 - INFO - __main__ -   test: [epoch: 0 | batch: 9200/10010 ] | Loss: 0.861 | Acc: 78.580% (925463/1177728)
01/13/2023 22:27:06 - INFO - __main__ -   test: [epoch: 0 | batch: 9300/10010 ] | Loss: 0.861 | Acc: 78.583% (935548/1190528)
01/13/2023 22:31:28 - INFO - __main__ -   test: [epoch: 0 | batch: 9400/10010 ] | Loss: 0.861 | Acc: 78.582% (945595/1203328)
01/13/2023 22:35:49 - INFO - __main__ -   test: [epoch: 0 | batch: 9500/10010 ] | Loss: 0.861 | Acc: 78.584% (955687/1216128)
01/13/2023 22:40:09 - INFO - __main__ -   test: [epoch: 0 | batch: 9600/10010 ] | Loss: 0.861 | Acc: 78.585% (965748/1228928)
01/13/2023 22:44:30 - INFO - __main__ -   test: [epoch: 0 | batch: 9700/10010 ] | Loss: 0.861 | Acc: 78.581% (975758/1241728)
01/13/2023 22:48:52 - INFO - __main__ -   test: [epoch: 0 | batch: 9800/10010 ] | Loss: 0.861 | Acc: 78.575% (985741/1254528)
01/13/2023 22:53:15 - INFO - __main__ -   test: [epoch: 0 | batch: 9900/10010 ] | Loss: 0.861 | Acc: 78.580% (995863/1267328)
01/13/2023 22:57:37 - INFO - __main__ -   test: [epoch: 0 | batch: 10000/10010 ] | Loss: 0.861 | Acc: 78.576% (1005872/1280128)
01/13/2023 22:58:02 - INFO - __main__ -   Saving Checkpoint
01/13/2023 22:58:04 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.455 | Acc: 86.719% (111/128)/ 97.656% (125/128)
01/13/2023 22:58:07 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.473 | Acc: 86.719% (222/256)/ 98.047% (251/256)
01/13/2023 22:58:10 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.622 | Acc: 83.594% (321/384)/ 95.833% (368/384)
01/13/2023 22:58:12 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.572 | Acc: 85.156% (436/512)/ 96.484% (494/512)
01/13/2023 22:58:15 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.489 | Acc: 87.344% (559/640)/ 97.188% (622/640)
01/13/2023 22:58:17 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.434 | Acc: 88.281% (678/768)/ 97.656% (750/768)
01/13/2023 22:58:20 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.426 | Acc: 88.504% (793/896)/ 97.545% (874/896)
01/13/2023 22:58:22 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.408 | Acc: 89.453% (916/1024)/ 97.656% (1000/1024)
01/13/2023 22:58:25 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.425 | Acc: 89.410% (1030/1152)/ 97.569% (1124/1152)
01/13/2023 22:58:28 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.404 | Acc: 89.922% (1151/1280)/ 97.656% (1250/1280)
01/13/2023 22:58:30 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.453 | Acc: 88.636% (1248/1408)/ 97.585% (1374/1408)
01/13/2023 22:58:33 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.457 | Acc: 88.802% (1364/1536)/ 97.461% (1497/1536)
01/13/2023 22:58:36 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.506 | Acc: 87.680% (1459/1664)/ 97.236% (1618/1664)
01/13/2023 22:58:38 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.554 | Acc: 86.105% (1543/1792)/ 96.763% (1734/1792)
01/13/2023 22:58:41 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.574 | Acc: 85.365% (1639/1920)/ 96.823% (1859/1920)
01/13/2023 22:58:43 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.583 | Acc: 84.961% (1740/2048)/ 96.924% (1985/2048)
01/13/2023 22:58:46 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.591 | Acc: 84.789% (1845/2176)/ 96.737% (2105/2176)
01/13/2023 22:58:48 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.618 | Acc: 84.288% (1942/2304)/ 96.224% (2217/2304)
01/13/2023 22:58:51 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.640 | Acc: 83.676% (2035/2432)/ 96.053% (2336/2432)
01/13/2023 22:58:54 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.647 | Acc: 83.477% (2137/2560)/ 95.977% (2457/2560)
01/13/2023 22:58:56 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.644 | Acc: 83.594% (2247/2688)/ 95.871% (2577/2688)
01/13/2023 22:58:59 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.676 | Acc: 82.919% (2335/2816)/ 95.739% (2696/2816)
01/13/2023 22:59:02 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.675 | Acc: 82.779% (2437/2944)/ 95.720% (2818/2944)
01/13/2023 22:59:04 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.719 | Acc: 81.901% (2516/3072)/ 95.410% (2931/3072)
01/13/2023 22:59:07 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.739 | Acc: 81.406% (2605/3200)/ 95.219% (3047/3200)
01/13/2023 22:59:09 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.764 | Acc: 80.769% (2688/3328)/ 94.982% (3161/3328)
01/13/2023 22:59:12 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.778 | Acc: 80.064% (2767/3456)/ 94.936% (3281/3456)
01/13/2023 22:59:15 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.761 | Acc: 80.552% (2887/3584)/ 94.978% (3404/3584)
01/13/2023 22:59:17 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.769 | Acc: 79.984% (2969/3712)/ 95.043% (3528/3712)
01/13/2023 22:59:20 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.762 | Acc: 80.156% (3078/3840)/ 95.156% (3654/3840)
01/13/2023 22:59:23 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.776 | Acc: 80.040% (3176/3968)/ 95.035% (3771/3968)
01/13/2023 22:59:25 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.772 | Acc: 80.225% (3286/4096)/ 95.117% (3896/4096)
01/13/2023 22:59:28 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.757 | Acc: 80.516% (3401/4224)/ 95.218% (4022/4224)
01/13/2023 22:59:30 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.751 | Acc: 80.699% (3512/4352)/ 95.267% (4146/4352)
01/13/2023 22:59:33 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.737 | Acc: 81.071% (3632/4480)/ 95.335% (4271/4480)
01/13/2023 22:59:36 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.724 | Acc: 81.467% (3754/4608)/ 95.334% (4393/4608)
01/13/2023 22:59:38 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.709 | Acc: 81.905% (3879/4736)/ 95.439% (4520/4736)
01/13/2023 22:59:41 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.699 | Acc: 82.196% (3998/4864)/ 95.498% (4645/4864)
01/13/2023 22:59:43 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.692 | Acc: 82.372% (4112/4992)/ 95.573% (4771/4992)
01/13/2023 22:59:46 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.687 | Acc: 82.402% (4219/5120)/ 95.605% (4895/5120)
01/13/2023 22:59:48 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.685 | Acc: 82.489% (4329/5248)/ 95.503% (5012/5248)
01/13/2023 22:59:51 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.689 | Acc: 82.552% (4438/5376)/ 95.406% (5129/5376)
01/13/2023 22:59:54 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.689 | Acc: 82.522% (4542/5504)/ 95.458% (5254/5504)
01/13/2023 22:59:56 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.686 | Acc: 82.582% (4651/5632)/ 95.401% (5373/5632)
01/13/2023 22:59:59 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.690 | Acc: 82.587% (4757/5760)/ 95.312% (5490/5760)
01/13/2023 23:00:01 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.687 | Acc: 82.728% (4871/5888)/ 95.312% (5612/5888)
01/13/2023 23:00:04 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.690 | Acc: 82.713% (4976/6016)/ 95.329% (5735/6016)
01/13/2023 23:00:07 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.691 | Acc: 82.650% (5078/6144)/ 95.378% (5860/6144)
01/13/2023 23:00:09 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.696 | Acc: 82.494% (5174/6272)/ 95.360% (5981/6272)
01/13/2023 23:00:12 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.699 | Acc: 82.531% (5282/6400)/ 95.281% (6098/6400)
01/13/2023 23:00:15 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.691 | Acc: 82.721% (5400/6528)/ 95.328% (6223/6528)
01/13/2023 23:00:17 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.683 | Acc: 82.903% (5518/6656)/ 95.403% (6350/6656)
01/13/2023 23:00:20 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.680 | Acc: 82.975% (5629/6784)/ 95.430% (6474/6784)
01/13/2023 23:00:23 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.671 | Acc: 83.174% (5749/6912)/ 95.515% (6602/6912)
01/13/2023 23:00:25 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.664 | Acc: 83.310% (5865/7040)/ 95.526% (6725/7040)
01/13/2023 23:00:28 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.658 | Acc: 83.468% (5983/7168)/ 95.564% (6850/7168)
01/13/2023 23:00:30 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.650 | Acc: 83.676% (6105/7296)/ 95.614% (6976/7296)
01/13/2023 23:00:33 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.643 | Acc: 83.877% (6227/7424)/ 95.676% (7103/7424)
01/13/2023 23:00:36 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.641 | Acc: 83.938% (6339/7552)/ 95.683% (7226/7552)
01/13/2023 23:00:38 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.643 | Acc: 83.854% (6440/7680)/ 95.690% (7349/7680)
01/13/2023 23:00:41 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.648 | Acc: 83.735% (6538/7808)/ 95.658% (7469/7808)
01/13/2023 23:00:43 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.648 | Acc: 83.732% (6645/7936)/ 95.678% (7593/7936)
01/13/2023 23:00:46 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.648 | Acc: 83.718% (6751/8064)/ 95.697% (7717/8064)
01/13/2023 23:00:49 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.656 | Acc: 83.594% (6848/8192)/ 95.642% (7835/8192)
01/13/2023 23:00:51 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.664 | Acc: 83.389% (6938/8320)/ 95.601% (7954/8320)
01/13/2023 23:00:54 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.677 | Acc: 82.860% (7000/8448)/ 95.526% (8070/8448)
01/13/2023 23:00:56 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.682 | Acc: 82.859% (7106/8576)/ 95.487% (8189/8576)
01/13/2023 23:00:59 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.685 | Acc: 82.801% (7207/8704)/ 95.496% (8312/8704)
01/13/2023 23:01:02 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.686 | Acc: 82.767% (7310/8832)/ 95.516% (8436/8832)
01/13/2023 23:01:04 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.681 | Acc: 82.857% (7424/8960)/ 95.558% (8562/8960)
01/13/2023 23:01:07 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.682 | Acc: 82.779% (7523/9088)/ 95.544% (8683/9088)
01/13/2023 23:01:09 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.680 | Acc: 82.845% (7635/9216)/ 95.551% (8806/9216)
01/13/2023 23:01:12 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.683 | Acc: 82.716% (7729/9344)/ 95.559% (8929/9344)
01/13/2023 23:01:15 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.686 | Acc: 82.612% (7825/9472)/ 95.576% (9053/9472)
01/13/2023 23:01:17 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.687 | Acc: 82.583% (7928/9600)/ 95.562% (9174/9600)
01/13/2023 23:01:20 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.693 | Acc: 82.401% (8016/9728)/ 95.549% (9295/9728)
01/13/2023 23:01:23 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.693 | Acc: 82.386% (8120/9856)/ 95.546% (9417/9856)
01/13/2023 23:01:25 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.693 | Acc: 82.352% (8222/9984)/ 95.573% (9542/9984)
01/13/2023 23:01:28 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.693 | Acc: 82.249% (8317/10112)/ 95.619% (9669/10112)
01/13/2023 23:01:30 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.692 | Acc: 82.256% (8423/10240)/ 95.645% (9794/10240)
01/13/2023 23:01:33 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.692 | Acc: 82.243% (8527/10368)/ 95.650% (9917/10368)
01/13/2023 23:01:35 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.691 | Acc: 82.241% (8632/10496)/ 95.675% (10042/10496)
01/13/2023 23:01:38 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.691 | Acc: 82.238% (8737/10624)/ 95.670% (10164/10624)
01/13/2023 23:01:40 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.690 | Acc: 82.273% (8846/10752)/ 95.657% (10285/10752)
01/13/2023 23:01:43 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.687 | Acc: 82.399% (8965/10880)/ 95.689% (10411/10880)
01/13/2023 23:01:46 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.685 | Acc: 82.386% (9069/11008)/ 95.730% (10538/11008)
01/13/2023 23:01:48 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.689 | Acc: 82.319% (9167/11136)/ 95.717% (10659/11136)
01/13/2023 23:01:51 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.687 | Acc: 82.342% (9275/11264)/ 95.721% (10782/11264)
01/13/2023 23:01:53 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.695 | Acc: 82.286% (9374/11392)/ 95.655% (10897/11392)
01/13/2023 23:01:56 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.693 | Acc: 82.326% (9484/11520)/ 95.668% (11021/11520)
01/13/2023 23:01:59 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.694 | Acc: 82.220% (9577/11648)/ 95.673% (11144/11648)
01/13/2023 23:02:01 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.692 | Acc: 82.252% (9686/11776)/ 95.678% (11267/11776)
01/13/2023 23:02:04 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.693 | Acc: 82.224% (9788/11904)/ 95.665% (11388/11904)
01/13/2023 23:02:07 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.697 | Acc: 82.031% (9870/12032)/ 95.695% (11514/12032)
01/13/2023 23:02:09 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.699 | Acc: 81.891% (9958/12160)/ 95.707% (11638/12160)
01/13/2023 23:02:12 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.697 | Acc: 81.950% (10070/12288)/ 95.711% (11761/12288)
01/13/2023 23:02:14 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.700 | Acc: 81.870% (10165/12416)/ 95.731% (11886/12416)
01/13/2023 23:02:17 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.702 | Acc: 81.688% (10247/12544)/ 95.751% (12011/12544)
01/13/2023 23:02:19 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.698 | Acc: 81.795% (10365/12672)/ 95.778% (12137/12672)
01/13/2023 23:02:22 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.693 | Acc: 81.938% (10488/12800)/ 95.820% (12265/12800)
01/13/2023 23:02:25 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.692 | Acc: 81.993% (10600/12928)/ 95.831% (12389/12928)
01/13/2023 23:02:27 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.687 | Acc: 82.100% (10719/13056)/ 95.872% (12517/13056)
01/13/2023 23:02:30 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.684 | Acc: 82.213% (10839/13184)/ 95.897% (12643/13184)
01/13/2023 23:02:32 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.686 | Acc: 82.024% (10919/13312)/ 95.913% (12768/13312)
01/13/2023 23:02:35 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.685 | Acc: 81.964% (11016/13440)/ 95.923% (12892/13440)
01/13/2023 23:02:38 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.686 | Acc: 81.965% (11121/13568)/ 95.924% (13015/13568)
01/13/2023 23:02:41 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.694 | Acc: 81.856% (11211/13696)/ 95.853% (13128/13696)
01/13/2023 23:02:43 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.691 | Acc: 81.981% (11333/13824)/ 95.884% (13255/13824)
01/13/2023 23:02:46 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.694 | Acc: 81.845% (11419/13952)/ 95.893% (13379/13952)
01/13/2023 23:02:49 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.695 | Acc: 81.818% (11520/14080)/ 95.895% (13502/14080)
01/13/2023 23:02:51 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.697 | Acc: 81.637% (11599/14208)/ 95.911% (13627/14208)
01/13/2023 23:02:54 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.700 | Acc: 81.578% (11695/14336)/ 95.878% (13745/14336)
01/13/2023 23:02:57 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.701 | Acc: 81.589% (11801/14464)/ 95.893% (13870/14464)
01/13/2023 23:02:59 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.700 | Acc: 81.634% (11912/14592)/ 95.895% (13993/14592)
01/13/2023 23:03:02 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.697 | Acc: 81.712% (12028/14720)/ 95.917% (14119/14720)
01/13/2023 23:03:04 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.694 | Acc: 81.796% (12145/14848)/ 95.939% (14245/14848)
01/13/2023 23:03:07 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.697 | Acc: 81.771% (12246/14976)/ 95.907% (14363/14976)
01/13/2023 23:03:09 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.695 | Acc: 81.800% (12355/15104)/ 95.922% (14488/15104)
01/13/2023 23:03:12 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.699 | Acc: 81.683% (12442/15232)/ 95.936% (14613/15232)
01/13/2023 23:03:15 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.697 | Acc: 81.725% (12553/15360)/ 95.957% (14739/15360)
01/13/2023 23:03:17 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.695 | Acc: 81.779% (12666/15488)/ 95.971% (14864/15488)
01/13/2023 23:03:20 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.700 | Acc: 81.634% (12748/15616)/ 95.940% (14982/15616)
01/13/2023 23:03:22 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.703 | Acc: 81.580% (12844/15744)/ 95.910% (15100/15744)
01/13/2023 23:03:25 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.704 | Acc: 81.590% (12950/15872)/ 95.898% (15221/15872)
01/13/2023 23:03:28 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.702 | Acc: 81.606% (13057/16000)/ 95.912% (15346/16000)
01/13/2023 23:03:30 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.698 | Acc: 81.703% (13177/16128)/ 95.939% (15473/16128)
01/13/2023 23:03:33 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.695 | Acc: 81.791% (13296/16256)/ 95.952% (15598/16256)
01/13/2023 23:03:36 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.693 | Acc: 81.873% (13414/16384)/ 95.959% (15722/16384)
01/13/2023 23:03:38 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.694 | Acc: 81.850% (13515/16512)/ 95.942% (15842/16512)
01/13/2023 23:03:41 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.692 | Acc: 81.869% (13623/16640)/ 95.950% (15966/16640)
01/13/2023 23:03:43 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.689 | Acc: 81.960% (13743/16768)/ 95.969% (16092/16768)
01/13/2023 23:03:46 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.689 | Acc: 82.008% (13856/16896)/ 95.975% (16216/16896)
01/13/2023 23:03:48 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.686 | Acc: 82.084% (13974/17024)/ 95.988% (16341/17024)
01/13/2023 23:03:51 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.688 | Acc: 82.037% (14071/17152)/ 95.977% (16462/17152)
01/13/2023 23:03:53 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.686 | Acc: 82.066% (14181/17280)/ 95.995% (16588/17280)
01/13/2023 23:03:56 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.686 | Acc: 82.054% (14284/17408)/ 95.990% (16710/17408)
01/13/2023 23:03:59 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.685 | Acc: 82.014% (14382/17536)/ 96.014% (16837/17536)
01/13/2023 23:04:01 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.683 | Acc: 82.048% (14493/17664)/ 96.043% (16965/17664)
01/13/2023 23:04:04 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.682 | Acc: 82.076% (14603/17792)/ 96.049% (17089/17792)
01/13/2023 23:04:07 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.688 | Acc: 81.914% (14679/17920)/ 96.032% (17209/17920)
01/13/2023 23:04:09 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.690 | Acc: 81.843% (14771/18048)/ 96.027% (17331/18048)
01/13/2023 23:04:11 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.688 | Acc: 81.883% (14883/18176)/ 96.039% (17456/18176)
01/13/2023 23:04:14 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.686 | Acc: 81.966% (15003/18304)/ 96.050% (17581/18304)
01/13/2023 23:04:17 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.687 | Acc: 81.988% (15112/18432)/ 96.034% (17701/18432)
01/13/2023 23:04:19 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.688 | Acc: 81.967% (15213/18560)/ 96.008% (17819/18560)
01/13/2023 23:04:22 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.691 | Acc: 81.946% (15314/18688)/ 95.981% (17937/18688)
01/13/2023 23:04:25 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.693 | Acc: 81.920% (15414/18816)/ 95.972% (18058/18816)
01/13/2023 23:04:27 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.693 | Acc: 81.926% (15520/18944)/ 95.957% (18178/18944)
01/13/2023 23:04:30 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.694 | Acc: 81.869% (15614/19072)/ 95.957% (18301/19072)
01/13/2023 23:04:33 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.698 | Acc: 81.766% (15699/19200)/ 95.932% (18419/19200)
01/13/2023 23:04:35 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.699 | Acc: 81.690% (15789/19328)/ 95.939% (18543/19328)
01/13/2023 23:04:38 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.699 | Acc: 81.718% (15899/19456)/ 95.934% (18665/19456)
01/13/2023 23:04:41 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.700 | Acc: 81.699% (16000/19584)/ 95.920% (18785/19584)
01/13/2023 23:04:43 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.698 | Acc: 81.762% (16117/19712)/ 95.921% (18908/19712)
01/13/2023 23:04:46 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.698 | Acc: 81.749% (16219/19840)/ 95.897% (19026/19840)
01/13/2023 23:04:48 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.699 | Acc: 81.766% (16327/19968)/ 95.888% (19147/19968)
01/13/2023 23:04:51 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.700 | Acc: 81.678% (16414/20096)/ 95.880% (19268/20096)
01/13/2023 23:04:54 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.702 | Acc: 81.660% (16515/20224)/ 95.856% (19386/20224)
01/13/2023 23:04:56 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.703 | Acc: 81.619% (16611/20352)/ 95.828% (19503/20352)
01/13/2023 23:04:59 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.705 | Acc: 81.602% (16712/20480)/ 95.825% (19625/20480)
01/13/2023 23:05:01 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.705 | Acc: 81.575% (16811/20608)/ 95.803% (19743/20608)
01/13/2023 23:05:04 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.715 | Acc: 81.351% (16869/20736)/ 95.718% (19848/20736)
01/13/2023 23:05:06 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.720 | Acc: 81.250% (16952/20864)/ 95.643% (19955/20864)
01/13/2023 23:05:09 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.723 | Acc: 81.198% (17045/20992)/ 95.627% (20074/20992)
01/13/2023 23:05:11 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.723 | Acc: 81.184% (17146/21120)/ 95.644% (20200/21120)
01/13/2023 23:05:14 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.725 | Acc: 81.118% (17236/21248)/ 95.637% (20321/21248)
01/13/2023 23:05:17 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.725 | Acc: 81.133% (17343/21376)/ 95.621% (20440/21376)
01/13/2023 23:05:19 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.727 | Acc: 81.069% (17433/21504)/ 95.605% (20559/21504)
01/13/2023 23:05:22 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.726 | Acc: 81.074% (17538/21632)/ 95.604% (20681/21632)
01/13/2023 23:05:25 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.728 | Acc: 81.048% (17636/21760)/ 95.561% (20794/21760)
01/13/2023 23:05:27 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.733 | Acc: 80.944% (17717/21888)/ 95.527% (20909/21888)
01/13/2023 23:05:30 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.736 | Acc: 80.887% (17808/22016)/ 95.494% (21024/22016)
01/13/2023 23:05:32 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.737 | Acc: 80.839% (17901/22144)/ 95.489% (21145/22144)
01/13/2023 23:05:35 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.740 | Acc: 80.783% (17992/22272)/ 95.461% (21261/22272)
01/13/2023 23:05:38 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.744 | Acc: 80.688% (18074/22400)/ 95.415% (21373/22400)
01/13/2023 23:05:40 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.742 | Acc: 80.744% (18190/22528)/ 95.423% (21497/22528)
01/13/2023 23:05:43 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.743 | Acc: 80.747% (18294/22656)/ 95.401% (21614/22656)
01/13/2023 23:05:45 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.746 | Acc: 80.679% (18382/22784)/ 95.356% (21726/22784)
01/13/2023 23:05:48 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.748 | Acc: 80.665% (18482/22912)/ 95.334% (21843/22912)
01/13/2023 23:05:51 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.751 | Acc: 80.608% (18572/23040)/ 95.291% (21955/23040)
01/13/2023 23:05:53 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.757 | Acc: 80.486% (18647/23168)/ 95.261% (22070/23168)
01/13/2023 23:05:56 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.763 | Acc: 80.353% (18719/23296)/ 95.201% (22178/23296)
01/13/2023 23:05:59 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.762 | Acc: 80.371% (18826/23424)/ 95.202% (22300/23424)
01/13/2023 23:06:01 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.768 | Acc: 80.252% (18901/23552)/ 95.117% (22402/23552)
01/13/2023 23:06:04 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.768 | Acc: 80.279% (19010/23680)/ 95.106% (22521/23680)
01/13/2023 23:06:07 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.768 | Acc: 80.284% (19114/23808)/ 95.098% (22641/23808)
01/13/2023 23:06:10 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.771 | Acc: 80.243% (19207/23936)/ 95.053% (22752/23936)
01/13/2023 23:06:12 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.776 | Acc: 80.124% (19281/24064)/ 95.034% (22869/24064)
01/13/2023 23:06:15 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.779 | Acc: 80.006% (19355/24192)/ 95.007% (22984/24192)
01/13/2023 23:06:17 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.781 | Acc: 79.934% (19440/24320)/ 95.004% (23105/24320)
01/13/2023 23:06:20 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.785 | Acc: 79.847% (19521/24448)/ 94.985% (23222/24448)
01/13/2023 23:06:23 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.788 | Acc: 79.814% (19615/24576)/ 94.963% (23338/24576)
01/13/2023 23:06:25 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.794 | Acc: 79.708% (19691/24704)/ 94.883% (23440/24704)
01/13/2023 23:06:28 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.794 | Acc: 79.728% (19798/24832)/ 94.882% (23561/24832)
01/13/2023 23:06:31 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.797 | Acc: 79.663% (19884/24960)/ 94.860% (23677/24960)
01/13/2023 23:06:33 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.802 | Acc: 79.588% (19967/25088)/ 94.794% (23782/25088)
01/13/2023 23:06:36 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.805 | Acc: 79.485% (20043/25216)/ 94.753% (23893/25216)
01/13/2023 23:06:39 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.810 | Acc: 79.407% (20125/25344)/ 94.736% (24010/25344)
01/13/2023 23:06:41 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.811 | Acc: 79.373% (20218/25472)/ 94.708% (24124/25472)
01/13/2023 23:06:44 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.811 | Acc: 79.352% (20314/25600)/ 94.711% (24246/25600)
01/13/2023 23:06:46 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.811 | Acc: 79.322% (20408/25728)/ 94.710% (24367/25728)
01/13/2023 23:06:49 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.815 | Acc: 79.235% (20487/25856)/ 94.674% (24479/25856)
01/13/2023 23:06:52 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.816 | Acc: 79.222% (20585/25984)/ 94.666% (24598/25984)
01/13/2023 23:06:54 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.817 | Acc: 79.213% (20684/26112)/ 94.654% (24716/26112)
01/13/2023 23:06:57 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.820 | Acc: 79.123% (20762/26240)/ 94.638% (24833/26240)
01/13/2023 23:06:59 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.822 | Acc: 79.035% (20840/26368)/ 94.607% (24946/26368)
01/13/2023 23:07:02 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.824 | Acc: 79.016% (20936/26496)/ 94.603% (25066/26496)
01/13/2023 23:07:05 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.828 | Acc: 78.921% (21012/26624)/ 94.565% (25177/26624)
01/13/2023 23:07:07 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.829 | Acc: 78.880% (21102/26752)/ 94.535% (25290/26752)
01/13/2023 23:07:10 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.829 | Acc: 78.876% (21202/26880)/ 94.550% (25415/26880)
01/13/2023 23:07:12 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.831 | Acc: 78.862% (21299/27008)/ 94.531% (25531/27008)
01/13/2023 23:07:15 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.833 | Acc: 78.810% (21386/27136)/ 94.502% (25644/27136)
01/13/2023 23:07:18 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.835 | Acc: 78.752% (21471/27264)/ 94.480% (25759/27264)
01/13/2023 23:07:20 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.835 | Acc: 78.757% (21573/27392)/ 94.487% (25882/27392)
01/13/2023 23:07:23 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.835 | Acc: 78.732% (21667/27520)/ 94.495% (26005/27520)
01/13/2023 23:07:26 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.835 | Acc: 78.751% (21773/27648)/ 94.488% (26124/27648)
01/13/2023 23:07:28 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.833 | Acc: 78.791% (21885/27776)/ 94.502% (26249/27776)
01/13/2023 23:07:31 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.838 | Acc: 78.731% (21969/27904)/ 94.438% (26352/27904)
01/13/2023 23:07:33 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.841 | Acc: 78.678% (22055/28032)/ 94.399% (26462/28032)
01/13/2023 23:07:36 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.839 | Acc: 78.714% (22166/28160)/ 94.407% (26585/28160)
01/13/2023 23:07:38 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.837 | Acc: 78.754% (22278/28288)/ 94.422% (26710/28288)
01/13/2023 23:07:41 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.839 | Acc: 78.709% (22366/28416)/ 94.405% (26826/28416)
01/13/2023 23:07:43 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.838 | Acc: 78.759% (22481/28544)/ 94.419% (26951/28544)
01/13/2023 23:07:46 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.838 | Acc: 78.760% (22582/28672)/ 94.409% (27069/28672)
01/13/2023 23:07:49 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.837 | Acc: 78.785% (22690/28800)/ 94.403% (27188/28800)
01/13/2023 23:07:51 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.837 | Acc: 78.782% (22790/28928)/ 94.410% (27311/28928)
01/13/2023 23:07:54 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.836 | Acc: 78.758% (22884/29056)/ 94.418% (27434/29056)
01/13/2023 23:07:56 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.839 | Acc: 78.749% (22982/29184)/ 94.408% (27552/29184)
01/13/2023 23:07:59 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.843 | Acc: 78.681% (23063/29312)/ 94.350% (27656/29312)
01/13/2023 23:08:01 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.846 | Acc: 78.624% (23147/29440)/ 94.304% (27763/29440)
01/13/2023 23:08:04 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.849 | Acc: 78.575% (23233/29568)/ 94.278% (27876/29568)
01/13/2023 23:08:07 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.849 | Acc: 78.563% (23330/29696)/ 94.265% (27993/29696)
01/13/2023 23:08:10 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.848 | Acc: 78.598% (23441/29824)/ 94.280% (28118/29824)
01/13/2023 23:08:12 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.850 | Acc: 78.546% (23526/29952)/ 94.261% (28233/29952)
01/13/2023 23:08:14 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.857 | Acc: 78.434% (23593/30080)/ 94.192% (28333/30080)
01/13/2023 23:08:17 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.857 | Acc: 78.420% (23689/30208)/ 94.197% (28455/30208)
01/13/2023 23:08:20 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.855 | Acc: 78.461% (23802/30336)/ 94.205% (28578/30336)
01/13/2023 23:08:22 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.856 | Acc: 78.466% (23904/30464)/ 94.170% (28688/30464)
01/13/2023 23:08:25 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.854 | Acc: 78.504% (24016/30592)/ 94.178% (28811/30592)
01/13/2023 23:08:28 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.853 | Acc: 78.542% (24128/30720)/ 94.180% (28932/30720)
01/13/2023 23:08:30 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.853 | Acc: 78.559% (24234/30848)/ 94.171% (29050/30848)
01/13/2023 23:08:33 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.856 | Acc: 78.470% (24307/30976)/ 94.131% (29158/30976)
01/13/2023 23:08:35 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.858 | Acc: 78.360% (24373/31104)/ 94.110% (29272/31104)
01/13/2023 23:08:38 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.864 | Acc: 78.227% (24432/31232)/ 94.045% (29372/31232)
01/13/2023 23:08:41 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.864 | Acc: 78.233% (24534/31360)/ 94.040% (29491/31360)
01/13/2023 23:08:43 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.864 | Acc: 78.239% (24636/31488)/ 94.033% (29609/31488)
01/13/2023 23:08:46 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.865 | Acc: 78.217% (24729/31616)/ 94.025% (29727/31616)
01/13/2023 23:08:49 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.870 | Acc: 78.122% (24799/31744)/ 93.952% (29824/31744)
01/13/2023 23:08:52 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.871 | Acc: 78.084% (24887/31872)/ 93.945% (29942/31872)
01/13/2023 23:08:54 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.873 | Acc: 77.963% (24948/32000)/ 93.934% (30059/32000)
01/13/2023 23:08:57 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.871 | Acc: 77.997% (25059/32128)/ 93.952% (30185/32128)
01/13/2023 23:08:59 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.874 | Acc: 77.945% (25142/32256)/ 93.917% (30294/32256)
01/13/2023 23:09:02 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.873 | Acc: 77.974% (25251/32384)/ 93.911% (30412/32384)
01/13/2023 23:09:05 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.874 | Acc: 77.944% (25341/32512)/ 93.895% (30527/32512)
01/13/2023 23:09:08 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.879 | Acc: 77.883% (25421/32640)/ 93.854% (30634/32640)
01/13/2023 23:09:10 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.881 | Acc: 77.844% (25508/32768)/ 93.842% (30750/32768)
01/13/2023 23:09:13 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.886 | Acc: 77.724% (25568/32896)/ 93.811% (30860/32896)
01/13/2023 23:09:16 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.887 | Acc: 77.710% (25663/33024)/ 93.798% (30976/33024)
01/13/2023 23:09:18 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.888 | Acc: 77.697% (25758/33152)/ 93.780% (31090/33152)
01/13/2023 23:09:21 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.891 | Acc: 77.578% (25818/33280)/ 93.768% (31206/33280)
01/13/2023 23:09:24 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.892 | Acc: 77.553% (25909/33408)/ 93.762% (31324/33408)
01/13/2023 23:09:26 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.890 | Acc: 77.597% (26023/33536)/ 93.783% (31451/33536)
01/13/2023 23:09:29 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.889 | Acc: 77.623% (26131/33664)/ 93.792% (31574/33664)
01/13/2023 23:09:31 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.892 | Acc: 77.560% (26209/33792)/ 93.768% (31686/33792)
01/13/2023 23:09:34 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.897 | Acc: 77.497% (26287/33920)/ 93.706% (31785/33920)
01/13/2023 23:09:37 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.896 | Acc: 77.517% (26393/34048)/ 93.706% (31905/34048)
01/13/2023 23:09:39 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.898 | Acc: 77.449% (26469/34176)/ 93.689% (32019/34176)
01/13/2023 23:09:42 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.898 | Acc: 77.484% (26580/34304)/ 93.689% (32139/34304)
01/13/2023 23:09:44 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.897 | Acc: 77.509% (26688/34432)/ 93.686% (32258/34432)
01/13/2023 23:09:47 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.899 | Acc: 77.465% (26772/34560)/ 93.666% (32371/34560)
01/13/2023 23:09:49 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.902 | Acc: 77.401% (26849/34688)/ 93.638% (32481/34688)
01/13/2023 23:09:52 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.902 | Acc: 77.410% (26951/34816)/ 93.632% (32599/34816)
01/13/2023 23:09:55 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.903 | Acc: 77.372% (27037/34944)/ 93.630% (32718/34944)
01/13/2023 23:09:57 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.903 | Acc: 77.378% (27138/35072)/ 93.616% (32833/35072)
01/13/2023 23:10:00 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.903 | Acc: 77.369% (27234/35200)/ 93.619% (32954/35200)
01/13/2023 23:10:02 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.905 | Acc: 77.338% (27322/35328)/ 93.611% (33071/35328)
01/13/2023 23:10:05 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.906 | Acc: 77.310% (27411/35456)/ 93.609% (33190/35456)
01/13/2023 23:10:08 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.906 | Acc: 77.282% (27500/35584)/ 93.595% (33305/35584)
01/13/2023 23:10:10 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.906 | Acc: 77.293% (27603/35712)/ 93.593% (33424/35712)
01/13/2023 23:10:13 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.906 | Acc: 77.305% (27706/35840)/ 93.588% (33542/35840)
01/13/2023 23:10:16 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.907 | Acc: 77.285% (27798/35968)/ 93.578% (33658/35968)
01/13/2023 23:10:18 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.907 | Acc: 77.294% (27900/36096)/ 93.573% (33776/36096)
01/13/2023 23:10:21 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.906 | Acc: 77.324% (28010/36224)/ 93.579% (33898/36224)
01/13/2023 23:10:24 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.907 | Acc: 77.294% (28098/36352)/ 93.574% (34016/36352)
01/13/2023 23:10:26 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.910 | Acc: 77.248% (28180/36480)/ 93.533% (34121/36480)
01/13/2023 23:10:29 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.913 | Acc: 77.204% (28263/36608)/ 93.493% (34226/36608)
01/13/2023 23:10:31 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.914 | Acc: 77.172% (28350/36736)/ 93.483% (34342/36736)
01/13/2023 23:10:34 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.914 | Acc: 77.170% (28448/36864)/ 93.479% (34460/36864)
01/13/2023 23:10:37 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.913 | Acc: 77.190% (28554/36992)/ 93.480% (34580/36992)
01/13/2023 23:10:39 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.915 | Acc: 77.150% (28638/37120)/ 93.448% (34688/37120)
01/13/2023 23:10:42 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.917 | Acc: 77.067% (28706/37248)/ 93.452% (34809/37248)
01/13/2023 23:10:44 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.917 | Acc: 77.082% (28810/37376)/ 93.445% (34926/37376)
01/13/2023 23:10:47 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.918 | Acc: 77.026% (28888/37504)/ 93.427% (35039/37504)
01/13/2023 23:10:50 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.919 | Acc: 77.025% (28986/37632)/ 93.423% (35157/37632)
01/13/2023 23:10:52 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.920 | Acc: 76.994% (29073/37760)/ 93.416% (35274/37760)
01/13/2023 23:10:55 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.919 | Acc: 77.027% (29184/37888)/ 93.423% (35396/37888)
01/13/2023 23:10:58 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.919 | Acc: 77.031% (29284/38016)/ 93.413% (35512/38016)
01/13/2023 23:11:00 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.921 | Acc: 77.013% (29376/38144)/ 93.388% (35622/38144)
01/13/2023 23:11:03 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.923 | Acc: 76.983% (29463/38272)/ 93.366% (35733/38272)
01/13/2023 23:11:06 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.924 | Acc: 76.977% (29559/38400)/ 93.344% (35844/38400)
01/13/2023 23:11:08 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.925 | Acc: 76.980% (29659/38528)/ 93.337% (35961/38528)
01/13/2023 23:11:11 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.925 | Acc: 76.963% (29751/38656)/ 93.323% (36075/38656)
01/13/2023 23:11:14 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.927 | Acc: 76.926% (29835/38784)/ 93.309% (36189/38784)
01/13/2023 23:11:16 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.928 | Acc: 76.904% (29925/38912)/ 93.293% (36302/38912)
01/13/2023 23:11:19 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.927 | Acc: 76.916% (30028/39040)/ 93.297% (36423/39040)
01/13/2023 23:11:22 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.928 | Acc: 76.871% (30109/39168)/ 93.290% (36540/39168)
01/13/2023 23:11:24 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.929 | Acc: 76.853% (30200/39296)/ 93.266% (36650/39296)
01/13/2023 23:11:27 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.930 | Acc: 76.859% (30301/39424)/ 93.250% (36763/39424)
01/13/2023 23:11:29 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.930 | Acc: 76.838% (30391/39552)/ 93.247% (36881/39552)
01/13/2023 23:11:32 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.931 | Acc: 76.832% (30487/39680)/ 93.226% (36992/39680)
01/13/2023 23:11:34 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.932 | Acc: 76.824% (30582/39808)/ 93.212% (37106/39808)
01/13/2023 23:11:37 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.933 | Acc: 76.798% (30670/39936)/ 93.202% (37221/39936)
01/13/2023 23:11:39 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.935 | Acc: 76.785% (30763/40064)/ 93.181% (37332/40064)
01/13/2023 23:11:42 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.933 | Acc: 76.824% (30877/40192)/ 93.200% (37459/40192)
01/13/2023 23:11:45 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.933 | Acc: 76.815% (30972/40320)/ 93.197% (37577/40320)
01/13/2023 23:11:47 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.934 | Acc: 76.797% (31063/40448)/ 93.184% (37691/40448)
01/13/2023 23:11:50 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.937 | Acc: 76.703% (31123/40576)/ 93.159% (37800/40576)
01/13/2023 23:11:52 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.939 | Acc: 76.661% (31204/40704)/ 93.131% (37908/40704)
01/13/2023 23:11:55 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.938 | Acc: 76.690% (31314/40832)/ 93.148% (38034/40832)
01/13/2023 23:11:57 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.940 | Acc: 76.633% (31389/40960)/ 93.115% (38140/40960)
01/13/2023 23:12:00 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.939 | Acc: 76.667% (31501/41088)/ 93.122% (38262/41088)
01/13/2023 23:12:02 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.939 | Acc: 76.686% (31607/41216)/ 93.114% (38378/41216)
01/13/2023 23:12:05 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.940 | Acc: 76.662% (31695/41344)/ 93.107% (38494/41344)
01/13/2023 23:12:08 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.943 | Acc: 76.625% (31778/41472)/ 93.087% (38605/41472)
01/13/2023 23:12:10 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.943 | Acc: 76.618% (31873/41600)/ 93.082% (38722/41600)
01/13/2023 23:12:13 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.942 | Acc: 76.632% (31977/41728)/ 93.081% (38841/41728)
01/13/2023 23:12:15 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.946 | Acc: 76.548% (32040/41856)/ 93.050% (38947/41856)
01/13/2023 23:12:18 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.949 | Acc: 76.467% (32104/41984)/ 93.014% (39051/41984)
01/13/2023 23:12:21 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.951 | Acc: 76.415% (32180/42112)/ 92.992% (39161/42112)
01/13/2023 23:12:23 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.951 | Acc: 76.411% (32276/42240)/ 92.992% (39280/42240)
01/13/2023 23:12:26 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.953 | Acc: 76.369% (32356/42368)/ 92.966% (39388/42368)
01/13/2023 23:12:28 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.953 | Acc: 76.339% (32441/42496)/ 92.976% (39511/42496)
01/13/2023 23:12:31 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.953 | Acc: 76.326% (32533/42624)/ 92.976% (39630/42624)
01/13/2023 23:12:33 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.952 | Acc: 76.352% (32642/42752)/ 92.983% (39752/42752)
01/13/2023 23:12:36 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.953 | Acc: 76.322% (32727/42880)/ 92.964% (39863/42880)
01/13/2023 23:12:38 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.954 | Acc: 76.295% (32813/43008)/ 92.950% (39976/43008)
01/13/2023 23:12:41 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.956 | Acc: 76.254% (32893/43136)/ 92.936% (40089/43136)
01/13/2023 23:12:43 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.956 | Acc: 76.246% (32987/43264)/ 92.932% (40206/43264)
01/13/2023 23:12:46 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.956 | Acc: 76.238% (33081/43392)/ 92.941% (40329/43392)
01/13/2023 23:12:49 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.959 | Acc: 76.199% (33162/43520)/ 92.914% (40436/43520)
01/13/2023 23:12:51 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.958 | Acc: 76.196% (33258/43648)/ 92.923% (40559/43648)
01/13/2023 23:12:54 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.957 | Acc: 76.234% (33372/43776)/ 92.941% (40686/43776)
01/13/2023 23:12:57 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.958 | Acc: 76.173% (33443/43904)/ 92.935% (40802/43904)
01/13/2023 23:12:59 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.957 | Acc: 76.172% (33540/44032)/ 92.937% (40922/44032)
01/13/2023 23:13:02 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.958 | Acc: 76.171% (33637/44160)/ 92.926% (41036/44160)
01/13/2023 23:13:05 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.961 | Acc: 76.109% (33707/44288)/ 92.887% (41138/44288)
01/13/2023 23:13:07 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.963 | Acc: 76.092% (33797/44416)/ 92.879% (41253/44416)
01/13/2023 23:13:10 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.962 | Acc: 76.100% (33898/44544)/ 92.890% (41377/44544)
01/13/2023 23:13:12 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.964 | Acc: 76.074% (33984/44672)/ 92.868% (41486/44672)
01/13/2023 23:13:15 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.963 | Acc: 76.074% (34081/44800)/ 92.877% (41609/44800)
01/13/2023 23:13:17 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.963 | Acc: 76.086% (34184/44928)/ 92.875% (41727/44928)
01/13/2023 23:13:20 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.965 | Acc: 76.032% (34257/45056)/ 92.862% (41840/45056)
01/13/2023 23:13:23 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.966 | Acc: 76.029% (34353/45184)/ 92.860% (41958/45184)
01/13/2023 23:13:25 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.968 | Acc: 75.984% (34430/45312)/ 92.821% (42059/45312)
01/13/2023 23:13:28 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.970 | Acc: 75.929% (34502/45440)/ 92.799% (42168/45440)
01/13/2023 23:13:30 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.973 | Acc: 75.865% (34570/45568)/ 92.789% (42282/45568)
01/13/2023 23:13:33 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.973 | Acc: 75.860% (34665/45696)/ 92.789% (42401/45696)
01/13/2023 23:13:36 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.972 | Acc: 75.893% (34777/45824)/ 92.803% (42526/45824)
01/13/2023 23:13:38 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.971 | Acc: 75.923% (34888/45952)/ 92.806% (42646/45952)
01/13/2023 23:13:41 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.972 | Acc: 75.931% (34989/46080)/ 92.797% (42761/46080)
01/13/2023 23:13:43 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.973 | Acc: 75.900% (35072/46208)/ 92.787% (42875/46208)
01/13/2023 23:13:46 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.973 | Acc: 75.902% (35170/46336)/ 92.794% (42997/46336)
01/13/2023 23:13:49 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.973 | Acc: 75.904% (35268/46464)/ 92.807% (43122/46464)
01/13/2023 23:13:51 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.973 | Acc: 75.897% (35362/46592)/ 92.801% (43238/46592)
01/13/2023 23:13:54 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.972 | Acc: 75.927% (35473/46720)/ 92.812% (43362/46720)
01/13/2023 23:13:57 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.971 | Acc: 75.943% (35578/46848)/ 92.817% (43483/46848)
01/13/2023 23:13:59 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.970 | Acc: 75.977% (35691/46976)/ 92.835% (43610/46976)
01/13/2023 23:14:02 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.969 | Acc: 75.996% (35797/47104)/ 92.848% (43735/47104)
01/13/2023 23:14:04 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.968 | Acc: 76.004% (35898/47232)/ 92.859% (43859/47232)
01/13/2023 23:14:07 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.967 | Acc: 76.026% (36006/47360)/ 92.870% (43983/47360)
01/13/2023 23:14:09 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.968 | Acc: 76.013% (36097/47488)/ 92.870% (44102/47488)
01/13/2023 23:14:12 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.967 | Acc: 76.021% (36198/47616)/ 92.872% (44222/47616)
01/13/2023 23:14:15 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.966 | Acc: 76.064% (36316/47744)/ 92.889% (44349/47744)
01/13/2023 23:14:17 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.964 | Acc: 76.101% (36431/47872)/ 92.898% (44472/47872)
01/13/2023 23:14:20 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.963 | Acc: 76.131% (36543/48000)/ 92.900% (44592/48000)
01/13/2023 23:14:22 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.966 | Acc: 76.062% (36607/48128)/ 92.865% (44694/48128)
01/13/2023 23:14:25 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.967 | Acc: 76.055% (36701/48256)/ 92.851% (44806/48256)
01/13/2023 23:14:27 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.967 | Acc: 76.042% (36792/48384)/ 92.843% (44921/48384)
01/13/2023 23:14:30 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.970 | Acc: 75.967% (36853/48512)/ 92.804% (45021/48512)
01/13/2023 23:14:32 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.971 | Acc: 75.948% (36941/48640)/ 92.810% (45143/48640)
01/13/2023 23:14:35 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.970 | Acc: 75.945% (37037/48768)/ 92.819% (45266/48768)
01/13/2023 23:14:38 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.972 | Acc: 75.900% (37112/48896)/ 92.821% (45386/48896)
01/13/2023 23:14:40 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.974 | Acc: 75.871% (37195/49024)/ 92.808% (45498/49024)
01/13/2023 23:14:43 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.974 | Acc: 75.881% (37297/49152)/ 92.800% (45613/49152)
01/13/2023 23:14:45 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.972 | Acc: 75.919% (37413/49280)/ 92.812% (45738/49280)
01/13/2023 23:14:48 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.971 | Acc: 75.929% (37515/49408)/ 92.823% (45862/49408)
01/13/2023 23:14:51 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.969 | Acc: 75.973% (37634/49536)/ 92.840% (45989/49536)
01/13/2023 23:14:53 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.967 | Acc: 76.013% (37751/49664)/ 92.850% (46113/49664)
01/13/2023 23:14:56 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.965 | Acc: 76.060% (37872/49792)/ 92.862% (46238/49792)
01/13/2023 23:14:59 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.965 | Acc: 76.064% (37971/49920)/ 92.865% (46358/49920)
01/13/2023 23:15:01 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.967 | Acc: 76.018% (38009/50000)/ 92.854% (46427/50000)
01/13/2023 23:15:01 - INFO - __main__ -   Final accuracy: 76.018
01/13/2023 23:15:01 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 1, '_step_count': 2, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00025]}
01/13/2023 23:15:01 - INFO - __main__ -   
Epoch: 1
01/13/2023 23:15:04 - INFO - __main__ -   test: [epoch: 1 | batch: 0/10010 ] | Loss: 0.626 | Acc: 86.719% (111/128)
01/13/2023 23:19:27 - INFO - __main__ -   test: [epoch: 1 | batch: 100/10010 ] | Loss: 0.830 | Acc: 79.541% (10283/12928)
01/13/2023 23:23:47 - INFO - __main__ -   test: [epoch: 1 | batch: 200/10010 ] | Loss: 0.830 | Acc: 79.295% (20401/25728)
01/13/2023 23:28:07 - INFO - __main__ -   test: [epoch: 1 | batch: 300/10010 ] | Loss: 0.843 | Acc: 79.036% (30451/38528)
01/13/2023 23:32:29 - INFO - __main__ -   test: [epoch: 1 | batch: 400/10010 ] | Loss: 0.855 | Acc: 78.828% (40461/51328)
01/13/2023 23:36:52 - INFO - __main__ -   test: [epoch: 1 | batch: 500/10010 ] | Loss: 0.855 | Acc: 78.791% (50527/64128)
01/13/2023 23:41:13 - INFO - __main__ -   test: [epoch: 1 | batch: 600/10010 ] | Loss: 0.858 | Acc: 78.723% (60560/76928)
01/13/2023 23:45:34 - INFO - __main__ -   test: [epoch: 1 | batch: 700/10010 ] | Loss: 0.859 | Acc: 78.674% (70593/89728)
01/13/2023 23:49:54 - INFO - __main__ -   test: [epoch: 1 | batch: 800/10010 ] | Loss: 0.857 | Acc: 78.662% (80651/102528)
01/13/2023 23:54:14 - INFO - __main__ -   test: [epoch: 1 | batch: 900/10010 ] | Loss: 0.858 | Acc: 78.642% (90696/115328)
01/13/2023 23:58:35 - INFO - __main__ -   test: [epoch: 1 | batch: 1000/10010 ] | Loss: 0.858 | Acc: 78.595% (100702/128128)
01/14/2023 00:02:58 - INFO - __main__ -   test: [epoch: 1 | batch: 1100/10010 ] | Loss: 0.860 | Acc: 78.553% (110703/140928)
01/14/2023 00:07:19 - INFO - __main__ -   test: [epoch: 1 | batch: 1200/10010 ] | Loss: 0.861 | Acc: 78.567% (120780/153728)
01/14/2023 00:11:41 - INFO - __main__ -   test: [epoch: 1 | batch: 1300/10010 ] | Loss: 0.858 | Acc: 78.653% (130980/166528)
01/14/2023 00:16:03 - INFO - __main__ -   test: [epoch: 1 | batch: 1400/10010 ] | Loss: 0.858 | Acc: 78.659% (141057/179328)
01/14/2023 00:20:24 - INFO - __main__ -   test: [epoch: 1 | batch: 1500/10010 ] | Loss: 0.857 | Acc: 78.649% (151107/192128)
01/14/2023 00:24:47 - INFO - __main__ -   test: [epoch: 1 | batch: 1600/10010 ] | Loss: 0.860 | Acc: 78.617% (161109/204928)
01/14/2023 00:29:08 - INFO - __main__ -   test: [epoch: 1 | batch: 1700/10010 ] | Loss: 0.859 | Acc: 78.615% (171167/217728)
01/14/2023 00:33:29 - INFO - __main__ -   test: [epoch: 1 | batch: 1800/10010 ] | Loss: 0.859 | Acc: 78.633% (181271/230528)
01/14/2023 00:37:51 - INFO - __main__ -   test: [epoch: 1 | batch: 1900/10010 ] | Loss: 0.858 | Acc: 78.668% (191421/243328)
01/14/2023 00:42:12 - INFO - __main__ -   test: [epoch: 1 | batch: 2000/10010 ] | Loss: 0.858 | Acc: 78.688% (201541/256128)
01/14/2023 00:46:33 - INFO - __main__ -   test: [epoch: 1 | batch: 2100/10010 ] | Loss: 0.857 | Acc: 78.683% (211600/268928)
01/14/2023 00:50:54 - INFO - __main__ -   test: [epoch: 1 | batch: 2200/10010 ] | Loss: 0.859 | Acc: 78.646% (221568/281728)
01/14/2023 00:55:18 - INFO - __main__ -   test: [epoch: 1 | batch: 2300/10010 ] | Loss: 0.859 | Acc: 78.633% (231597/294528)
01/14/2023 00:59:40 - INFO - __main__ -   test: [epoch: 1 | batch: 2400/10010 ] | Loss: 0.858 | Acc: 78.665% (241759/307328)
01/14/2023 01:04:02 - INFO - __main__ -   test: [epoch: 1 | batch: 2500/10010 ] | Loss: 0.859 | Acc: 78.634% (251730/320128)
01/14/2023 01:08:23 - INFO - __main__ -   test: [epoch: 1 | batch: 2600/10010 ] | Loss: 0.860 | Acc: 78.639% (261812/332928)
01/14/2023 01:12:44 - INFO - __main__ -   test: [epoch: 1 | batch: 2700/10010 ] | Loss: 0.860 | Acc: 78.636% (271868/345728)
01/14/2023 01:17:04 - INFO - __main__ -   test: [epoch: 1 | batch: 2800/10010 ] | Loss: 0.860 | Acc: 78.628% (281902/358528)
01/14/2023 01:21:28 - INFO - __main__ -   test: [epoch: 1 | batch: 2900/10010 ] | Loss: 0.860 | Acc: 78.628% (291968/371328)
01/14/2023 01:25:49 - INFO - __main__ -   test: [epoch: 1 | batch: 3000/10010 ] | Loss: 0.860 | Acc: 78.641% (302081/384128)
01/14/2023 01:30:10 - INFO - __main__ -   test: [epoch: 1 | batch: 3100/10010 ] | Loss: 0.860 | Acc: 78.632% (312113/396928)
01/14/2023 01:34:31 - INFO - __main__ -   test: [epoch: 1 | batch: 3200/10010 ] | Loss: 0.860 | Acc: 78.612% (322094/409728)
01/14/2023 01:38:52 - INFO - __main__ -   test: [epoch: 1 | batch: 3300/10010 ] | Loss: 0.861 | Acc: 78.595% (332086/422528)
01/14/2023 01:43:12 - INFO - __main__ -   test: [epoch: 1 | batch: 3400/10010 ] | Loss: 0.861 | Acc: 78.603% (342179/435328)
01/14/2023 01:47:34 - INFO - __main__ -   test: [epoch: 1 | batch: 3500/10010 ] | Loss: 0.861 | Acc: 78.596% (352209/448128)
01/14/2023 01:51:57 - INFO - __main__ -   test: [epoch: 1 | batch: 3600/10010 ] | Loss: 0.861 | Acc: 78.598% (362282/460928)
01/14/2023 01:56:18 - INFO - __main__ -   test: [epoch: 1 | batch: 3700/10010 ] | Loss: 0.862 | Acc: 78.582% (372266/473728)
01/14/2023 02:00:39 - INFO - __main__ -   test: [epoch: 1 | batch: 3800/10010 ] | Loss: 0.862 | Acc: 78.579% (382308/486528)
01/14/2023 02:05:00 - INFO - __main__ -   test: [epoch: 1 | batch: 3900/10010 ] | Loss: 0.861 | Acc: 78.588% (392413/499328)
01/14/2023 02:09:23 - INFO - __main__ -   test: [epoch: 1 | batch: 4000/10010 ] | Loss: 0.861 | Acc: 78.587% (402466/512128)
01/14/2023 02:13:44 - INFO - __main__ -   test: [epoch: 1 | batch: 4100/10010 ] | Loss: 0.861 | Acc: 78.600% (412591/524928)
01/14/2023 02:18:05 - INFO - __main__ -   test: [epoch: 1 | batch: 4200/10010 ] | Loss: 0.861 | Acc: 78.592% (422609/537728)
01/14/2023 02:22:27 - INFO - __main__ -   test: [epoch: 1 | batch: 4300/10010 ] | Loss: 0.861 | Acc: 78.601% (432720/550528)
01/14/2023 02:26:48 - INFO - __main__ -   test: [epoch: 1 | batch: 4400/10010 ] | Loss: 0.860 | Acc: 78.606% (442812/563328)
01/14/2023 02:31:09 - INFO - __main__ -   test: [epoch: 1 | batch: 4500/10010 ] | Loss: 0.860 | Acc: 78.605% (452863/576128)
01/14/2023 02:35:31 - INFO - __main__ -   test: [epoch: 1 | batch: 4600/10010 ] | Loss: 0.860 | Acc: 78.601% (462905/588928)
01/14/2023 02:39:51 - INFO - __main__ -   test: [epoch: 1 | batch: 4700/10010 ] | Loss: 0.860 | Acc: 78.610% (473020/601728)
01/14/2023 02:44:11 - INFO - __main__ -   test: [epoch: 1 | batch: 4800/10010 ] | Loss: 0.860 | Acc: 78.617% (483123/614528)
01/14/2023 02:48:31 - INFO - __main__ -   test: [epoch: 1 | batch: 4900/10010 ] | Loss: 0.860 | Acc: 78.610% (493144/627328)
01/14/2023 02:52:54 - INFO - __main__ -   test: [epoch: 1 | batch: 5000/10010 ] | Loss: 0.860 | Acc: 78.622% (503283/640128)
01/14/2023 02:57:15 - INFO - __main__ -   test: [epoch: 1 | batch: 5100/10010 ] | Loss: 0.860 | Acc: 78.620% (513330/652928)
01/14/2023 03:01:37 - INFO - __main__ -   test: [epoch: 1 | batch: 5200/10010 ] | Loss: 0.860 | Acc: 78.613% (523351/665728)
01/14/2023 03:05:59 - INFO - __main__ -   test: [epoch: 1 | batch: 5300/10010 ] | Loss: 0.860 | Acc: 78.611% (533397/678528)
01/14/2023 03:10:20 - INFO - __main__ -   test: [epoch: 1 | batch: 5400/10010 ] | Loss: 0.860 | Acc: 78.609% (543443/691328)
01/14/2023 03:14:43 - INFO - __main__ -   test: [epoch: 1 | batch: 5500/10010 ] | Loss: 0.860 | Acc: 78.603% (553464/704128)
01/14/2023 03:19:04 - INFO - __main__ -   test: [epoch: 1 | batch: 5600/10010 ] | Loss: 0.860 | Acc: 78.613% (563598/716928)
01/14/2023 03:23:26 - INFO - __main__ -   test: [epoch: 1 | batch: 5700/10010 ] | Loss: 0.860 | Acc: 78.618% (573694/729728)
01/14/2023 03:27:48 - INFO - __main__ -   test: [epoch: 1 | batch: 5800/10010 ] | Loss: 0.859 | Acc: 78.624% (583808/742528)
01/14/2023 03:32:10 - INFO - __main__ -   test: [epoch: 1 | batch: 5900/10010 ] | Loss: 0.859 | Acc: 78.621% (593850/755328)
01/14/2023 03:36:34 - INFO - __main__ -   test: [epoch: 1 | batch: 6000/10010 ] | Loss: 0.859 | Acc: 78.625% (603938/768128)
01/14/2023 03:40:56 - INFO - __main__ -   test: [epoch: 1 | batch: 6100/10010 ] | Loss: 0.860 | Acc: 78.612% (613903/780928)
01/14/2023 03:45:16 - INFO - __main__ -   test: [epoch: 1 | batch: 6200/10010 ] | Loss: 0.859 | Acc: 78.614% (623983/793728)
01/14/2023 03:49:36 - INFO - __main__ -   test: [epoch: 1 | batch: 6300/10010 ] | Loss: 0.859 | Acc: 78.612% (634028/806528)
01/14/2023 03:53:56 - INFO - __main__ -   test: [epoch: 1 | batch: 6400/10010 ] | Loss: 0.860 | Acc: 78.600% (643993/819328)
01/14/2023 03:58:17 - INFO - __main__ -   test: [epoch: 1 | batch: 6500/10010 ] | Loss: 0.860 | Acc: 78.603% (654081/832128)
01/14/2023 04:02:38 - INFO - __main__ -   test: [epoch: 1 | batch: 6600/10010 ] | Loss: 0.859 | Acc: 78.612% (664215/844928)
01/14/2023 04:07:00 - INFO - __main__ -   test: [epoch: 1 | batch: 6700/10010 ] | Loss: 0.860 | Acc: 78.602% (674191/857728)
01/14/2023 04:11:21 - INFO - __main__ -   test: [epoch: 1 | batch: 6800/10010 ] | Loss: 0.860 | Acc: 78.594% (684180/870528)
01/14/2023 04:15:41 - INFO - __main__ -   test: [epoch: 1 | batch: 6900/10010 ] | Loss: 0.860 | Acc: 78.596% (694263/883328)
01/14/2023 04:20:04 - INFO - __main__ -   test: [epoch: 1 | batch: 7000/10010 ] | Loss: 0.860 | Acc: 78.589% (704260/896128)
01/14/2023 04:24:26 - INFO - __main__ -   test: [epoch: 1 | batch: 7100/10010 ] | Loss: 0.860 | Acc: 78.594% (714366/908928)
01/14/2023 04:28:46 - INFO - __main__ -   test: [epoch: 1 | batch: 7200/10010 ] | Loss: 0.860 | Acc: 78.597% (724450/921728)
01/14/2023 04:33:09 - INFO - __main__ -   test: [epoch: 1 | batch: 7300/10010 ] | Loss: 0.860 | Acc: 78.597% (734514/934528)
01/14/2023 04:37:31 - INFO - __main__ -   test: [epoch: 1 | batch: 7400/10010 ] | Loss: 0.860 | Acc: 78.590% (744503/947328)
01/14/2023 04:41:51 - INFO - __main__ -   test: [epoch: 1 | batch: 7500/10010 ] | Loss: 0.860 | Acc: 78.591% (754571/960128)
01/14/2023 04:46:14 - INFO - __main__ -   test: [epoch: 1 | batch: 7600/10010 ] | Loss: 0.860 | Acc: 78.584% (764568/972928)
01/14/2023 04:50:34 - INFO - __main__ -   test: [epoch: 1 | batch: 7700/10010 ] | Loss: 0.860 | Acc: 78.582% (774609/985728)
01/14/2023 04:54:55 - INFO - __main__ -   test: [epoch: 1 | batch: 7800/10010 ] | Loss: 0.861 | Acc: 78.570% (784546/998528)
01/14/2023 04:59:16 - INFO - __main__ -   test: [epoch: 1 | batch: 7900/10010 ] | Loss: 0.860 | Acc: 78.572% (794622/1011328)
01/14/2023 05:03:37 - INFO - __main__ -   test: [epoch: 1 | batch: 8000/10010 ] | Loss: 0.860 | Acc: 78.574% (804703/1024128)
01/14/2023 05:07:58 - INFO - __main__ -   test: [epoch: 1 | batch: 8100/10010 ] | Loss: 0.860 | Acc: 78.584% (814863/1036928)
01/14/2023 05:12:18 - INFO - __main__ -   test: [epoch: 1 | batch: 8200/10010 ] | Loss: 0.860 | Acc: 78.579% (824867/1049728)
01/14/2023 05:16:40 - INFO - __main__ -   test: [epoch: 1 | batch: 8300/10010 ] | Loss: 0.860 | Acc: 78.576% (834887/1062528)
01/14/2023 05:21:00 - INFO - __main__ -   test: [epoch: 1 | batch: 8400/10010 ] | Loss: 0.860 | Acc: 78.577% (844958/1075328)
01/14/2023 05:25:23 - INFO - __main__ -   test: [epoch: 1 | batch: 8500/10010 ] | Loss: 0.860 | Acc: 78.580% (855051/1088128)
01/14/2023 05:29:45 - INFO - __main__ -   test: [epoch: 1 | batch: 8600/10010 ] | Loss: 0.860 | Acc: 78.578% (865085/1100928)
01/14/2023 05:34:08 - INFO - __main__ -   test: [epoch: 1 | batch: 8700/10010 ] | Loss: 0.860 | Acc: 78.585% (875221/1113728)
01/14/2023 05:38:30 - INFO - __main__ -   test: [epoch: 1 | batch: 8800/10010 ] | Loss: 0.860 | Acc: 78.590% (885337/1126528)
01/14/2023 05:42:54 - INFO - __main__ -   test: [epoch: 1 | batch: 8900/10010 ] | Loss: 0.860 | Acc: 78.593% (895429/1139328)
01/14/2023 05:47:14 - INFO - __main__ -   test: [epoch: 1 | batch: 9000/10010 ] | Loss: 0.860 | Acc: 78.593% (905489/1152128)
01/14/2023 05:51:35 - INFO - __main__ -   test: [epoch: 1 | batch: 9100/10010 ] | Loss: 0.860 | Acc: 78.593% (915553/1164928)
01/14/2023 05:55:54 - INFO - __main__ -   test: [epoch: 1 | batch: 9200/10010 ] | Loss: 0.860 | Acc: 78.593% (925612/1177728)
01/14/2023 06:00:15 - INFO - __main__ -   test: [epoch: 1 | batch: 9300/10010 ] | Loss: 0.860 | Acc: 78.598% (935736/1190528)
01/14/2023 06:04:37 - INFO - __main__ -   test: [epoch: 1 | batch: 9400/10010 ] | Loss: 0.860 | Acc: 78.596% (945773/1203328)
01/14/2023 06:09:01 - INFO - __main__ -   test: [epoch: 1 | batch: 9500/10010 ] | Loss: 0.860 | Acc: 78.597% (955843/1216128)
01/14/2023 06:13:32 - INFO - __main__ -   test: [epoch: 1 | batch: 9600/10010 ] | Loss: 0.860 | Acc: 78.595% (965878/1228928)
01/14/2023 06:17:55 - INFO - __main__ -   test: [epoch: 1 | batch: 9700/10010 ] | Loss: 0.860 | Acc: 78.596% (975954/1241728)
01/14/2023 06:22:19 - INFO - __main__ -   test: [epoch: 1 | batch: 9800/10010 ] | Loss: 0.860 | Acc: 78.595% (985993/1254528)
01/14/2023 06:26:40 - INFO - __main__ -   test: [epoch: 1 | batch: 9900/10010 ] | Loss: 0.860 | Acc: 78.596% (996072/1267328)
01/14/2023 06:31:01 - INFO - __main__ -   test: [epoch: 1 | batch: 10000/10010 ] | Loss: 0.860 | Acc: 78.593% (1006088/1280128)
01/14/2023 06:31:25 - INFO - __main__ -   Saving Checkpoint
01/14/2023 06:31:28 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.447 | Acc: 86.719% (111/128)/ 97.656% (125/128)
01/14/2023 06:31:30 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.458 | Acc: 87.109% (223/256)/ 98.047% (251/256)
01/14/2023 06:31:33 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.610 | Acc: 83.333% (320/384)/ 96.094% (369/384)
01/14/2023 06:31:35 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.564 | Acc: 84.961% (435/512)/ 96.680% (495/512)
01/14/2023 06:31:38 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.483 | Acc: 87.188% (558/640)/ 97.344% (623/640)
01/14/2023 06:31:40 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.427 | Acc: 88.542% (680/768)/ 97.786% (751/768)
01/14/2023 06:31:43 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.421 | Acc: 88.728% (795/896)/ 97.656% (875/896)
01/14/2023 06:31:46 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.404 | Acc: 89.551% (917/1024)/ 97.656% (1000/1024)
01/14/2023 06:31:48 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.420 | Acc: 89.497% (1031/1152)/ 97.569% (1124/1152)
01/14/2023 06:31:51 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.398 | Acc: 90.000% (1152/1280)/ 97.656% (1250/1280)
01/14/2023 06:31:53 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.448 | Acc: 88.636% (1248/1408)/ 97.656% (1375/1408)
01/14/2023 06:31:56 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.452 | Acc: 88.802% (1364/1536)/ 97.526% (1498/1536)
01/14/2023 06:31:59 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.501 | Acc: 87.620% (1458/1664)/ 97.236% (1618/1664)
01/14/2023 06:32:01 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.552 | Acc: 85.993% (1541/1792)/ 96.708% (1733/1792)
01/14/2023 06:32:04 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.573 | Acc: 85.156% (1635/1920)/ 96.823% (1859/1920)
01/14/2023 06:32:06 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.581 | Acc: 84.668% (1734/2048)/ 96.924% (1985/2048)
01/14/2023 06:32:09 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.590 | Acc: 84.513% (1839/2176)/ 96.783% (2106/2176)
01/14/2023 06:32:11 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.618 | Acc: 84.071% (1937/2304)/ 96.311% (2219/2304)
01/14/2023 06:32:14 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.641 | Acc: 83.512% (2031/2432)/ 96.176% (2339/2432)
01/14/2023 06:32:17 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.650 | Acc: 83.203% (2130/2560)/ 96.016% (2458/2560)
01/14/2023 06:32:19 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.647 | Acc: 83.296% (2239/2688)/ 95.945% (2579/2688)
01/14/2023 06:32:22 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.679 | Acc: 82.635% (2327/2816)/ 95.810% (2698/2816)
01/14/2023 06:32:24 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.677 | Acc: 82.473% (2428/2944)/ 95.788% (2820/2944)
01/14/2023 06:32:27 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.721 | Acc: 81.576% (2506/3072)/ 95.508% (2934/3072)
01/14/2023 06:32:29 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.741 | Acc: 81.062% (2594/3200)/ 95.281% (3049/3200)
01/14/2023 06:32:32 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.767 | Acc: 80.409% (2676/3328)/ 95.042% (3163/3328)
01/14/2023 06:32:35 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.783 | Acc: 79.688% (2754/3456)/ 94.907% (3280/3456)
01/14/2023 06:32:37 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.766 | Acc: 80.218% (2875/3584)/ 94.950% (3403/3584)
01/14/2023 06:32:40 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.775 | Acc: 79.607% (2955/3712)/ 95.016% (3527/3712)
01/14/2023 06:32:42 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.767 | Acc: 79.766% (3063/3840)/ 95.130% (3653/3840)
01/14/2023 06:32:45 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.781 | Acc: 79.713% (3163/3968)/ 95.010% (3770/3968)
01/14/2023 06:32:48 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.776 | Acc: 79.883% (3272/4096)/ 95.068% (3894/4096)
01/14/2023 06:32:50 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.762 | Acc: 80.161% (3386/4224)/ 95.170% (4020/4224)
01/14/2023 06:32:53 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.756 | Acc: 80.285% (3494/4352)/ 95.221% (4144/4352)
01/14/2023 06:32:55 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.742 | Acc: 80.670% (3614/4480)/ 95.268% (4268/4480)
01/14/2023 06:32:58 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.729 | Acc: 81.076% (3736/4608)/ 95.291% (4391/4608)
01/14/2023 06:33:01 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.714 | Acc: 81.524% (3861/4736)/ 95.397% (4518/4736)
01/14/2023 06:33:03 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.705 | Acc: 81.846% (3981/4864)/ 95.456% (4643/4864)
01/14/2023 06:33:06 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.697 | Acc: 82.011% (4094/4992)/ 95.553% (4770/4992)
01/14/2023 06:33:08 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.692 | Acc: 82.070% (4202/5120)/ 95.605% (4895/5120)
01/14/2023 06:33:11 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.690 | Acc: 82.184% (4313/5248)/ 95.503% (5012/5248)
01/14/2023 06:33:14 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.694 | Acc: 82.254% (4422/5376)/ 95.424% (5130/5376)
01/14/2023 06:33:16 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.693 | Acc: 82.286% (4529/5504)/ 95.494% (5256/5504)
01/14/2023 06:33:19 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.690 | Acc: 82.351% (4638/5632)/ 95.437% (5375/5632)
01/14/2023 06:33:22 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.693 | Acc: 82.378% (4745/5760)/ 95.347% (5492/5760)
01/14/2023 06:33:24 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.690 | Acc: 82.558% (4861/5888)/ 95.346% (5614/5888)
01/14/2023 06:33:27 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.693 | Acc: 82.530% (4965/6016)/ 95.379% (5738/6016)
01/14/2023 06:33:30 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.695 | Acc: 82.471% (5067/6144)/ 95.426% (5863/6144)
01/14/2023 06:33:32 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.700 | Acc: 82.318% (5163/6272)/ 95.392% (5983/6272)
01/14/2023 06:33:35 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.703 | Acc: 82.375% (5272/6400)/ 95.312% (6100/6400)
01/14/2023 06:33:38 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.694 | Acc: 82.583% (5391/6528)/ 95.358% (6225/6528)
01/14/2023 06:33:40 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.687 | Acc: 82.767% (5509/6656)/ 95.433% (6352/6656)
01/14/2023 06:33:43 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.683 | Acc: 82.857% (5621/6784)/ 95.460% (6476/6784)
01/14/2023 06:33:45 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.674 | Acc: 83.073% (5742/6912)/ 95.544% (6604/6912)
01/14/2023 06:33:48 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.667 | Acc: 83.210% (5858/7040)/ 95.554% (6727/7040)
01/14/2023 06:33:50 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.661 | Acc: 83.371% (5976/7168)/ 95.592% (6852/7168)
01/14/2023 06:33:53 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.652 | Acc: 83.580% (6098/7296)/ 95.655% (6979/7296)
01/14/2023 06:33:56 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.646 | Acc: 83.769% (6219/7424)/ 95.717% (7106/7424)
01/14/2023 06:33:58 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.644 | Acc: 83.832% (6331/7552)/ 95.710% (7228/7552)
01/14/2023 06:34:01 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.646 | Acc: 83.750% (6432/7680)/ 95.729% (7352/7680)
01/14/2023 06:34:03 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.650 | Acc: 83.645% (6531/7808)/ 95.697% (7472/7808)
01/14/2023 06:34:06 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.651 | Acc: 83.632% (6637/7936)/ 95.716% (7596/7936)
01/14/2023 06:34:09 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.650 | Acc: 83.619% (6743/8064)/ 95.722% (7719/8064)
01/14/2023 06:34:11 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.658 | Acc: 83.496% (6840/8192)/ 95.667% (7837/8192)
01/14/2023 06:34:14 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.667 | Acc: 83.293% (6930/8320)/ 95.601% (7954/8320)
01/14/2023 06:34:17 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.680 | Acc: 82.777% (6993/8448)/ 95.526% (8070/8448)
01/14/2023 06:34:20 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.685 | Acc: 82.801% (7101/8576)/ 95.487% (8189/8576)
01/14/2023 06:34:22 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.688 | Acc: 82.755% (7203/8704)/ 95.496% (8312/8704)
01/14/2023 06:34:25 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.689 | Acc: 82.699% (7304/8832)/ 95.516% (8436/8832)
01/14/2023 06:34:27 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.684 | Acc: 82.801% (7419/8960)/ 95.558% (8562/8960)
01/14/2023 06:34:30 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.686 | Acc: 82.724% (7518/9088)/ 95.555% (8684/9088)
01/14/2023 06:34:33 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.684 | Acc: 82.780% (7629/9216)/ 95.573% (8808/9216)
01/14/2023 06:34:35 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.686 | Acc: 82.673% (7725/9344)/ 95.591% (8932/9344)
01/14/2023 06:34:38 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.690 | Acc: 82.559% (7820/9472)/ 95.598% (9055/9472)
01/14/2023 06:34:40 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.691 | Acc: 82.542% (7924/9600)/ 95.583% (9176/9600)
01/14/2023 06:34:43 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.697 | Acc: 82.350% (8011/9728)/ 95.580% (9298/9728)
01/14/2023 06:34:46 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.697 | Acc: 82.336% (8115/9856)/ 95.576% (9420/9856)
01/14/2023 06:34:48 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.697 | Acc: 82.302% (8217/9984)/ 95.603% (9545/9984)
01/14/2023 06:34:51 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.697 | Acc: 82.209% (8313/10112)/ 95.639% (9671/10112)
01/14/2023 06:34:54 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.696 | Acc: 82.207% (8418/10240)/ 95.664% (9796/10240)
01/14/2023 06:34:56 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.695 | Acc: 82.176% (8520/10368)/ 95.660% (9918/10368)
01/14/2023 06:34:59 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.694 | Acc: 82.203% (8628/10496)/ 95.684% (10043/10496)
01/14/2023 06:35:02 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.694 | Acc: 82.210% (8734/10624)/ 95.680% (10165/10624)
01/14/2023 06:35:04 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.693 | Acc: 82.254% (8844/10752)/ 95.666% (10286/10752)
01/14/2023 06:35:07 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.689 | Acc: 82.381% (8963/10880)/ 95.699% (10412/10880)
01/14/2023 06:35:10 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.688 | Acc: 82.376% (9068/11008)/ 95.739% (10539/11008)
01/14/2023 06:35:12 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.692 | Acc: 82.319% (9167/11136)/ 95.717% (10659/11136)
01/14/2023 06:35:15 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.690 | Acc: 82.342% (9275/11264)/ 95.721% (10782/11264)
01/14/2023 06:35:17 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.698 | Acc: 82.268% (9372/11392)/ 95.664% (10898/11392)
01/14/2023 06:35:20 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.696 | Acc: 82.300% (9481/11520)/ 95.677% (11022/11520)
01/14/2023 06:35:22 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.696 | Acc: 82.194% (9574/11648)/ 95.682% (11145/11648)
01/14/2023 06:35:25 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.695 | Acc: 82.227% (9683/11776)/ 95.695% (11269/11776)
01/14/2023 06:35:28 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.696 | Acc: 82.208% (9786/11904)/ 95.674% (11389/11904)
01/14/2023 06:35:30 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.700 | Acc: 82.023% (9869/12032)/ 95.703% (11515/12032)
01/14/2023 06:35:33 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.702 | Acc: 81.875% (9956/12160)/ 95.715% (11639/12160)
01/14/2023 06:35:36 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.700 | Acc: 81.934% (10068/12288)/ 95.719% (11762/12288)
01/14/2023 06:35:38 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.704 | Acc: 81.822% (10159/12416)/ 95.739% (11887/12416)
01/14/2023 06:35:41 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.705 | Acc: 81.633% (10240/12544)/ 95.759% (12012/12544)
01/14/2023 06:35:44 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.702 | Acc: 81.739% (10358/12672)/ 95.786% (12138/12672)
01/14/2023 06:35:46 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.696 | Acc: 81.891% (10482/12800)/ 95.828% (12266/12800)
01/14/2023 06:35:49 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.695 | Acc: 81.946% (10594/12928)/ 95.846% (12391/12928)
01/14/2023 06:35:52 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.691 | Acc: 82.047% (10712/13056)/ 95.879% (12518/13056)
01/14/2023 06:35:54 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.687 | Acc: 82.168% (10833/13184)/ 95.904% (12644/13184)
01/14/2023 06:35:57 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.689 | Acc: 81.994% (10915/13312)/ 95.928% (12770/13312)
01/14/2023 06:36:00 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.688 | Acc: 81.927% (11011/13440)/ 95.938% (12894/13440)
01/14/2023 06:36:02 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.689 | Acc: 81.913% (11114/13568)/ 95.939% (13017/13568)
01/14/2023 06:36:05 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.698 | Acc: 81.812% (11205/13696)/ 95.867% (13130/13696)
01/14/2023 06:36:07 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.694 | Acc: 81.930% (11326/13824)/ 95.898% (13257/13824)
01/14/2023 06:36:10 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.697 | Acc: 81.809% (11414/13952)/ 95.907% (13381/13952)
01/14/2023 06:36:13 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.698 | Acc: 81.768% (11513/14080)/ 95.916% (13505/14080)
01/14/2023 06:36:15 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.700 | Acc: 81.595% (11593/14208)/ 95.925% (13629/14208)
01/14/2023 06:36:18 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.704 | Acc: 81.550% (11691/14336)/ 95.878% (13745/14336)
01/14/2023 06:36:20 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.704 | Acc: 81.582% (11800/14464)/ 95.893% (13870/14464)
01/14/2023 06:36:23 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.703 | Acc: 81.620% (11910/14592)/ 95.902% (13994/14592)
01/14/2023 06:36:25 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.700 | Acc: 81.712% (12028/14720)/ 95.924% (14120/14720)
01/14/2023 06:36:28 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.697 | Acc: 81.789% (12144/14848)/ 95.946% (14246/14848)
01/14/2023 06:36:31 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.700 | Acc: 81.751% (12243/14976)/ 95.913% (14364/14976)
01/14/2023 06:36:34 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.698 | Acc: 81.773% (12351/15104)/ 95.928% (14489/15104)
01/14/2023 06:36:36 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.702 | Acc: 81.664% (12439/15232)/ 95.943% (14614/15232)
01/14/2023 06:36:39 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.700 | Acc: 81.706% (12550/15360)/ 95.964% (14740/15360)
01/14/2023 06:36:41 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.698 | Acc: 81.747% (12661/15488)/ 95.978% (14865/15488)
01/14/2023 06:36:44 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.703 | Acc: 81.602% (12743/15616)/ 95.953% (14984/15616)
01/14/2023 06:36:47 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.705 | Acc: 81.549% (12839/15744)/ 95.929% (15103/15744)
01/14/2023 06:36:49 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.706 | Acc: 81.565% (12946/15872)/ 95.930% (15226/15872)
01/14/2023 06:36:52 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.705 | Acc: 81.569% (13051/16000)/ 95.944% (15351/16000)
01/14/2023 06:36:55 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.701 | Acc: 81.672% (13172/16128)/ 95.970% (15478/16128)
01/14/2023 06:36:57 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.697 | Acc: 81.767% (13292/16256)/ 95.983% (15603/16256)
01/14/2023 06:37:00 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.695 | Acc: 81.848% (13410/16384)/ 95.990% (15727/16384)
01/14/2023 06:37:03 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.696 | Acc: 81.831% (13512/16512)/ 95.973% (15847/16512)
01/14/2023 06:37:05 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.694 | Acc: 81.845% (13619/16640)/ 95.980% (15971/16640)
01/14/2023 06:37:08 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.691 | Acc: 81.948% (13741/16768)/ 95.998% (16097/16768)
01/14/2023 06:37:10 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.691 | Acc: 81.996% (13854/16896)/ 96.005% (16221/16896)
01/14/2023 06:37:13 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.688 | Acc: 82.066% (13971/17024)/ 96.017% (16346/17024)
01/14/2023 06:37:16 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.690 | Acc: 82.020% (14068/17152)/ 96.012% (16468/17152)
01/14/2023 06:37:18 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.688 | Acc: 82.054% (14179/17280)/ 96.036% (16595/17280)
01/14/2023 06:37:21 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.688 | Acc: 82.043% (14282/17408)/ 96.031% (16717/17408)
01/14/2023 06:37:23 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.686 | Acc: 82.003% (14380/17536)/ 96.054% (16844/17536)
01/14/2023 06:37:26 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.684 | Acc: 82.043% (14492/17664)/ 96.082% (16972/17664)
01/14/2023 06:37:28 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.684 | Acc: 82.065% (14601/17792)/ 96.083% (17095/17792)
01/14/2023 06:37:31 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.689 | Acc: 81.908% (14678/17920)/ 96.071% (17216/17920)
01/14/2023 06:37:33 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.691 | Acc: 81.854% (14773/18048)/ 96.066% (17338/18048)
01/14/2023 06:37:36 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.690 | Acc: 81.888% (14884/18176)/ 96.077% (17463/18176)
01/14/2023 06:37:39 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.687 | Acc: 81.971% (15004/18304)/ 96.088% (17588/18304)
01/14/2023 06:37:41 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.688 | Acc: 81.982% (15111/18432)/ 96.072% (17708/18432)
01/14/2023 06:37:44 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.690 | Acc: 81.956% (15211/18560)/ 96.034% (17824/18560)
01/14/2023 06:37:46 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.693 | Acc: 81.935% (15312/18688)/ 96.008% (17942/18688)
01/14/2023 06:37:49 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.694 | Acc: 81.914% (15413/18816)/ 96.003% (18064/18816)
01/14/2023 06:37:52 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.694 | Acc: 81.920% (15519/18944)/ 95.983% (18183/18944)
01/14/2023 06:37:54 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.696 | Acc: 81.869% (15614/19072)/ 95.984% (18306/19072)
01/14/2023 06:37:57 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.699 | Acc: 81.781% (15702/19200)/ 95.953% (18423/19200)
01/14/2023 06:38:00 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.700 | Acc: 81.731% (15797/19328)/ 95.959% (18547/19328)
01/14/2023 06:38:02 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.700 | Acc: 81.769% (15909/19456)/ 95.960% (18670/19456)
01/14/2023 06:38:05 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.701 | Acc: 81.761% (16012/19584)/ 95.946% (18790/19584)
01/14/2023 06:38:07 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.699 | Acc: 81.813% (16127/19712)/ 95.952% (18914/19712)
01/14/2023 06:38:10 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.699 | Acc: 81.809% (16231/19840)/ 95.927% (19032/19840)
01/14/2023 06:38:13 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.700 | Acc: 81.821% (16338/19968)/ 95.923% (19154/19968)
01/14/2023 06:38:15 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.702 | Acc: 81.738% (16426/20096)/ 95.905% (19273/20096)
01/14/2023 06:38:18 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.703 | Acc: 81.720% (16527/20224)/ 95.881% (19391/20224)
01/14/2023 06:38:21 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.704 | Acc: 81.687% (16625/20352)/ 95.853% (19508/20352)
01/14/2023 06:38:24 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.706 | Acc: 81.660% (16724/20480)/ 95.845% (19629/20480)
01/14/2023 06:38:26 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.706 | Acc: 81.633% (16823/20608)/ 95.827% (19748/20608)
01/14/2023 06:38:29 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.716 | Acc: 81.409% (16881/20736)/ 95.727% (19850/20736)
01/14/2023 06:38:31 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.721 | Acc: 81.317% (16966/20864)/ 95.648% (19956/20864)
01/14/2023 06:38:34 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.724 | Acc: 81.274% (17061/20992)/ 95.636% (20076/20992)
01/14/2023 06:38:37 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.724 | Acc: 81.264% (17163/21120)/ 95.653% (20202/21120)
01/14/2023 06:38:39 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.726 | Acc: 81.179% (17249/21248)/ 95.642% (20322/21248)
01/14/2023 06:38:42 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.726 | Acc: 81.189% (17355/21376)/ 95.626% (20441/21376)
01/14/2023 06:38:44 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.728 | Acc: 81.124% (17445/21504)/ 95.610% (20560/21504)
01/14/2023 06:38:47 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.727 | Acc: 81.134% (17551/21632)/ 95.604% (20681/21632)
01/14/2023 06:38:50 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.729 | Acc: 81.108% (17649/21760)/ 95.565% (20795/21760)
01/14/2023 06:38:52 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.733 | Acc: 81.008% (17731/21888)/ 95.527% (20909/21888)
01/14/2023 06:38:55 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.737 | Acc: 80.946% (17821/22016)/ 95.494% (21024/22016)
01/14/2023 06:38:57 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.738 | Acc: 80.898% (17914/22144)/ 95.493% (21146/22144)
01/14/2023 06:39:00 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.740 | Acc: 80.837% (18004/22272)/ 95.465% (21262/22272)
01/14/2023 06:39:02 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.744 | Acc: 80.754% (18089/22400)/ 95.420% (21374/22400)
01/14/2023 06:39:05 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.743 | Acc: 80.802% (18203/22528)/ 95.428% (21498/22528)
01/14/2023 06:39:07 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.743 | Acc: 80.804% (18307/22656)/ 95.410% (21616/22656)
01/14/2023 06:39:10 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.747 | Acc: 80.732% (18394/22784)/ 95.365% (21728/22784)
01/14/2023 06:39:12 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.749 | Acc: 80.718% (18494/22912)/ 95.347% (21846/22912)
01/14/2023 06:39:15 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.752 | Acc: 80.664% (18585/23040)/ 95.299% (21957/23040)
01/14/2023 06:39:18 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.758 | Acc: 80.538% (18659/23168)/ 95.265% (22071/23168)
01/14/2023 06:39:20 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.764 | Acc: 80.409% (18732/23296)/ 95.201% (22178/23296)
01/14/2023 06:39:23 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.763 | Acc: 80.422% (18838/23424)/ 95.202% (22300/23424)
01/14/2023 06:39:26 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.770 | Acc: 80.299% (18912/23552)/ 95.109% (22400/23552)
01/14/2023 06:39:28 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.769 | Acc: 80.325% (19021/23680)/ 95.097% (22519/23680)
01/14/2023 06:39:31 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.769 | Acc: 80.334% (19126/23808)/ 95.090% (22639/23808)
01/14/2023 06:39:34 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.772 | Acc: 80.297% (19220/23936)/ 95.041% (22749/23936)
01/14/2023 06:39:36 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.777 | Acc: 80.178% (19294/24064)/ 95.013% (22864/24064)
01/14/2023 06:39:39 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.781 | Acc: 80.051% (19366/24192)/ 94.990% (22980/24192)
01/14/2023 06:39:42 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.782 | Acc: 79.992% (19454/24320)/ 94.992% (23102/24320)
01/14/2023 06:39:44 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.787 | Acc: 79.900% (19534/24448)/ 94.965% (23217/24448)
01/14/2023 06:39:47 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.789 | Acc: 79.862% (19627/24576)/ 94.942% (23333/24576)
01/14/2023 06:39:50 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.795 | Acc: 79.748% (19701/24704)/ 94.859% (23434/24704)
01/14/2023 06:39:52 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.795 | Acc: 79.764% (19807/24832)/ 94.857% (23555/24832)
01/14/2023 06:39:55 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.798 | Acc: 79.700% (19893/24960)/ 94.840% (23672/24960)
01/14/2023 06:39:58 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.803 | Acc: 79.624% (19976/25088)/ 94.778% (23778/25088)
01/14/2023 06:40:00 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.806 | Acc: 79.529% (20054/25216)/ 94.734% (23888/25216)
01/14/2023 06:40:03 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.811 | Acc: 79.451% (20136/25344)/ 94.709% (24003/25344)
01/14/2023 06:40:05 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.813 | Acc: 79.413% (20228/25472)/ 94.680% (24117/25472)
01/14/2023 06:40:08 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.812 | Acc: 79.395% (20325/25600)/ 94.684% (24239/25600)
01/14/2023 06:40:10 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.812 | Acc: 79.357% (20417/25728)/ 94.683% (24360/25728)
01/14/2023 06:40:13 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.816 | Acc: 79.274% (20497/25856)/ 94.647% (24472/25856)
01/14/2023 06:40:15 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.817 | Acc: 79.264% (20596/25984)/ 94.639% (24591/25984)
01/14/2023 06:40:18 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.818 | Acc: 79.251% (20694/26112)/ 94.627% (24709/26112)
01/14/2023 06:40:21 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.821 | Acc: 79.162% (20772/26240)/ 94.611% (24826/26240)
01/14/2023 06:40:23 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.824 | Acc: 79.077% (20851/26368)/ 94.581% (24939/26368)
01/14/2023 06:40:26 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.825 | Acc: 79.050% (20945/26496)/ 94.577% (25059/26496)
01/14/2023 06:40:29 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.829 | Acc: 78.970% (21025/26624)/ 94.539% (25170/26624)
01/14/2023 06:40:31 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.830 | Acc: 78.929% (21115/26752)/ 94.505% (25282/26752)
01/14/2023 06:40:34 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.830 | Acc: 78.925% (21215/26880)/ 94.520% (25407/26880)
01/14/2023 06:40:36 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.831 | Acc: 78.914% (21313/27008)/ 94.502% (25523/27008)
01/14/2023 06:40:39 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.834 | Acc: 78.855% (21398/27136)/ 94.476% (25637/27136)
01/14/2023 06:40:41 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.836 | Acc: 78.789% (21481/27264)/ 94.454% (25752/27264)
01/14/2023 06:40:44 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.835 | Acc: 78.789% (21582/27392)/ 94.462% (25875/27392)
01/14/2023 06:40:47 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.836 | Acc: 78.765% (21676/27520)/ 94.466% (25997/27520)
01/14/2023 06:40:49 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.836 | Acc: 78.783% (21782/27648)/ 94.463% (26117/27648)
01/14/2023 06:40:52 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.834 | Acc: 78.823% (21894/27776)/ 94.481% (26243/27776)
01/14/2023 06:40:54 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.839 | Acc: 78.759% (21977/27904)/ 94.420% (26347/27904)
01/14/2023 06:40:57 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.842 | Acc: 78.710% (22064/28032)/ 94.381% (26457/28032)
01/14/2023 06:40:59 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.840 | Acc: 78.743% (22174/28160)/ 94.386% (26579/28160)
01/14/2023 06:41:02 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.838 | Acc: 78.786% (22287/28288)/ 94.404% (26705/28288)
01/14/2023 06:41:05 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.841 | Acc: 78.737% (22374/28416)/ 94.387% (26821/28416)
01/14/2023 06:41:07 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.839 | Acc: 78.787% (22489/28544)/ 94.402% (26946/28544)
01/14/2023 06:41:10 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.839 | Acc: 78.791% (22591/28672)/ 94.392% (27064/28672)
01/14/2023 06:41:12 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.838 | Acc: 78.812% (22698/28800)/ 94.385% (27183/28800)
01/14/2023 06:41:15 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.838 | Acc: 78.806% (22797/28928)/ 94.396% (27307/28928)
01/14/2023 06:41:18 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.838 | Acc: 78.789% (22893/29056)/ 94.400% (27429/29056)
01/14/2023 06:41:20 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.840 | Acc: 78.783% (22992/29184)/ 94.380% (27544/29184)
01/14/2023 06:41:23 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.844 | Acc: 78.705% (23070/29312)/ 94.323% (27648/29312)
01/14/2023 06:41:25 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.848 | Acc: 78.655% (23156/29440)/ 94.283% (27757/29440)
01/14/2023 06:41:28 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.851 | Acc: 78.602% (23241/29568)/ 94.247% (27867/29568)
01/14/2023 06:41:31 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.850 | Acc: 78.596% (23340/29696)/ 94.232% (27983/29696)
01/14/2023 06:41:33 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.849 | Acc: 78.625% (23449/29824)/ 94.246% (28108/29824)
01/14/2023 06:41:35 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.851 | Acc: 78.579% (23536/29952)/ 94.227% (28223/29952)
01/14/2023 06:41:38 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.858 | Acc: 78.457% (23600/30080)/ 94.159% (28323/30080)
01/14/2023 06:41:41 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.858 | Acc: 78.449% (23698/30208)/ 94.154% (28442/30208)
01/14/2023 06:41:43 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.856 | Acc: 78.491% (23811/30336)/ 94.159% (28564/30336)
01/14/2023 06:41:46 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.857 | Acc: 78.489% (23911/30464)/ 94.124% (28674/30464)
01/14/2023 06:41:48 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.856 | Acc: 78.527% (24023/30592)/ 94.132% (28797/30592)
01/14/2023 06:41:51 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.855 | Acc: 78.568% (24136/30720)/ 94.134% (28918/30720)
01/14/2023 06:41:54 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.855 | Acc: 78.585% (24242/30848)/ 94.126% (29036/30848)
01/14/2023 06:41:57 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.858 | Acc: 78.499% (24316/30976)/ 94.086% (29144/30976)
01/14/2023 06:41:59 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.860 | Acc: 78.401% (24386/31104)/ 94.068% (29259/31104)
01/14/2023 06:42:02 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.866 | Acc: 78.266% (24444/31232)/ 94.000% (29358/31232)
01/14/2023 06:42:04 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.866 | Acc: 78.272% (24546/31360)/ 93.999% (29478/31360)
01/14/2023 06:42:07 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.865 | Acc: 78.281% (24649/31488)/ 93.991% (29596/31488)
01/14/2023 06:42:09 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.866 | Acc: 78.261% (24743/31616)/ 93.987% (29715/31616)
01/14/2023 06:42:12 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.872 | Acc: 78.166% (24813/31744)/ 93.917% (29813/31744)
01/14/2023 06:42:15 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.872 | Acc: 78.112% (24896/31872)/ 93.913% (29932/31872)
01/14/2023 06:42:17 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.874 | Acc: 77.984% (24955/32000)/ 93.903% (30049/32000)
01/14/2023 06:42:20 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.873 | Acc: 78.022% (25067/32128)/ 93.921% (30175/32128)
01/14/2023 06:42:23 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.875 | Acc: 77.967% (25149/32256)/ 93.890% (30285/32256)
01/14/2023 06:42:25 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.875 | Acc: 77.992% (25257/32384)/ 93.886% (30404/32384)
01/14/2023 06:42:28 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.876 | Acc: 77.965% (25348/32512)/ 93.870% (30519/32512)
01/14/2023 06:42:30 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.880 | Acc: 77.898% (25426/32640)/ 93.833% (30627/32640)
01/14/2023 06:42:33 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.882 | Acc: 77.866% (25515/32768)/ 93.823% (30744/32768)
01/14/2023 06:42:36 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.887 | Acc: 77.745% (25575/32896)/ 93.790% (30853/32896)
01/14/2023 06:42:38 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.888 | Acc: 77.731% (25670/33024)/ 93.777% (30969/33024)
01/14/2023 06:42:41 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.889 | Acc: 77.721% (25766/33152)/ 93.762% (31084/33152)
01/14/2023 06:42:43 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.893 | Acc: 77.602% (25826/33280)/ 93.744% (31198/33280)
01/14/2023 06:42:46 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.893 | Acc: 77.577% (25917/33408)/ 93.735% (31315/33408)
01/14/2023 06:42:49 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.891 | Acc: 77.621% (26031/33536)/ 93.756% (31442/33536)
01/14/2023 06:42:51 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.890 | Acc: 77.647% (26139/33664)/ 93.762% (31564/33664)
01/14/2023 06:42:54 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.893 | Acc: 77.575% (26214/33792)/ 93.732% (31674/33792)
01/14/2023 06:42:56 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.898 | Acc: 77.509% (26291/33920)/ 93.670% (31773/33920)
01/14/2023 06:42:59 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.898 | Acc: 77.535% (26399/34048)/ 93.674% (31894/34048)
01/14/2023 06:43:01 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.900 | Acc: 77.458% (26472/34176)/ 93.656% (32008/34176)
01/14/2023 06:43:04 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.900 | Acc: 77.492% (26583/34304)/ 93.657% (32128/34304)
01/14/2023 06:43:07 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.899 | Acc: 77.512% (26689/34432)/ 93.654% (32247/34432)
01/14/2023 06:43:09 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.901 | Acc: 77.459% (26770/34560)/ 93.634% (32360/34560)
01/14/2023 06:43:12 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.904 | Acc: 77.393% (26846/34688)/ 93.603% (32469/34688)
01/14/2023 06:43:14 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.904 | Acc: 77.404% (26949/34816)/ 93.598% (32587/34816)
01/14/2023 06:43:17 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.905 | Acc: 77.361% (27033/34944)/ 93.595% (32706/34944)
01/14/2023 06:43:19 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.905 | Acc: 77.367% (27134/35072)/ 93.585% (32822/35072)
01/14/2023 06:43:22 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.905 | Acc: 77.361% (27231/35200)/ 93.588% (32943/35200)
01/14/2023 06:43:24 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.907 | Acc: 77.332% (27320/35328)/ 93.583% (33061/35328)
01/14/2023 06:43:27 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.908 | Acc: 77.301% (27408/35456)/ 93.581% (33180/35456)
01/14/2023 06:43:30 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.908 | Acc: 77.273% (27497/35584)/ 93.565% (33294/35584)
01/14/2023 06:43:32 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.908 | Acc: 77.288% (27601/35712)/ 93.562% (33413/35712)
01/14/2023 06:43:35 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.908 | Acc: 77.296% (27703/35840)/ 93.555% (33530/35840)
01/14/2023 06:43:37 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.909 | Acc: 77.274% (27794/35968)/ 93.550% (33648/35968)
01/14/2023 06:43:40 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.909 | Acc: 77.286% (27897/36096)/ 93.545% (33766/36096)
01/14/2023 06:43:43 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.908 | Acc: 77.319% (28008/36224)/ 93.551% (33888/36224)
01/14/2023 06:43:45 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.909 | Acc: 77.300% (28100/36352)/ 93.544% (34005/36352)
01/14/2023 06:43:48 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.912 | Acc: 77.256% (28183/36480)/ 93.506% (34111/36480)
01/14/2023 06:43:51 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.915 | Acc: 77.210% (28265/36608)/ 93.466% (34216/36608)
01/14/2023 06:43:53 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.916 | Acc: 77.175% (28351/36736)/ 93.456% (34332/36736)
01/14/2023 06:43:56 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.916 | Acc: 77.173% (28449/36864)/ 93.452% (34450/36864)
01/14/2023 06:43:58 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.915 | Acc: 77.192% (28555/36992)/ 93.453% (34570/36992)
01/14/2023 06:44:01 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.917 | Acc: 77.155% (28640/37120)/ 93.419% (34677/37120)
01/14/2023 06:44:03 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.918 | Acc: 77.081% (28711/37248)/ 93.422% (34798/37248)
01/14/2023 06:44:06 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.918 | Acc: 77.090% (28813/37376)/ 93.413% (34914/37376)
01/14/2023 06:44:09 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.920 | Acc: 77.034% (28891/37504)/ 93.393% (35026/37504)
01/14/2023 06:44:11 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.920 | Acc: 77.028% (28987/37632)/ 93.386% (35143/37632)
01/14/2023 06:44:13 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.921 | Acc: 77.010% (29079/37760)/ 93.379% (35260/37760)
01/14/2023 06:44:16 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.920 | Acc: 77.038% (29188/37888)/ 93.383% (35381/37888)
01/14/2023 06:44:19 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.920 | Acc: 77.036% (29286/38016)/ 93.376% (35498/38016)
01/14/2023 06:44:22 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.923 | Acc: 77.013% (29376/38144)/ 93.349% (35607/38144)
01/14/2023 06:44:24 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.924 | Acc: 76.981% (29462/38272)/ 93.321% (35716/38272)
01/14/2023 06:44:27 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.926 | Acc: 76.971% (29557/38400)/ 93.302% (35828/38400)
01/14/2023 06:44:30 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.926 | Acc: 76.978% (29658/38528)/ 93.296% (35945/38528)
01/14/2023 06:44:32 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.926 | Acc: 76.961% (29750/38656)/ 93.284% (36060/38656)
01/14/2023 06:44:35 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.928 | Acc: 76.923% (29834/38784)/ 93.268% (36173/38784)
01/14/2023 06:44:37 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.929 | Acc: 76.902% (29924/38912)/ 93.254% (36287/38912)
01/14/2023 06:44:40 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.928 | Acc: 76.916% (30028/39040)/ 93.258% (36408/39040)
01/14/2023 06:44:43 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.929 | Acc: 76.869% (30108/39168)/ 93.252% (36525/39168)
01/14/2023 06:44:45 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.930 | Acc: 76.855% (30201/39296)/ 93.228% (36635/39296)
01/14/2023 06:44:48 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.931 | Acc: 76.857% (30300/39424)/ 93.212% (36748/39424)
01/14/2023 06:44:50 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.931 | Acc: 76.841% (30392/39552)/ 93.206% (36865/39552)
01/14/2023 06:44:53 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.933 | Acc: 76.835% (30488/39680)/ 93.183% (36975/39680)
01/14/2023 06:44:56 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.933 | Acc: 76.819% (30580/39808)/ 93.172% (37090/39808)
01/14/2023 06:44:58 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.935 | Acc: 76.798% (30670/39936)/ 93.162% (37205/39936)
01/14/2023 06:45:01 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.936 | Acc: 76.782% (30762/40064)/ 93.138% (37315/40064)
01/14/2023 06:45:04 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.934 | Acc: 76.824% (30877/40192)/ 93.158% (37442/40192)
01/14/2023 06:45:06 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.935 | Acc: 76.813% (30971/40320)/ 93.155% (37560/40320)
01/14/2023 06:45:09 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.936 | Acc: 76.797% (31063/40448)/ 93.142% (37674/40448)
01/14/2023 06:45:11 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.938 | Acc: 76.705% (31124/40576)/ 93.119% (37784/40576)
01/14/2023 06:45:14 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.940 | Acc: 76.663% (31205/40704)/ 93.094% (37893/40704)
01/14/2023 06:45:17 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.939 | Acc: 76.695% (31316/40832)/ 93.111% (38019/40832)
01/14/2023 06:45:19 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.941 | Acc: 76.643% (31393/40960)/ 93.083% (38127/40960)
01/14/2023 06:45:22 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.940 | Acc: 76.679% (31506/41088)/ 93.093% (38250/41088)
01/14/2023 06:45:25 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.940 | Acc: 76.698% (31612/41216)/ 93.085% (38366/41216)
01/14/2023 06:45:27 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.941 | Acc: 76.669% (31698/41344)/ 93.078% (38482/41344)
01/14/2023 06:45:30 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.943 | Acc: 76.630% (31780/41472)/ 93.056% (38592/41472)
01/14/2023 06:45:32 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.944 | Acc: 76.627% (31877/41600)/ 93.055% (38711/41600)
01/14/2023 06:45:35 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.943 | Acc: 76.637% (31979/41728)/ 93.055% (38830/41728)
01/14/2023 06:45:38 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.947 | Acc: 76.551% (32041/41856)/ 93.024% (38936/41856)
01/14/2023 06:45:40 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.950 | Acc: 76.465% (32103/41984)/ 92.993% (39042/41984)
01/14/2023 06:45:43 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.952 | Acc: 76.411% (32178/42112)/ 92.971% (39152/42112)
01/14/2023 06:45:45 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.952 | Acc: 76.406% (32274/42240)/ 92.973% (39272/42240)
01/14/2023 06:45:48 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.954 | Acc: 76.367% (32355/42368)/ 92.950% (39381/42368)
01/14/2023 06:45:51 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.954 | Acc: 76.332% (32438/42496)/ 92.959% (39504/42496)
01/14/2023 06:45:54 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.955 | Acc: 76.319% (32530/42624)/ 92.959% (39623/42624)
01/14/2023 06:45:56 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.953 | Acc: 76.345% (32639/42752)/ 92.969% (39746/42752)
01/14/2023 06:45:59 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.955 | Acc: 76.318% (32725/42880)/ 92.950% (39857/42880)
01/14/2023 06:46:02 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.956 | Acc: 76.295% (32813/43008)/ 92.939% (39971/43008)
01/14/2023 06:46:04 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.958 | Acc: 76.252% (32892/43136)/ 92.925% (40084/43136)
01/14/2023 06:46:07 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.958 | Acc: 76.244% (32986/43264)/ 92.918% (40200/43264)
01/14/2023 06:46:09 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.957 | Acc: 76.231% (33078/43392)/ 92.930% (40324/43392)
01/14/2023 06:46:12 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.960 | Acc: 76.195% (33160/43520)/ 92.902% (40431/43520)
01/14/2023 06:46:15 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.960 | Acc: 76.191% (33256/43648)/ 92.911% (40554/43648)
01/14/2023 06:46:17 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.958 | Acc: 76.234% (33372/43776)/ 92.930% (40681/43776)
01/14/2023 06:46:20 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.959 | Acc: 76.175% (33444/43904)/ 92.923% (40797/43904)
01/14/2023 06:46:23 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.958 | Acc: 76.174% (33541/44032)/ 92.926% (40917/44032)
01/14/2023 06:46:26 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.959 | Acc: 76.173% (33638/44160)/ 92.917% (41032/44160)
01/14/2023 06:46:28 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.963 | Acc: 76.106% (33706/44288)/ 92.876% (41133/44288)
01/14/2023 06:46:31 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.964 | Acc: 76.090% (33796/44416)/ 92.863% (41246/44416)
01/14/2023 06:46:34 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.964 | Acc: 76.102% (33899/44544)/ 92.874% (41370/44544)
01/14/2023 06:46:36 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.965 | Acc: 76.079% (33986/44672)/ 92.857% (41481/44672)
01/14/2023 06:46:39 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.965 | Acc: 76.080% (34084/44800)/ 92.868% (41605/44800)
01/14/2023 06:46:41 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.964 | Acc: 76.093% (34187/44928)/ 92.869% (41724/44928)
01/14/2023 06:46:44 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.967 | Acc: 76.036% (34259/45056)/ 92.853% (41836/45056)
01/14/2023 06:46:46 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.967 | Acc: 76.036% (34356/45184)/ 92.849% (41953/45184)
01/14/2023 06:46:49 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.969 | Acc: 75.995% (34435/45312)/ 92.814% (42056/45312)
01/14/2023 06:46:52 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.972 | Acc: 75.940% (34507/45440)/ 92.795% (42166/45440)
01/14/2023 06:46:54 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.974 | Acc: 75.880% (34577/45568)/ 92.784% (42280/45568)
01/14/2023 06:46:57 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.975 | Acc: 75.873% (34671/45696)/ 92.781% (42397/45696)
01/14/2023 06:46:59 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.973 | Acc: 75.908% (34784/45824)/ 92.794% (42522/45824)
01/14/2023 06:47:02 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.972 | Acc: 75.936% (34894/45952)/ 92.797% (42642/45952)
01/14/2023 06:47:04 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.973 | Acc: 75.944% (34995/46080)/ 92.791% (42758/46080)
01/14/2023 06:47:07 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.975 | Acc: 75.918% (35080/46208)/ 92.783% (42873/46208)
01/14/2023 06:47:10 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.974 | Acc: 75.919% (35178/46336)/ 92.790% (42995/46336)
01/14/2023 06:47:12 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.974 | Acc: 75.921% (35276/46464)/ 92.803% (43120/46464)
01/14/2023 06:47:15 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.974 | Acc: 75.910% (35368/46592)/ 92.797% (43236/46592)
01/14/2023 06:47:18 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.973 | Acc: 75.938% (35478/46720)/ 92.806% (43359/46720)
01/14/2023 06:47:20 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.972 | Acc: 75.954% (35583/46848)/ 92.811% (43480/46848)
01/14/2023 06:47:23 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.971 | Acc: 75.990% (35697/46976)/ 92.828% (43607/46976)
01/14/2023 06:47:26 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.970 | Acc: 76.013% (35805/47104)/ 92.841% (43732/47104)
01/14/2023 06:47:28 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.969 | Acc: 76.018% (35905/47232)/ 92.850% (43855/47232)
01/14/2023 06:47:31 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.969 | Acc: 76.039% (36012/47360)/ 92.859% (43978/47360)
01/14/2023 06:47:34 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.969 | Acc: 76.028% (36104/47488)/ 92.859% (44097/47488)
01/14/2023 06:47:36 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.968 | Acc: 76.035% (36205/47616)/ 92.862% (44217/47616)
01/14/2023 06:47:39 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.967 | Acc: 76.083% (36325/47744)/ 92.877% (44343/47744)
01/14/2023 06:47:41 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.965 | Acc: 76.122% (36441/47872)/ 92.885% (44466/47872)
01/14/2023 06:47:44 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.964 | Acc: 76.152% (36553/48000)/ 92.892% (44588/48000)
01/14/2023 06:47:46 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.967 | Acc: 76.083% (36617/48128)/ 92.852% (44688/48128)
01/14/2023 06:47:49 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.968 | Acc: 76.071% (36709/48256)/ 92.840% (44801/48256)
01/14/2023 06:47:52 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.968 | Acc: 76.058% (36800/48384)/ 92.834% (44917/48384)
01/14/2023 06:47:54 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.971 | Acc: 75.987% (36863/48512)/ 92.794% (45016/48512)
01/14/2023 06:47:57 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.972 | Acc: 75.970% (36952/48640)/ 92.800% (45138/48640)
01/14/2023 06:48:00 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.971 | Acc: 75.968% (37048/48768)/ 92.807% (45260/48768)
01/14/2023 06:48:02 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.973 | Acc: 75.918% (37121/48896)/ 92.805% (45378/48896)
01/14/2023 06:48:05 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.975 | Acc: 75.883% (37201/49024)/ 92.791% (45490/49024)
01/14/2023 06:48:07 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.975 | Acc: 75.891% (37302/49152)/ 92.786% (45606/49152)
01/14/2023 06:48:10 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.973 | Acc: 75.931% (37419/49280)/ 92.798% (45731/49280)
01/14/2023 06:48:13 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.972 | Acc: 75.941% (37521/49408)/ 92.807% (45854/49408)
01/14/2023 06:48:15 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.970 | Acc: 75.987% (37641/49536)/ 92.821% (45980/49536)
01/14/2023 06:48:18 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.968 | Acc: 76.027% (37758/49664)/ 92.832% (46104/49664)
01/14/2023 06:48:20 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.966 | Acc: 76.074% (37879/49792)/ 92.844% (46229/49792)
01/14/2023 06:48:23 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.966 | Acc: 76.076% (37977/49920)/ 92.847% (46349/49920)
01/14/2023 06:48:25 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.968 | Acc: 76.026% (38013/50000)/ 92.838% (46419/50000)
01/14/2023 06:48:25 - INFO - __main__ -   Final accuracy: 76.026
01/14/2023 06:48:25 - INFO - __main__ -   {'milestones': Counter({2: 1, 3: 1, 4: 1}), 'gamma': 0.1, 'base_lrs': [0.00025], 'last_epoch': 2, '_step_count': 3, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [2.5e-05]}
01/14/2023 06:48:25 - INFO - __main__ -   
Epoch: 2
01/14/2023 06:48:28 - INFO - __main__ -   test: [epoch: 2 | batch: 0/10010 ] | Loss: 0.972 | Acc: 77.344% (99/128)
01/14/2023 06:52:51 - INFO - __main__ -   test: [epoch: 2 | batch: 100/10010 ] | Loss: 0.831 | Acc: 79.680% (10301/12928)
01/14/2023 06:57:13 - INFO - __main__ -   test: [epoch: 2 | batch: 200/10010 ] | Loss: 0.839 | Acc: 79.069% (20343/25728)
01/14/2023 07:01:35 - INFO - __main__ -   test: [epoch: 2 | batch: 300/10010 ] | Loss: 0.844 | Acc: 79.028% (30448/38528)
01/14/2023 07:05:56 - INFO - __main__ -   test: [epoch: 2 | batch: 400/10010 ] | Loss: 0.850 | Acc: 78.856% (40475/51328)
01/14/2023 07:10:20 - INFO - __main__ -   test: [epoch: 2 | batch: 500/10010 ] | Loss: 0.854 | Acc: 78.810% (50539/64128)
01/14/2023 07:14:42 - INFO - __main__ -   test: [epoch: 2 | batch: 600/10010 ] | Loss: 0.858 | Acc: 78.740% (60573/76928)
01/14/2023 07:19:07 - INFO - __main__ -   test: [epoch: 2 | batch: 700/10010 ] | Loss: 0.859 | Acc: 78.676% (70594/89728)
01/14/2023 07:23:27 - INFO - __main__ -   test: [epoch: 2 | batch: 800/10010 ] | Loss: 0.860 | Acc: 78.645% (80633/102528)
01/14/2023 07:27:48 - INFO - __main__ -   test: [epoch: 2 | batch: 900/10010 ] | Loss: 0.858 | Acc: 78.699% (90762/115328)
01/14/2023 07:32:09 - INFO - __main__ -   test: [epoch: 2 | batch: 1000/10010 ] | Loss: 0.860 | Acc: 78.634% (100752/128128)
01/14/2023 07:36:31 - INFO - __main__ -   test: [epoch: 2 | batch: 1100/10010 ] | Loss: 0.861 | Acc: 78.629% (110810/140928)
01/14/2023 07:40:54 - INFO - __main__ -   test: [epoch: 2 | batch: 1200/10010 ] | Loss: 0.863 | Acc: 78.587% (120810/153728)
01/14/2023 07:45:15 - INFO - __main__ -   test: [epoch: 2 | batch: 1300/10010 ] | Loss: 0.861 | Acc: 78.611% (130910/166528)
01/14/2023 07:49:35 - INFO - __main__ -   test: [epoch: 2 | batch: 1400/10010 ] | Loss: 0.861 | Acc: 78.634% (141013/179328)
01/14/2023 07:53:56 - INFO - __main__ -   test: [epoch: 2 | batch: 1500/10010 ] | Loss: 0.862 | Acc: 78.595% (151003/192128)
01/14/2023 07:58:17 - INFO - __main__ -   test: [epoch: 2 | batch: 1600/10010 ] | Loss: 0.862 | Acc: 78.566% (161003/204928)
01/14/2023 08:02:39 - INFO - __main__ -   test: [epoch: 2 | batch: 1700/10010 ] | Loss: 0.862 | Acc: 78.556% (171038/217728)
01/14/2023 08:06:59 - INFO - __main__ -   test: [epoch: 2 | batch: 1800/10010 ] | Loss: 0.861 | Acc: 78.563% (181109/230528)
01/14/2023 08:11:20 - INFO - __main__ -   test: [epoch: 2 | batch: 1900/10010 ] | Loss: 0.860 | Acc: 78.584% (191217/243328)
01/14/2023 08:15:40 - INFO - __main__ -   test: [epoch: 2 | batch: 2000/10010 ] | Loss: 0.859 | Acc: 78.597% (201310/256128)
01/14/2023 08:20:01 - INFO - __main__ -   test: [epoch: 2 | batch: 2100/10010 ] | Loss: 0.859 | Acc: 78.598% (211371/268928)
01/14/2023 08:24:22 - INFO - __main__ -   test: [epoch: 2 | batch: 2200/10010 ] | Loss: 0.860 | Acc: 78.579% (221378/281728)
01/14/2023 08:28:43 - INFO - __main__ -   test: [epoch: 2 | batch: 2300/10010 ] | Loss: 0.861 | Acc: 78.561% (231383/294528)
01/14/2023 08:33:04 - INFO - __main__ -   test: [epoch: 2 | batch: 2400/10010 ] | Loss: 0.861 | Acc: 78.563% (241445/307328)
01/14/2023 08:37:23 - INFO - __main__ -   test: [epoch: 2 | batch: 2500/10010 ] | Loss: 0.861 | Acc: 78.555% (251477/320128)
01/14/2023 08:41:42 - INFO - __main__ -   test: [epoch: 2 | batch: 2600/10010 ] | Loss: 0.861 | Acc: 78.569% (261577/332928)
01/14/2023 08:46:04 - INFO - __main__ -   test: [epoch: 2 | batch: 2700/10010 ] | Loss: 0.860 | Acc: 78.602% (271748/345728)
01/14/2023 08:50:26 - INFO - __main__ -   test: [epoch: 2 | batch: 2800/10010 ] | Loss: 0.860 | Acc: 78.595% (281784/358528)
01/14/2023 08:54:48 - INFO - __main__ -   test: [epoch: 2 | batch: 2900/10010 ] | Loss: 0.860 | Acc: 78.591% (291831/371328)
01/14/2023 08:59:09 - INFO - __main__ -   test: [epoch: 2 | batch: 3000/10010 ] | Loss: 0.860 | Acc: 78.589% (301881/384128)
01/14/2023 09:03:31 - INFO - __main__ -   test: [epoch: 2 | batch: 3100/10010 ] | Loss: 0.860 | Acc: 78.598% (311978/396928)
01/14/2023 09:07:53 - INFO - __main__ -   test: [epoch: 2 | batch: 3200/10010 ] | Loss: 0.860 | Acc: 78.601% (322051/409728)
01/14/2023 09:12:13 - INFO - __main__ -   test: [epoch: 2 | batch: 3300/10010 ] | Loss: 0.860 | Acc: 78.584% (332040/422528)
01/14/2023 09:16:32 - INFO - __main__ -   test: [epoch: 2 | batch: 3400/10010 ] | Loss: 0.860 | Acc: 78.595% (342144/435328)
01/14/2023 09:20:53 - INFO - __main__ -   test: [epoch: 2 | batch: 3500/10010 ] | Loss: 0.860 | Acc: 78.595% (352206/448128)
01/14/2023 09:25:14 - INFO - __main__ -   test: [epoch: 2 | batch: 3600/10010 ] | Loss: 0.860 | Acc: 78.611% (362338/460928)
01/14/2023 09:29:36 - INFO - __main__ -   test: [epoch: 2 | batch: 3700/10010 ] | Loss: 0.860 | Acc: 78.597% (372335/473728)
01/14/2023 09:33:56 - INFO - __main__ -   test: [epoch: 2 | batch: 3800/10010 ] | Loss: 0.859 | Acc: 78.618% (382499/486528)
01/14/2023 09:38:18 - INFO - __main__ -   test: [epoch: 2 | batch: 3900/10010 ] | Loss: 0.859 | Acc: 78.609% (392519/499328)
01/14/2023 09:42:39 - INFO - __main__ -   test: [epoch: 2 | batch: 4000/10010 ] | Loss: 0.860 | Acc: 78.593% (402498/512128)
01/14/2023 09:47:01 - INFO - __main__ -   test: [epoch: 2 | batch: 4100/10010 ] | Loss: 0.860 | Acc: 78.596% (412572/524928)
01/14/2023 09:51:22 - INFO - __main__ -   test: [epoch: 2 | batch: 4200/10010 ] | Loss: 0.860 | Acc: 78.592% (422612/537728)
01/14/2023 09:55:43 - INFO - __main__ -   test: [epoch: 2 | batch: 4300/10010 ] | Loss: 0.860 | Acc: 78.592% (432671/550528)
01/14/2023 10:00:01 - INFO - __main__ -   test: [epoch: 2 | batch: 4400/10010 ] | Loss: 0.860 | Acc: 78.603% (442791/563328)
01/14/2023 10:04:21 - INFO - __main__ -   test: [epoch: 2 | batch: 4500/10010 ] | Loss: 0.860 | Acc: 78.595% (452807/576128)
01/14/2023 10:08:42 - INFO - __main__ -   test: [epoch: 2 | batch: 4600/10010 ] | Loss: 0.860 | Acc: 78.584% (462801/588928)
01/14/2023 10:13:04 - INFO - __main__ -   test: [epoch: 2 | batch: 4700/10010 ] | Loss: 0.860 | Acc: 78.582% (472852/601728)
01/14/2023 10:17:25 - INFO - __main__ -   test: [epoch: 2 | batch: 4800/10010 ] | Loss: 0.860 | Acc: 78.588% (482945/614528)
01/14/2023 10:21:47 - INFO - __main__ -   test: [epoch: 2 | batch: 4900/10010 ] | Loss: 0.860 | Acc: 78.585% (492985/627328)
01/14/2023 10:26:11 - INFO - __main__ -   test: [epoch: 2 | batch: 5000/10010 ] | Loss: 0.860 | Acc: 78.602% (503153/640128)
01/14/2023 10:30:32 - INFO - __main__ -   test: [epoch: 2 | batch: 5100/10010 ] | Loss: 0.860 | Acc: 78.590% (513133/652928)
01/14/2023 10:34:54 - INFO - __main__ -   test: [epoch: 2 | batch: 5200/10010 ] | Loss: 0.860 | Acc: 78.586% (523171/665728)
01/14/2023 10:39:15 - INFO - __main__ -   test: [epoch: 2 | batch: 5300/10010 ] | Loss: 0.861 | Acc: 78.579% (533180/678528)
01/14/2023 10:43:38 - INFO - __main__ -   test: [epoch: 2 | batch: 5400/10010 ] | Loss: 0.861 | Acc: 78.573% (543200/691328)
01/14/2023 10:47:59 - INFO - __main__ -   test: [epoch: 2 | batch: 5500/10010 ] | Loss: 0.861 | Acc: 78.571% (553237/704128)
01/14/2023 10:52:22 - INFO - __main__ -   test: [epoch: 2 | batch: 5600/10010 ] | Loss: 0.861 | Acc: 78.575% (563327/716928)
01/14/2023 10:56:43 - INFO - __main__ -   test: [epoch: 2 | batch: 5700/10010 ] | Loss: 0.861 | Acc: 78.579% (573410/729728)
01/14/2023 11:01:03 - INFO - __main__ -   test: [epoch: 2 | batch: 5800/10010 ] | Loss: 0.860 | Acc: 78.583% (583504/742528)
01/14/2023 11:05:25 - INFO - __main__ -   test: [epoch: 2 | batch: 5900/10010 ] | Loss: 0.860 | Acc: 78.594% (593639/755328)
01/14/2023 11:09:46 - INFO - __main__ -   test: [epoch: 2 | batch: 6000/10010 ] | Loss: 0.860 | Acc: 78.591% (603683/768128)
01/14/2023 11:14:06 - INFO - __main__ -   test: [epoch: 2 | batch: 6100/10010 ] | Loss: 0.861 | Acc: 78.579% (613646/780928)
01/14/2023 11:18:29 - INFO - __main__ -   test: [epoch: 2 | batch: 6200/10010 ] | Loss: 0.861 | Acc: 78.578% (623698/793728)
01/14/2023 11:22:49 - INFO - __main__ -   test: [epoch: 2 | batch: 6300/10010 ] | Loss: 0.861 | Acc: 78.581% (633780/806528)
01/14/2023 11:27:11 - INFO - __main__ -   test: [epoch: 2 | batch: 6400/10010 ] | Loss: 0.861 | Acc: 78.574% (643776/819328)
01/14/2023 11:31:31 - INFO - __main__ -   test: [epoch: 2 | batch: 6500/10010 ] | Loss: 0.861 | Acc: 78.579% (653881/832128)
01/14/2023 11:35:53 - INFO - __main__ -   test: [epoch: 2 | batch: 6600/10010 ] | Loss: 0.861 | Acc: 78.575% (663902/844928)
01/14/2023 11:40:14 - INFO - __main__ -   test: [epoch: 2 | batch: 6700/10010 ] | Loss: 0.861 | Acc: 78.573% (673940/857728)
01/14/2023 11:44:35 - INFO - __main__ -   test: [epoch: 2 | batch: 6800/10010 ] | Loss: 0.861 | Acc: 78.572% (683989/870528)
01/14/2023 11:48:55 - INFO - __main__ -   test: [epoch: 2 | batch: 6900/10010 ] | Loss: 0.861 | Acc: 78.576% (694086/883328)
01/14/2023 11:53:14 - INFO - __main__ -   test: [epoch: 2 | batch: 7000/10010 ] | Loss: 0.861 | Acc: 78.571% (704097/896128)
01/14/2023 11:57:35 - INFO - __main__ -   test: [epoch: 2 | batch: 7100/10010 ] | Loss: 0.861 | Acc: 78.577% (714205/908928)
01/14/2023 12:01:56 - INFO - __main__ -   test: [epoch: 2 | batch: 7200/10010 ] | Loss: 0.860 | Acc: 78.580% (724294/921728)
01/14/2023 12:06:19 - INFO - __main__ -   test: [epoch: 2 | batch: 7300/10010 ] | Loss: 0.860 | Acc: 78.577% (734323/934528)
01/14/2023 12:10:39 - INFO - __main__ -   test: [epoch: 2 | batch: 7400/10010 ] | Loss: 0.860 | Acc: 78.580% (744413/947328)
01/14/2023 12:15:02 - INFO - __main__ -   test: [epoch: 2 | batch: 7500/10010 ] | Loss: 0.860 | Acc: 78.586% (754528/960128)
01/14/2023 12:19:22 - INFO - __main__ -   test: [epoch: 2 | batch: 7600/10010 ] | Loss: 0.860 | Acc: 78.595% (764672/972928)
01/14/2023 12:23:43 - INFO - __main__ -   test: [epoch: 2 | batch: 7700/10010 ] | Loss: 0.860 | Acc: 78.591% (774698/985728)
01/14/2023 12:28:07 - INFO - __main__ -   test: [epoch: 2 | batch: 7800/10010 ] | Loss: 0.860 | Acc: 78.588% (784721/998528)
01/14/2023 12:32:28 - INFO - __main__ -   test: [epoch: 2 | batch: 7900/10010 ] | Loss: 0.860 | Acc: 78.590% (794806/1011328)
01/14/2023 12:36:47 - INFO - __main__ -   test: [epoch: 2 | batch: 8000/10010 ] | Loss: 0.860 | Acc: 78.588% (804846/1024128)
01/14/2023 12:41:10 - INFO - __main__ -   test: [epoch: 2 | batch: 8100/10010 ] | Loss: 0.860 | Acc: 78.591% (814929/1036928)
01/14/2023 12:45:32 - INFO - __main__ -   test: [epoch: 2 | batch: 8200/10010 ] | Loss: 0.860 | Acc: 78.590% (824982/1049728)
01/14/2023 12:49:54 - INFO - __main__ -   test: [epoch: 2 | batch: 8300/10010 ] | Loss: 0.860 | Acc: 78.589% (835025/1062528)
01/14/2023 12:54:16 - INFO - __main__ -   test: [epoch: 2 | batch: 8400/10010 ] | Loss: 0.860 | Acc: 78.591% (845108/1075328)
01/14/2023 12:58:37 - INFO - __main__ -   test: [epoch: 2 | batch: 8500/10010 ] | Loss: 0.860 | Acc: 78.596% (855222/1088128)
01/14/2023 13:02:58 - INFO - __main__ -   test: [epoch: 2 | batch: 8600/10010 ] | Loss: 0.860 | Acc: 78.601% (865336/1100928)
01/14/2023 13:07:20 - INFO - __main__ -   test: [epoch: 2 | batch: 8700/10010 ] | Loss: 0.860 | Acc: 78.603% (875422/1113728)
01/14/2023 13:11:41 - INFO - __main__ -   test: [epoch: 2 | batch: 8800/10010 ] | Loss: 0.860 | Acc: 78.607% (885533/1126528)
01/14/2023 13:16:04 - INFO - __main__ -   test: [epoch: 2 | batch: 8900/10010 ] | Loss: 0.860 | Acc: 78.607% (895596/1139328)
01/14/2023 13:20:26 - INFO - __main__ -   test: [epoch: 2 | batch: 9000/10010 ] | Loss: 0.860 | Acc: 78.599% (905557/1152128)
01/14/2023 13:24:47 - INFO - __main__ -   test: [epoch: 2 | batch: 9100/10010 ] | Loss: 0.860 | Acc: 78.594% (915561/1164928)
01/14/2023 13:29:09 - INFO - __main__ -   test: [epoch: 2 | batch: 9200/10010 ] | Loss: 0.860 | Acc: 78.597% (925664/1177728)
01/14/2023 13:33:29 - INFO - __main__ -   test: [epoch: 2 | batch: 9300/10010 ] | Loss: 0.860 | Acc: 78.593% (935677/1190528)
01/14/2023 13:37:50 - INFO - __main__ -   test: [epoch: 2 | batch: 9400/10010 ] | Loss: 0.860 | Acc: 78.595% (945756/1203328)
01/14/2023 13:42:12 - INFO - __main__ -   test: [epoch: 2 | batch: 9500/10010 ] | Loss: 0.860 | Acc: 78.590% (955759/1216128)
01/14/2023 13:46:33 - INFO - __main__ -   test: [epoch: 2 | batch: 9600/10010 ] | Loss: 0.860 | Acc: 78.591% (965831/1228928)
01/14/2023 13:50:56 - INFO - __main__ -   test: [epoch: 2 | batch: 9700/10010 ] | Loss: 0.861 | Acc: 78.585% (975814/1241728)
01/14/2023 13:55:19 - INFO - __main__ -   test: [epoch: 2 | batch: 9800/10010 ] | Loss: 0.861 | Acc: 78.584% (985858/1254528)
01/14/2023 13:59:43 - INFO - __main__ -   test: [epoch: 2 | batch: 9900/10010 ] | Loss: 0.861 | Acc: 78.586% (995938/1267328)
01/14/2023 14:04:06 - INFO - __main__ -   test: [epoch: 2 | batch: 10000/10010 ] | Loss: 0.861 | Acc: 78.582% (1005948/1280128)
01/14/2023 14:04:30 - INFO - __main__ -   Saving Checkpoint
01/14/2023 14:04:32 - INFO - __main__ -   test: [batch: 0/391 ] | Loss: 0.480 | Acc: 86.719% (111/128)/ 96.875% (124/128)
01/14/2023 14:04:35 - INFO - __main__ -   test: [batch: 1/391 ] | Loss: 0.481 | Acc: 86.719% (222/256)/ 97.656% (250/256)
01/14/2023 14:04:37 - INFO - __main__ -   test: [batch: 2/391 ] | Loss: 0.627 | Acc: 83.333% (320/384)/ 95.573% (367/384)
01/14/2023 14:04:40 - INFO - __main__ -   test: [batch: 3/391 ] | Loss: 0.582 | Acc: 84.961% (435/512)/ 96.094% (492/512)
01/14/2023 14:04:43 - INFO - __main__ -   test: [batch: 4/391 ] | Loss: 0.498 | Acc: 87.344% (559/640)/ 96.875% (620/640)
01/14/2023 14:04:45 - INFO - __main__ -   test: [batch: 5/391 ] | Loss: 0.440 | Acc: 88.411% (679/768)/ 97.396% (748/768)
01/14/2023 14:04:48 - INFO - __main__ -   test: [batch: 6/391 ] | Loss: 0.432 | Acc: 88.504% (793/896)/ 97.321% (872/896)
01/14/2023 14:04:51 - INFO - __main__ -   test: [batch: 7/391 ] | Loss: 0.412 | Acc: 89.355% (915/1024)/ 97.461% (998/1024)
01/14/2023 14:04:53 - INFO - __main__ -   test: [batch: 8/391 ] | Loss: 0.429 | Acc: 89.062% (1026/1152)/ 97.396% (1122/1152)
01/14/2023 14:04:56 - INFO - __main__ -   test: [batch: 9/391 ] | Loss: 0.408 | Acc: 89.609% (1147/1280)/ 97.500% (1248/1280)
01/14/2023 14:04:58 - INFO - __main__ -   test: [batch: 10/391 ] | Loss: 0.456 | Acc: 88.352% (1244/1408)/ 97.514% (1373/1408)
01/14/2023 14:05:01 - INFO - __main__ -   test: [batch: 11/391 ] | Loss: 0.460 | Acc: 88.477% (1359/1536)/ 97.461% (1497/1536)
01/14/2023 14:05:04 - INFO - __main__ -   test: [batch: 12/391 ] | Loss: 0.505 | Acc: 87.440% (1455/1664)/ 97.175% (1617/1664)
01/14/2023 14:05:06 - INFO - __main__ -   test: [batch: 13/391 ] | Loss: 0.551 | Acc: 85.882% (1539/1792)/ 96.708% (1733/1792)
01/14/2023 14:05:09 - INFO - __main__ -   test: [batch: 14/391 ] | Loss: 0.573 | Acc: 85.052% (1633/1920)/ 96.771% (1858/1920)
01/14/2023 14:05:11 - INFO - __main__ -   test: [batch: 15/391 ] | Loss: 0.582 | Acc: 84.570% (1732/2048)/ 96.875% (1984/2048)
01/14/2023 14:05:14 - INFO - __main__ -   test: [batch: 16/391 ] | Loss: 0.590 | Acc: 84.421% (1837/2176)/ 96.691% (2104/2176)
01/14/2023 14:05:17 - INFO - __main__ -   test: [batch: 17/391 ] | Loss: 0.615 | Acc: 84.028% (1936/2304)/ 96.224% (2217/2304)
01/14/2023 14:05:19 - INFO - __main__ -   test: [batch: 18/391 ] | Loss: 0.639 | Acc: 83.429% (2029/2432)/ 96.053% (2336/2432)
01/14/2023 14:05:22 - INFO - __main__ -   test: [batch: 19/391 ] | Loss: 0.646 | Acc: 83.203% (2130/2560)/ 95.898% (2455/2560)
01/14/2023 14:05:24 - INFO - __main__ -   test: [batch: 20/391 ] | Loss: 0.644 | Acc: 83.371% (2241/2688)/ 95.796% (2575/2688)
01/14/2023 14:05:27 - INFO - __main__ -   test: [batch: 21/391 ] | Loss: 0.676 | Acc: 82.635% (2327/2816)/ 95.632% (2693/2816)
01/14/2023 14:05:30 - INFO - __main__ -   test: [batch: 22/391 ] | Loss: 0.675 | Acc: 82.507% (2429/2944)/ 95.618% (2815/2944)
01/14/2023 14:05:32 - INFO - __main__ -   test: [batch: 23/391 ] | Loss: 0.718 | Acc: 81.673% (2509/3072)/ 95.280% (2927/3072)
01/14/2023 14:05:35 - INFO - __main__ -   test: [batch: 24/391 ] | Loss: 0.737 | Acc: 81.156% (2597/3200)/ 95.125% (3044/3200)
01/14/2023 14:05:38 - INFO - __main__ -   test: [batch: 25/391 ] | Loss: 0.762 | Acc: 80.499% (2679/3328)/ 94.922% (3159/3328)
01/14/2023 14:05:40 - INFO - __main__ -   test: [batch: 26/391 ] | Loss: 0.776 | Acc: 79.774% (2757/3456)/ 94.907% (3280/3456)
01/14/2023 14:05:43 - INFO - __main__ -   test: [batch: 27/391 ] | Loss: 0.758 | Acc: 80.301% (2878/3584)/ 94.950% (3403/3584)
01/14/2023 14:05:45 - INFO - __main__ -   test: [batch: 28/391 ] | Loss: 0.768 | Acc: 79.768% (2961/3712)/ 95.016% (3527/3712)
01/14/2023 14:05:48 - INFO - __main__ -   test: [batch: 29/391 ] | Loss: 0.760 | Acc: 79.922% (3069/3840)/ 95.130% (3653/3840)
01/14/2023 14:05:50 - INFO - __main__ -   test: [batch: 30/391 ] | Loss: 0.773 | Acc: 79.889% (3170/3968)/ 95.010% (3770/3968)
01/14/2023 14:05:53 - INFO - __main__ -   test: [batch: 31/391 ] | Loss: 0.768 | Acc: 80.078% (3280/4096)/ 95.068% (3894/4096)
01/14/2023 14:05:56 - INFO - __main__ -   test: [batch: 32/391 ] | Loss: 0.754 | Acc: 80.350% (3394/4224)/ 95.170% (4020/4224)
01/14/2023 14:05:58 - INFO - __main__ -   test: [batch: 33/391 ] | Loss: 0.748 | Acc: 80.492% (3503/4352)/ 95.221% (4144/4352)
01/14/2023 14:06:01 - INFO - __main__ -   test: [batch: 34/391 ] | Loss: 0.735 | Acc: 80.871% (3623/4480)/ 95.268% (4268/4480)
01/14/2023 14:06:03 - INFO - __main__ -   test: [batch: 35/391 ] | Loss: 0.722 | Acc: 81.272% (3745/4608)/ 95.269% (4390/4608)
01/14/2023 14:06:06 - INFO - __main__ -   test: [batch: 36/391 ] | Loss: 0.708 | Acc: 81.715% (3870/4736)/ 95.376% (4517/4736)
01/14/2023 14:06:09 - INFO - __main__ -   test: [batch: 37/391 ] | Loss: 0.699 | Acc: 82.011% (3989/4864)/ 95.436% (4642/4864)
01/14/2023 14:06:11 - INFO - __main__ -   test: [batch: 38/391 ] | Loss: 0.691 | Acc: 82.171% (4102/4992)/ 95.493% (4767/4992)
01/14/2023 14:06:14 - INFO - __main__ -   test: [batch: 39/391 ] | Loss: 0.686 | Acc: 82.207% (4209/5120)/ 95.527% (4891/5120)
01/14/2023 14:06:16 - INFO - __main__ -   test: [batch: 40/391 ] | Loss: 0.684 | Acc: 82.336% (4321/5248)/ 95.446% (5009/5248)
01/14/2023 14:06:19 - INFO - __main__ -   test: [batch: 41/391 ] | Loss: 0.688 | Acc: 82.422% (4431/5376)/ 95.387% (5128/5376)
01/14/2023 14:06:22 - INFO - __main__ -   test: [batch: 42/391 ] | Loss: 0.688 | Acc: 82.395% (4535/5504)/ 95.440% (5253/5504)
01/14/2023 14:06:24 - INFO - __main__ -   test: [batch: 43/391 ] | Loss: 0.685 | Acc: 82.457% (4644/5632)/ 95.401% (5373/5632)
01/14/2023 14:06:27 - INFO - __main__ -   test: [batch: 44/391 ] | Loss: 0.689 | Acc: 82.465% (4750/5760)/ 95.312% (5490/5760)
01/14/2023 14:06:30 - INFO - __main__ -   test: [batch: 45/391 ] | Loss: 0.686 | Acc: 82.626% (4865/5888)/ 95.312% (5612/5888)
01/14/2023 14:06:32 - INFO - __main__ -   test: [batch: 46/391 ] | Loss: 0.689 | Acc: 82.613% (4970/6016)/ 95.346% (5736/6016)
01/14/2023 14:06:35 - INFO - __main__ -   test: [batch: 47/391 ] | Loss: 0.690 | Acc: 82.536% (5071/6144)/ 95.394% (5861/6144)
01/14/2023 14:06:37 - INFO - __main__ -   test: [batch: 48/391 ] | Loss: 0.695 | Acc: 82.382% (5167/6272)/ 95.360% (5981/6272)
01/14/2023 14:06:40 - INFO - __main__ -   test: [batch: 49/391 ] | Loss: 0.699 | Acc: 82.422% (5275/6400)/ 95.281% (6098/6400)
01/14/2023 14:06:43 - INFO - __main__ -   test: [batch: 50/391 ] | Loss: 0.690 | Acc: 82.629% (5394/6528)/ 95.328% (6223/6528)
01/14/2023 14:06:45 - INFO - __main__ -   test: [batch: 51/391 ] | Loss: 0.683 | Acc: 82.828% (5513/6656)/ 95.373% (6348/6656)
01/14/2023 14:06:48 - INFO - __main__ -   test: [batch: 52/391 ] | Loss: 0.681 | Acc: 82.886% (5623/6784)/ 95.401% (6472/6784)
01/14/2023 14:06:51 - INFO - __main__ -   test: [batch: 53/391 ] | Loss: 0.671 | Acc: 83.087% (5743/6912)/ 95.472% (6599/6912)
01/14/2023 14:06:54 - INFO - __main__ -   test: [batch: 54/391 ] | Loss: 0.664 | Acc: 83.239% (5860/7040)/ 95.526% (6725/7040)
01/14/2023 14:06:56 - INFO - __main__ -   test: [batch: 55/391 ] | Loss: 0.658 | Acc: 83.398% (5978/7168)/ 95.564% (6850/7168)
01/14/2023 14:06:59 - INFO - __main__ -   test: [batch: 56/391 ] | Loss: 0.650 | Acc: 83.607% (6100/7296)/ 95.614% (6976/7296)
01/14/2023 14:07:01 - INFO - __main__ -   test: [batch: 57/391 ] | Loss: 0.643 | Acc: 83.809% (6222/7424)/ 95.676% (7103/7424)
01/14/2023 14:07:04 - INFO - __main__ -   test: [batch: 58/391 ] | Loss: 0.641 | Acc: 83.859% (6333/7552)/ 95.670% (7225/7552)
01/14/2023 14:07:07 - INFO - __main__ -   test: [batch: 59/391 ] | Loss: 0.644 | Acc: 83.776% (6434/7680)/ 95.690% (7349/7680)
01/14/2023 14:07:09 - INFO - __main__ -   test: [batch: 60/391 ] | Loss: 0.648 | Acc: 83.671% (6533/7808)/ 95.671% (7470/7808)
01/14/2023 14:07:12 - INFO - __main__ -   test: [batch: 61/391 ] | Loss: 0.648 | Acc: 83.682% (6641/7936)/ 95.703% (7595/7936)
01/14/2023 14:07:15 - INFO - __main__ -   test: [batch: 62/391 ] | Loss: 0.647 | Acc: 83.656% (6746/8064)/ 95.709% (7718/8064)
01/14/2023 14:07:17 - INFO - __main__ -   test: [batch: 63/391 ] | Loss: 0.656 | Acc: 83.521% (6842/8192)/ 95.654% (7836/8192)
01/14/2023 14:07:20 - INFO - __main__ -   test: [batch: 64/391 ] | Loss: 0.664 | Acc: 83.329% (6933/8320)/ 95.613% (7955/8320)
01/14/2023 14:07:23 - INFO - __main__ -   test: [batch: 65/391 ] | Loss: 0.677 | Acc: 82.824% (6997/8448)/ 95.526% (8070/8448)
01/14/2023 14:07:26 - INFO - __main__ -   test: [batch: 66/391 ] | Loss: 0.682 | Acc: 82.847% (7105/8576)/ 95.487% (8189/8576)
01/14/2023 14:07:28 - INFO - __main__ -   test: [batch: 67/391 ] | Loss: 0.685 | Acc: 82.801% (7207/8704)/ 95.508% (8313/8704)
01/14/2023 14:07:31 - INFO - __main__ -   test: [batch: 68/391 ] | Loss: 0.686 | Acc: 82.767% (7310/8832)/ 95.528% (8437/8832)
01/14/2023 14:07:33 - INFO - __main__ -   test: [batch: 69/391 ] | Loss: 0.681 | Acc: 82.857% (7424/8960)/ 95.569% (8563/8960)
01/14/2023 14:07:36 - INFO - __main__ -   test: [batch: 70/391 ] | Loss: 0.683 | Acc: 82.779% (7523/9088)/ 95.566% (8685/9088)
01/14/2023 14:07:39 - INFO - __main__ -   test: [batch: 71/391 ] | Loss: 0.681 | Acc: 82.823% (7633/9216)/ 95.584% (8809/9216)
01/14/2023 14:07:41 - INFO - __main__ -   test: [batch: 72/391 ] | Loss: 0.683 | Acc: 82.716% (7729/9344)/ 95.591% (8932/9344)
01/14/2023 14:07:44 - INFO - __main__ -   test: [batch: 73/391 ] | Loss: 0.686 | Acc: 82.622% (7826/9472)/ 95.598% (9055/9472)
01/14/2023 14:07:47 - INFO - __main__ -   test: [batch: 74/391 ] | Loss: 0.687 | Acc: 82.594% (7929/9600)/ 95.583% (9176/9600)
01/14/2023 14:07:49 - INFO - __main__ -   test: [batch: 75/391 ] | Loss: 0.693 | Acc: 82.391% (8015/9728)/ 95.569% (9297/9728)
01/14/2023 14:07:52 - INFO - __main__ -   test: [batch: 76/391 ] | Loss: 0.693 | Acc: 82.376% (8119/9856)/ 95.566% (9419/9856)
01/14/2023 14:07:55 - INFO - __main__ -   test: [batch: 77/391 ] | Loss: 0.694 | Acc: 82.352% (8222/9984)/ 95.593% (9544/9984)
01/14/2023 14:07:57 - INFO - __main__ -   test: [batch: 78/391 ] | Loss: 0.694 | Acc: 82.229% (8315/10112)/ 95.629% (9670/10112)
01/14/2023 14:08:00 - INFO - __main__ -   test: [batch: 79/391 ] | Loss: 0.693 | Acc: 82.227% (8420/10240)/ 95.645% (9794/10240)
01/14/2023 14:08:02 - INFO - __main__ -   test: [batch: 80/391 ] | Loss: 0.693 | Acc: 82.186% (8521/10368)/ 95.650% (9917/10368)
01/14/2023 14:08:05 - INFO - __main__ -   test: [batch: 81/391 ] | Loss: 0.692 | Acc: 82.212% (8629/10496)/ 95.675% (10042/10496)
01/14/2023 14:08:08 - INFO - __main__ -   test: [batch: 82/391 ] | Loss: 0.691 | Acc: 82.229% (8736/10624)/ 95.670% (10164/10624)
01/14/2023 14:08:11 - INFO - __main__ -   test: [batch: 83/391 ] | Loss: 0.691 | Acc: 82.264% (8845/10752)/ 95.657% (10285/10752)
01/14/2023 14:08:13 - INFO - __main__ -   test: [batch: 84/391 ] | Loss: 0.687 | Acc: 82.381% (8963/10880)/ 95.689% (10411/10880)
01/14/2023 14:08:16 - INFO - __main__ -   test: [batch: 85/391 ] | Loss: 0.686 | Acc: 82.386% (9069/11008)/ 95.730% (10538/11008)
01/14/2023 14:08:18 - INFO - __main__ -   test: [batch: 86/391 ] | Loss: 0.690 | Acc: 82.328% (9168/11136)/ 95.708% (10658/11136)
01/14/2023 14:08:21 - INFO - __main__ -   test: [batch: 87/391 ] | Loss: 0.688 | Acc: 82.369% (9278/11264)/ 95.721% (10782/11264)
01/14/2023 14:08:24 - INFO - __main__ -   test: [batch: 88/391 ] | Loss: 0.695 | Acc: 82.286% (9374/11392)/ 95.655% (10897/11392)
01/14/2023 14:08:26 - INFO - __main__ -   test: [batch: 89/391 ] | Loss: 0.693 | Acc: 82.335% (9485/11520)/ 95.668% (11021/11520)
01/14/2023 14:08:29 - INFO - __main__ -   test: [batch: 90/391 ] | Loss: 0.694 | Acc: 82.220% (9577/11648)/ 95.673% (11144/11648)
01/14/2023 14:08:31 - INFO - __main__ -   test: [batch: 91/391 ] | Loss: 0.693 | Acc: 82.252% (9686/11776)/ 95.678% (11267/11776)
01/14/2023 14:08:34 - INFO - __main__ -   test: [batch: 92/391 ] | Loss: 0.694 | Acc: 82.233% (9789/11904)/ 95.665% (11388/11904)
01/14/2023 14:08:36 - INFO - __main__ -   test: [batch: 93/391 ] | Loss: 0.698 | Acc: 82.048% (9872/12032)/ 95.695% (11514/12032)
01/14/2023 14:08:39 - INFO - __main__ -   test: [batch: 94/391 ] | Loss: 0.700 | Acc: 81.916% (9961/12160)/ 95.707% (11638/12160)
01/14/2023 14:08:42 - INFO - __main__ -   test: [batch: 95/391 ] | Loss: 0.698 | Acc: 81.974% (10073/12288)/ 95.711% (11761/12288)
01/14/2023 14:08:44 - INFO - __main__ -   test: [batch: 96/391 ] | Loss: 0.701 | Acc: 81.894% (10168/12416)/ 95.723% (11885/12416)
01/14/2023 14:08:47 - INFO - __main__ -   test: [batch: 97/391 ] | Loss: 0.703 | Acc: 81.728% (10252/12544)/ 95.743% (12010/12544)
01/14/2023 14:08:49 - INFO - __main__ -   test: [batch: 98/391 ] | Loss: 0.699 | Acc: 81.834% (10370/12672)/ 95.778% (12137/12672)
01/14/2023 14:08:52 - INFO - __main__ -   test: [batch: 99/391 ] | Loss: 0.693 | Acc: 81.984% (10494/12800)/ 95.820% (12265/12800)
01/14/2023 14:08:55 - INFO - __main__ -   test: [batch: 100/391 ] | Loss: 0.693 | Acc: 82.039% (10606/12928)/ 95.823% (12388/12928)
01/14/2023 14:08:57 - INFO - __main__ -   test: [batch: 101/391 ] | Loss: 0.688 | Acc: 82.138% (10724/13056)/ 95.856% (12515/13056)
01/14/2023 14:09:00 - INFO - __main__ -   test: [batch: 102/391 ] | Loss: 0.685 | Acc: 82.259% (10845/13184)/ 95.881% (12641/13184)
01/14/2023 14:09:02 - INFO - __main__ -   test: [batch: 103/391 ] | Loss: 0.686 | Acc: 82.084% (10927/13312)/ 95.906% (12767/13312)
01/14/2023 14:09:04 - INFO - __main__ -   test: [batch: 104/391 ] | Loss: 0.686 | Acc: 82.024% (11024/13440)/ 95.915% (12891/13440)
01/14/2023 14:09:07 - INFO - __main__ -   test: [batch: 105/391 ] | Loss: 0.687 | Acc: 82.017% (11128/13568)/ 95.917% (13014/13568)
01/14/2023 14:09:09 - INFO - __main__ -   test: [batch: 106/391 ] | Loss: 0.695 | Acc: 81.900% (11217/13696)/ 95.853% (13128/13696)
01/14/2023 14:09:11 - INFO - __main__ -   test: [batch: 107/391 ] | Loss: 0.691 | Acc: 82.017% (11338/13824)/ 95.884% (13255/13824)
01/14/2023 14:09:13 - INFO - __main__ -   test: [batch: 108/391 ] | Loss: 0.694 | Acc: 81.874% (11423/13952)/ 95.893% (13379/13952)
01/14/2023 14:09:15 - INFO - __main__ -   test: [batch: 109/391 ] | Loss: 0.695 | Acc: 81.847% (11524/14080)/ 95.895% (13502/14080)
01/14/2023 14:09:17 - INFO - __main__ -   test: [batch: 110/391 ] | Loss: 0.698 | Acc: 81.672% (11604/14208)/ 95.911% (13627/14208)
01/14/2023 14:09:19 - INFO - __main__ -   test: [batch: 111/391 ] | Loss: 0.701 | Acc: 81.620% (11701/14336)/ 95.871% (13744/14336)
01/14/2023 14:09:22 - INFO - __main__ -   test: [batch: 112/391 ] | Loss: 0.702 | Acc: 81.637% (11808/14464)/ 95.886% (13869/14464)
01/14/2023 14:09:24 - INFO - __main__ -   test: [batch: 113/391 ] | Loss: 0.701 | Acc: 81.668% (11917/14592)/ 95.895% (13993/14592)
01/14/2023 14:09:26 - INFO - __main__ -   test: [batch: 114/391 ] | Loss: 0.697 | Acc: 81.753% (12034/14720)/ 95.924% (14120/14720)
01/14/2023 14:09:29 - INFO - __main__ -   test: [batch: 115/391 ] | Loss: 0.694 | Acc: 81.829% (12150/14848)/ 95.946% (14246/14848)
01/14/2023 14:09:31 - INFO - __main__ -   test: [batch: 116/391 ] | Loss: 0.698 | Acc: 81.804% (12251/14976)/ 95.913% (14364/14976)
01/14/2023 14:09:34 - INFO - __main__ -   test: [batch: 117/391 ] | Loss: 0.696 | Acc: 81.826% (12359/15104)/ 95.928% (14489/15104)
01/14/2023 14:09:36 - INFO - __main__ -   test: [batch: 118/391 ] | Loss: 0.699 | Acc: 81.729% (12449/15232)/ 95.936% (14613/15232)
01/14/2023 14:09:39 - INFO - __main__ -   test: [batch: 119/391 ] | Loss: 0.697 | Acc: 81.790% (12563/15360)/ 95.957% (14739/15360)
01/14/2023 14:09:41 - INFO - __main__ -   test: [batch: 120/391 ] | Loss: 0.696 | Acc: 81.844% (12676/15488)/ 95.971% (14864/15488)
01/14/2023 14:09:43 - INFO - __main__ -   test: [batch: 121/391 ] | Loss: 0.700 | Acc: 81.705% (12759/15616)/ 95.946% (14983/15616)
01/14/2023 14:09:45 - INFO - __main__ -   test: [batch: 122/391 ] | Loss: 0.702 | Acc: 81.650% (12855/15744)/ 95.922% (15102/15744)
01/14/2023 14:09:47 - INFO - __main__ -   test: [batch: 123/391 ] | Loss: 0.703 | Acc: 81.666% (12962/15872)/ 95.924% (15225/15872)
01/14/2023 14:09:49 - INFO - __main__ -   test: [batch: 124/391 ] | Loss: 0.702 | Acc: 81.675% (13068/16000)/ 95.938% (15350/16000)
01/14/2023 14:09:51 - INFO - __main__ -   test: [batch: 125/391 ] | Loss: 0.698 | Acc: 81.777% (13189/16128)/ 95.964% (15477/16128)
01/14/2023 14:09:53 - INFO - __main__ -   test: [batch: 126/391 ] | Loss: 0.694 | Acc: 81.865% (13308/16256)/ 95.977% (15602/16256)
01/14/2023 14:09:56 - INFO - __main__ -   test: [batch: 127/391 ] | Loss: 0.692 | Acc: 81.946% (13426/16384)/ 95.984% (15726/16384)
01/14/2023 14:09:58 - INFO - __main__ -   test: [batch: 128/391 ] | Loss: 0.693 | Acc: 81.928% (13528/16512)/ 95.961% (15845/16512)
01/14/2023 14:10:00 - INFO - __main__ -   test: [batch: 129/391 ] | Loss: 0.692 | Acc: 81.947% (13636/16640)/ 95.968% (15969/16640)
01/14/2023 14:10:02 - INFO - __main__ -   test: [batch: 130/391 ] | Loss: 0.688 | Acc: 82.043% (13757/16768)/ 95.986% (16095/16768)
01/14/2023 14:10:04 - INFO - __main__ -   test: [batch: 131/391 ] | Loss: 0.688 | Acc: 82.090% (13870/16896)/ 95.993% (16219/16896)
01/14/2023 14:10:06 - INFO - __main__ -   test: [batch: 132/391 ] | Loss: 0.686 | Acc: 82.155% (13986/17024)/ 96.006% (16344/17024)
01/14/2023 14:10:08 - INFO - __main__ -   test: [batch: 133/391 ] | Loss: 0.687 | Acc: 82.107% (14083/17152)/ 95.995% (16465/17152)
01/14/2023 14:10:10 - INFO - __main__ -   test: [batch: 134/391 ] | Loss: 0.685 | Acc: 82.135% (14193/17280)/ 96.019% (16592/17280)
01/14/2023 14:10:13 - INFO - __main__ -   test: [batch: 135/391 ] | Loss: 0.685 | Acc: 82.123% (14296/17408)/ 96.019% (16715/17408)
01/14/2023 14:10:15 - INFO - __main__ -   test: [batch: 136/391 ] | Loss: 0.684 | Acc: 82.083% (14394/17536)/ 96.042% (16842/17536)
01/14/2023 14:10:17 - INFO - __main__ -   test: [batch: 137/391 ] | Loss: 0.682 | Acc: 82.116% (14505/17664)/ 96.071% (16970/17664)
01/14/2023 14:10:19 - INFO - __main__ -   test: [batch: 138/391 ] | Loss: 0.681 | Acc: 82.161% (14618/17792)/ 96.071% (17093/17792)
01/14/2023 14:10:21 - INFO - __main__ -   test: [batch: 139/391 ] | Loss: 0.686 | Acc: 82.009% (14696/17920)/ 96.055% (17213/17920)
01/14/2023 14:10:23 - INFO - __main__ -   test: [batch: 140/391 ] | Loss: 0.688 | Acc: 81.943% (14789/18048)/ 96.049% (17335/18048)
01/14/2023 14:10:25 - INFO - __main__ -   test: [batch: 141/391 ] | Loss: 0.687 | Acc: 81.971% (14899/18176)/ 96.061% (17460/18176)
01/14/2023 14:10:27 - INFO - __main__ -   test: [batch: 142/391 ] | Loss: 0.684 | Acc: 82.042% (15017/18304)/ 96.077% (17586/18304)
01/14/2023 14:10:30 - INFO - __main__ -   test: [batch: 143/391 ] | Loss: 0.685 | Acc: 82.058% (15125/18432)/ 96.067% (17707/18432)
01/14/2023 14:10:32 - INFO - __main__ -   test: [batch: 144/391 ] | Loss: 0.687 | Acc: 82.020% (15223/18560)/ 96.040% (17825/18560)
01/14/2023 14:10:34 - INFO - __main__ -   test: [batch: 145/391 ] | Loss: 0.690 | Acc: 81.994% (15323/18688)/ 96.013% (17943/18688)
01/14/2023 14:10:36 - INFO - __main__ -   test: [batch: 146/391 ] | Loss: 0.691 | Acc: 81.978% (15425/18816)/ 95.993% (18062/18816)
01/14/2023 14:10:38 - INFO - __main__ -   test: [batch: 147/391 ] | Loss: 0.692 | Acc: 81.978% (15530/18944)/ 95.978% (18182/18944)
01/14/2023 14:10:40 - INFO - __main__ -   test: [batch: 148/391 ] | Loss: 0.693 | Acc: 81.916% (15623/19072)/ 95.973% (18304/19072)
01/14/2023 14:10:42 - INFO - __main__ -   test: [batch: 149/391 ] | Loss: 0.697 | Acc: 81.823% (15710/19200)/ 95.943% (18421/19200)
01/14/2023 14:10:44 - INFO - __main__ -   test: [batch: 150/391 ] | Loss: 0.697 | Acc: 81.757% (15802/19328)/ 95.949% (18545/19328)
01/14/2023 14:10:46 - INFO - __main__ -   test: [batch: 151/391 ] | Loss: 0.697 | Acc: 81.785% (15912/19456)/ 95.950% (18668/19456)
01/14/2023 14:10:48 - INFO - __main__ -   test: [batch: 152/391 ] | Loss: 0.699 | Acc: 81.771% (16014/19584)/ 95.935% (18788/19584)
01/14/2023 14:10:50 - INFO - __main__ -   test: [batch: 153/391 ] | Loss: 0.697 | Acc: 81.828% (16130/19712)/ 95.936% (18911/19712)
01/14/2023 14:10:52 - INFO - __main__ -   test: [batch: 154/391 ] | Loss: 0.697 | Acc: 81.809% (16231/19840)/ 95.912% (19029/19840)
01/14/2023 14:10:55 - INFO - __main__ -   test: [batch: 155/391 ] | Loss: 0.698 | Acc: 81.831% (16340/19968)/ 95.908% (19151/19968)
01/14/2023 14:10:57 - INFO - __main__ -   test: [batch: 156/391 ] | Loss: 0.700 | Acc: 81.753% (16429/20096)/ 95.885% (19269/20096)
01/14/2023 14:10:59 - INFO - __main__ -   test: [batch: 157/391 ] | Loss: 0.702 | Acc: 81.735% (16530/20224)/ 95.861% (19387/20224)
01/14/2023 14:11:01 - INFO - __main__ -   test: [batch: 158/391 ] | Loss: 0.703 | Acc: 81.702% (16628/20352)/ 95.833% (19504/20352)
01/14/2023 14:11:03 - INFO - __main__ -   test: [batch: 159/391 ] | Loss: 0.704 | Acc: 81.675% (16727/20480)/ 95.835% (19627/20480)
01/14/2023 14:11:05 - INFO - __main__ -   test: [batch: 160/391 ] | Loss: 0.705 | Acc: 81.662% (16829/20608)/ 95.812% (19745/20608)
01/14/2023 14:11:07 - INFO - __main__ -   test: [batch: 161/391 ] | Loss: 0.714 | Acc: 81.438% (16887/20736)/ 95.718% (19848/20736)
01/14/2023 14:11:09 - INFO - __main__ -   test: [batch: 162/391 ] | Loss: 0.719 | Acc: 81.336% (16970/20864)/ 95.638% (19954/20864)
01/14/2023 14:11:11 - INFO - __main__ -   test: [batch: 163/391 ] | Loss: 0.722 | Acc: 81.288% (17064/20992)/ 95.622% (20073/20992)
01/14/2023 14:11:14 - INFO - __main__ -   test: [batch: 164/391 ] | Loss: 0.722 | Acc: 81.274% (17165/21120)/ 95.639% (20199/21120)
01/14/2023 14:11:16 - INFO - __main__ -   test: [batch: 165/391 ] | Loss: 0.724 | Acc: 81.198% (17253/21248)/ 95.637% (20321/21248)
01/14/2023 14:11:18 - INFO - __main__ -   test: [batch: 166/391 ] | Loss: 0.724 | Acc: 81.217% (17361/21376)/ 95.621% (20440/21376)
01/14/2023 14:11:20 - INFO - __main__ -   test: [batch: 167/391 ] | Loss: 0.726 | Acc: 81.152% (17451/21504)/ 95.605% (20559/21504)
01/14/2023 14:11:22 - INFO - __main__ -   test: [batch: 168/391 ] | Loss: 0.725 | Acc: 81.153% (17555/21632)/ 95.599% (20680/21632)
01/14/2023 14:11:24 - INFO - __main__ -   test: [batch: 169/391 ] | Loss: 0.727 | Acc: 81.131% (17654/21760)/ 95.565% (20795/21760)
01/14/2023 14:11:26 - INFO - __main__ -   test: [batch: 170/391 ] | Loss: 0.732 | Acc: 81.031% (17736/21888)/ 95.532% (20910/21888)
01/14/2023 14:11:29 - INFO - __main__ -   test: [batch: 171/391 ] | Loss: 0.736 | Acc: 80.964% (17825/22016)/ 95.499% (21025/22016)
01/14/2023 14:11:31 - INFO - __main__ -   test: [batch: 172/391 ] | Loss: 0.737 | Acc: 80.920% (17919/22144)/ 95.493% (21146/22144)
01/14/2023 14:11:33 - INFO - __main__ -   test: [batch: 173/391 ] | Loss: 0.739 | Acc: 80.868% (18011/22272)/ 95.461% (21261/22272)
01/14/2023 14:11:35 - INFO - __main__ -   test: [batch: 174/391 ] | Loss: 0.743 | Acc: 80.777% (18094/22400)/ 95.415% (21373/22400)
01/14/2023 14:11:37 - INFO - __main__ -   test: [batch: 175/391 ] | Loss: 0.741 | Acc: 80.819% (18207/22528)/ 95.423% (21497/22528)
01/14/2023 14:11:39 - INFO - __main__ -   test: [batch: 176/391 ] | Loss: 0.742 | Acc: 80.809% (18308/22656)/ 95.405% (21615/22656)
01/14/2023 14:11:41 - INFO - __main__ -   test: [batch: 177/391 ] | Loss: 0.746 | Acc: 80.745% (18397/22784)/ 95.361% (21727/22784)
01/14/2023 14:11:43 - INFO - __main__ -   test: [batch: 178/391 ] | Loss: 0.747 | Acc: 80.731% (18497/22912)/ 95.339% (21844/22912)
01/14/2023 14:11:45 - INFO - __main__ -   test: [batch: 179/391 ] | Loss: 0.750 | Acc: 80.686% (18590/23040)/ 95.295% (21956/23040)
01/14/2023 14:11:47 - INFO - __main__ -   test: [batch: 180/391 ] | Loss: 0.757 | Acc: 80.559% (18664/23168)/ 95.256% (22069/23168)
01/14/2023 14:11:49 - INFO - __main__ -   test: [batch: 181/391 ] | Loss: 0.763 | Acc: 80.426% (18736/23296)/ 95.197% (22177/23296)
01/14/2023 14:11:51 - INFO - __main__ -   test: [batch: 182/391 ] | Loss: 0.762 | Acc: 80.439% (18842/23424)/ 95.197% (22299/23424)
01/14/2023 14:11:54 - INFO - __main__ -   test: [batch: 183/391 ] | Loss: 0.768 | Acc: 80.312% (18915/23552)/ 95.109% (22400/23552)
01/14/2023 14:11:56 - INFO - __main__ -   test: [batch: 184/391 ] | Loss: 0.768 | Acc: 80.334% (19023/23680)/ 95.097% (22519/23680)
01/14/2023 14:11:58 - INFO - __main__ -   test: [batch: 185/391 ] | Loss: 0.768 | Acc: 80.339% (19127/23808)/ 95.090% (22639/23808)
01/14/2023 14:12:00 - INFO - __main__ -   test: [batch: 186/391 ] | Loss: 0.771 | Acc: 80.297% (19220/23936)/ 95.049% (22751/23936)
01/14/2023 14:12:02 - INFO - __main__ -   test: [batch: 187/391 ] | Loss: 0.775 | Acc: 80.182% (19295/24064)/ 95.026% (22867/24064)
01/14/2023 14:12:04 - INFO - __main__ -   test: [batch: 188/391 ] | Loss: 0.779 | Acc: 80.060% (19368/24192)/ 95.002% (22983/24192)
01/14/2023 14:12:06 - INFO - __main__ -   test: [batch: 189/391 ] | Loss: 0.781 | Acc: 79.992% (19454/24320)/ 95.000% (23104/24320)
01/14/2023 14:12:09 - INFO - __main__ -   test: [batch: 190/391 ] | Loss: 0.785 | Acc: 79.904% (19535/24448)/ 94.977% (23220/24448)
01/14/2023 14:12:11 - INFO - __main__ -   test: [batch: 191/391 ] | Loss: 0.788 | Acc: 79.862% (19627/24576)/ 94.958% (23337/24576)
01/14/2023 14:12:13 - INFO - __main__ -   test: [batch: 192/391 ] | Loss: 0.794 | Acc: 79.752% (19702/24704)/ 94.879% (23439/24704)
01/14/2023 14:12:15 - INFO - __main__ -   test: [batch: 193/391 ] | Loss: 0.793 | Acc: 79.772% (19809/24832)/ 94.874% (23559/24832)
01/14/2023 14:12:17 - INFO - __main__ -   test: [batch: 194/391 ] | Loss: 0.796 | Acc: 79.712% (19896/24960)/ 94.864% (23678/24960)
01/14/2023 14:12:19 - INFO - __main__ -   test: [batch: 195/391 ] | Loss: 0.801 | Acc: 79.640% (19980/25088)/ 94.802% (23784/25088)
01/14/2023 14:12:21 - INFO - __main__ -   test: [batch: 196/391 ] | Loss: 0.805 | Acc: 79.537% (20056/25216)/ 94.761% (23895/25216)
01/14/2023 14:12:23 - INFO - __main__ -   test: [batch: 197/391 ] | Loss: 0.809 | Acc: 79.463% (20139/25344)/ 94.740% (24011/25344)
01/14/2023 14:12:25 - INFO - __main__ -   test: [batch: 198/391 ] | Loss: 0.811 | Acc: 79.428% (20232/25472)/ 94.712% (24125/25472)
01/14/2023 14:12:27 - INFO - __main__ -   test: [batch: 199/391 ] | Loss: 0.810 | Acc: 79.410% (20329/25600)/ 94.719% (24248/25600)
01/14/2023 14:12:29 - INFO - __main__ -   test: [batch: 200/391 ] | Loss: 0.810 | Acc: 79.369% (20420/25728)/ 94.718% (24369/25728)
01/14/2023 14:12:32 - INFO - __main__ -   test: [batch: 201/391 ] | Loss: 0.814 | Acc: 79.289% (20501/25856)/ 94.682% (24481/25856)
01/14/2023 14:12:34 - INFO - __main__ -   test: [batch: 202/391 ] | Loss: 0.815 | Acc: 79.272% (20598/25984)/ 94.674% (24600/25984)
01/14/2023 14:12:36 - INFO - __main__ -   test: [batch: 203/391 ] | Loss: 0.816 | Acc: 79.259% (20696/26112)/ 94.661% (24718/26112)
01/14/2023 14:12:38 - INFO - __main__ -   test: [batch: 204/391 ] | Loss: 0.819 | Acc: 79.162% (20772/26240)/ 94.642% (24834/26240)
01/14/2023 14:12:40 - INFO - __main__ -   test: [batch: 205/391 ] | Loss: 0.822 | Acc: 79.073% (20850/26368)/ 94.607% (24946/26368)
01/14/2023 14:12:42 - INFO - __main__ -   test: [batch: 206/391 ] | Loss: 0.823 | Acc: 79.050% (20945/26496)/ 94.603% (25066/26496)
01/14/2023 14:12:44 - INFO - __main__ -   test: [batch: 207/391 ] | Loss: 0.827 | Acc: 78.955% (21021/26624)/ 94.573% (25179/26624)
01/14/2023 14:12:46 - INFO - __main__ -   test: [batch: 208/391 ] | Loss: 0.829 | Acc: 78.914% (21111/26752)/ 94.542% (25292/26752)
01/14/2023 14:12:48 - INFO - __main__ -   test: [batch: 209/391 ] | Loss: 0.829 | Acc: 78.910% (21211/26880)/ 94.557% (25417/26880)
01/14/2023 14:12:51 - INFO - __main__ -   test: [batch: 210/391 ] | Loss: 0.830 | Acc: 78.895% (21308/27008)/ 94.539% (25533/27008)
01/14/2023 14:12:53 - INFO - __main__ -   test: [batch: 211/391 ] | Loss: 0.832 | Acc: 78.840% (21394/27136)/ 94.520% (25649/27136)
01/14/2023 14:12:55 - INFO - __main__ -   test: [batch: 212/391 ] | Loss: 0.834 | Acc: 78.778% (21478/27264)/ 94.498% (25764/27264)
01/14/2023 14:12:57 - INFO - __main__ -   test: [batch: 213/391 ] | Loss: 0.834 | Acc: 78.778% (21579/27392)/ 94.506% (25887/27392)
01/14/2023 14:12:59 - INFO - __main__ -   test: [batch: 214/391 ] | Loss: 0.834 | Acc: 78.757% (21674/27520)/ 94.506% (26008/27520)
01/14/2023 14:13:01 - INFO - __main__ -   test: [batch: 215/391 ] | Loss: 0.834 | Acc: 78.772% (21779/27648)/ 94.499% (26127/27648)
01/14/2023 14:13:03 - INFO - __main__ -   test: [batch: 216/391 ] | Loss: 0.832 | Acc: 78.813% (21891/27776)/ 94.517% (26253/27776)
01/14/2023 14:13:05 - INFO - __main__ -   test: [batch: 217/391 ] | Loss: 0.837 | Acc: 78.741% (21972/27904)/ 94.452% (26356/27904)
01/14/2023 14:13:08 - INFO - __main__ -   test: [batch: 218/391 ] | Loss: 0.840 | Acc: 78.692% (22059/28032)/ 94.421% (26468/28032)
01/14/2023 14:13:10 - INFO - __main__ -   test: [batch: 219/391 ] | Loss: 0.839 | Acc: 78.722% (22168/28160)/ 94.425% (26590/28160)
01/14/2023 14:13:12 - INFO - __main__ -   test: [batch: 220/391 ] | Loss: 0.837 | Acc: 78.758% (22279/28288)/ 94.439% (26715/28288)
01/14/2023 14:13:14 - INFO - __main__ -   test: [batch: 221/391 ] | Loss: 0.839 | Acc: 78.716% (22368/28416)/ 94.422% (26831/28416)
01/14/2023 14:13:16 - INFO - __main__ -   test: [batch: 222/391 ] | Loss: 0.837 | Acc: 78.777% (22486/28544)/ 94.437% (26956/28544)
01/14/2023 14:13:18 - INFO - __main__ -   test: [batch: 223/391 ] | Loss: 0.837 | Acc: 78.774% (22586/28672)/ 94.430% (27075/28672)
01/14/2023 14:13:20 - INFO - __main__ -   test: [batch: 224/391 ] | Loss: 0.837 | Acc: 78.799% (22694/28800)/ 94.424% (27194/28800)
01/14/2023 14:13:22 - INFO - __main__ -   test: [batch: 225/391 ] | Loss: 0.836 | Acc: 78.792% (22793/28928)/ 94.424% (27315/28928)
01/14/2023 14:13:25 - INFO - __main__ -   test: [batch: 226/391 ] | Loss: 0.836 | Acc: 78.769% (22887/29056)/ 94.435% (27439/29056)
01/14/2023 14:13:27 - INFO - __main__ -   test: [batch: 227/391 ] | Loss: 0.838 | Acc: 78.752% (22983/29184)/ 94.425% (27557/29184)
01/14/2023 14:13:29 - INFO - __main__ -   test: [batch: 228/391 ] | Loss: 0.843 | Acc: 78.671% (23060/29312)/ 94.367% (27661/29312)
01/14/2023 14:13:31 - INFO - __main__ -   test: [batch: 229/391 ] | Loss: 0.846 | Acc: 78.611% (23143/29440)/ 94.321% (27768/29440)
01/14/2023 14:13:33 - INFO - __main__ -   test: [batch: 230/391 ] | Loss: 0.849 | Acc: 78.555% (23227/29568)/ 94.284% (27878/29568)
01/14/2023 14:13:35 - INFO - __main__ -   test: [batch: 231/391 ] | Loss: 0.849 | Acc: 78.539% (23323/29696)/ 94.272% (27995/29696)
01/14/2023 14:13:37 - INFO - __main__ -   test: [batch: 232/391 ] | Loss: 0.848 | Acc: 78.564% (23431/29824)/ 94.286% (28120/29824)
01/14/2023 14:13:39 - INFO - __main__ -   test: [batch: 233/391 ] | Loss: 0.850 | Acc: 78.519% (23518/29952)/ 94.267% (28235/29952)
01/14/2023 14:13:41 - INFO - __main__ -   test: [batch: 234/391 ] | Loss: 0.856 | Acc: 78.401% (23583/30080)/ 94.192% (28333/30080)
01/14/2023 14:13:43 - INFO - __main__ -   test: [batch: 235/391 ] | Loss: 0.856 | Acc: 78.390% (23680/30208)/ 94.190% (28453/30208)
01/14/2023 14:13:46 - INFO - __main__ -   test: [batch: 236/391 ] | Loss: 0.855 | Acc: 78.425% (23791/30336)/ 94.195% (28575/30336)
01/14/2023 14:13:48 - INFO - __main__ -   test: [batch: 237/391 ] | Loss: 0.855 | Acc: 78.430% (23893/30464)/ 94.160% (28685/30464)
01/14/2023 14:13:50 - INFO - __main__ -   test: [batch: 238/391 ] | Loss: 0.854 | Acc: 78.471% (24006/30592)/ 94.168% (28808/30592)
01/14/2023 14:13:52 - INFO - __main__ -   test: [batch: 239/391 ] | Loss: 0.853 | Acc: 78.509% (24118/30720)/ 94.170% (28929/30720)
01/14/2023 14:13:54 - INFO - __main__ -   test: [batch: 240/391 ] | Loss: 0.853 | Acc: 78.527% (24224/30848)/ 94.158% (29046/30848)
01/14/2023 14:13:56 - INFO - __main__ -   test: [batch: 241/391 ] | Loss: 0.856 | Acc: 78.438% (24297/30976)/ 94.118% (29154/30976)
01/14/2023 14:13:58 - INFO - __main__ -   test: [batch: 242/391 ] | Loss: 0.858 | Acc: 78.328% (24363/31104)/ 94.097% (29268/31104)
01/14/2023 14:14:01 - INFO - __main__ -   test: [batch: 243/391 ] | Loss: 0.864 | Acc: 78.199% (24423/31232)/ 94.029% (29367/31232)
01/14/2023 14:14:03 - INFO - __main__ -   test: [batch: 244/391 ] | Loss: 0.864 | Acc: 78.205% (24525/31360)/ 94.031% (29488/31360)
01/14/2023 14:14:05 - INFO - __main__ -   test: [batch: 245/391 ] | Loss: 0.863 | Acc: 78.217% (24629/31488)/ 94.023% (29606/31488)
01/14/2023 14:14:07 - INFO - __main__ -   test: [batch: 246/391 ] | Loss: 0.864 | Acc: 78.188% (24720/31616)/ 94.016% (29724/31616)
01/14/2023 14:14:09 - INFO - __main__ -   test: [batch: 247/391 ] | Loss: 0.870 | Acc: 78.100% (24792/31744)/ 93.948% (29823/31744)
01/14/2023 14:14:11 - INFO - __main__ -   test: [batch: 248/391 ] | Loss: 0.870 | Acc: 78.056% (24878/31872)/ 93.941% (29941/31872)
01/14/2023 14:14:13 - INFO - __main__ -   test: [batch: 249/391 ] | Loss: 0.872 | Acc: 77.931% (24938/32000)/ 93.934% (30059/32000)
01/14/2023 14:14:15 - INFO - __main__ -   test: [batch: 250/391 ] | Loss: 0.871 | Acc: 77.966% (25049/32128)/ 93.952% (30185/32128)
01/14/2023 14:14:17 - INFO - __main__ -   test: [batch: 251/391 ] | Loss: 0.874 | Acc: 77.914% (25132/32256)/ 93.921% (30295/32256)
01/14/2023 14:14:19 - INFO - __main__ -   test: [batch: 252/391 ] | Loss: 0.873 | Acc: 77.940% (25240/32384)/ 93.914% (30413/32384)
01/14/2023 14:14:22 - INFO - __main__ -   test: [batch: 253/391 ] | Loss: 0.874 | Acc: 77.910% (25330/32512)/ 93.898% (30528/32512)
01/14/2023 14:14:24 - INFO - __main__ -   test: [batch: 254/391 ] | Loss: 0.878 | Acc: 77.846% (25409/32640)/ 93.854% (30634/32640)
01/14/2023 14:14:26 - INFO - __main__ -   test: [batch: 255/391 ] | Loss: 0.880 | Acc: 77.811% (25497/32768)/ 93.842% (30750/32768)
01/14/2023 14:14:28 - INFO - __main__ -   test: [batch: 256/391 ] | Loss: 0.885 | Acc: 77.684% (25555/32896)/ 93.805% (30858/32896)
01/14/2023 14:14:30 - INFO - __main__ -   test: [batch: 257/391 ] | Loss: 0.886 | Acc: 77.668% (25649/33024)/ 93.792% (30974/33024)
01/14/2023 14:14:32 - INFO - __main__ -   test: [batch: 258/391 ] | Loss: 0.887 | Acc: 77.660% (25746/33152)/ 93.777% (31089/33152)
01/14/2023 14:14:34 - INFO - __main__ -   test: [batch: 259/391 ] | Loss: 0.891 | Acc: 77.539% (25805/33280)/ 93.768% (31206/33280)
01/14/2023 14:14:36 - INFO - __main__ -   test: [batch: 260/391 ] | Loss: 0.891 | Acc: 77.517% (25897/33408)/ 93.759% (31323/33408)
01/14/2023 14:14:38 - INFO - __main__ -   test: [batch: 261/391 ] | Loss: 0.889 | Acc: 77.564% (26012/33536)/ 93.780% (31450/33536)
01/14/2023 14:14:41 - INFO - __main__ -   test: [batch: 262/391 ] | Loss: 0.888 | Acc: 77.590% (26120/33664)/ 93.789% (31573/33664)
01/14/2023 14:14:43 - INFO - __main__ -   test: [batch: 263/391 ] | Loss: 0.891 | Acc: 77.521% (26196/33792)/ 93.762% (31684/33792)
01/14/2023 14:14:45 - INFO - __main__ -   test: [batch: 264/391 ] | Loss: 0.896 | Acc: 77.456% (26273/33920)/ 93.697% (31782/33920)
01/14/2023 14:14:47 - INFO - __main__ -   test: [batch: 265/391 ] | Loss: 0.896 | Acc: 77.479% (26380/34048)/ 93.700% (31903/34048)
01/14/2023 14:14:49 - INFO - __main__ -   test: [batch: 266/391 ] | Loss: 0.898 | Acc: 77.411% (26456/34176)/ 93.683% (32017/34176)
01/14/2023 14:14:51 - INFO - __main__ -   test: [batch: 267/391 ] | Loss: 0.897 | Acc: 77.440% (26565/34304)/ 93.683% (32137/34304)
01/14/2023 14:14:53 - INFO - __main__ -   test: [batch: 268/391 ] | Loss: 0.897 | Acc: 77.466% (26673/34432)/ 93.680% (32256/34432)
01/14/2023 14:14:55 - INFO - __main__ -   test: [batch: 269/391 ] | Loss: 0.899 | Acc: 77.416% (26755/34560)/ 93.660% (32369/34560)
01/14/2023 14:14:57 - INFO - __main__ -   test: [batch: 270/391 ] | Loss: 0.902 | Acc: 77.350% (26831/34688)/ 93.632% (32479/34688)
01/14/2023 14:14:59 - INFO - __main__ -   test: [batch: 271/391 ] | Loss: 0.902 | Acc: 77.358% (26933/34816)/ 93.626% (32597/34816)
01/14/2023 14:15:01 - INFO - __main__ -   test: [batch: 272/391 ] | Loss: 0.903 | Acc: 77.321% (27019/34944)/ 93.621% (32715/34944)
01/14/2023 14:15:03 - INFO - __main__ -   test: [batch: 273/391 ] | Loss: 0.903 | Acc: 77.327% (27120/35072)/ 93.607% (32830/35072)
01/14/2023 14:15:06 - INFO - __main__ -   test: [batch: 274/391 ] | Loss: 0.903 | Acc: 77.327% (27219/35200)/ 93.614% (32952/35200)
01/14/2023 14:15:08 - INFO - __main__ -   test: [batch: 275/391 ] | Loss: 0.905 | Acc: 77.296% (27307/35328)/ 93.608% (33070/35328)
01/14/2023 14:15:10 - INFO - __main__ -   test: [batch: 276/391 ] | Loss: 0.906 | Acc: 77.253% (27391/35456)/ 93.603% (33188/35456)
01/14/2023 14:15:12 - INFO - __main__ -   test: [batch: 277/391 ] | Loss: 0.907 | Acc: 77.229% (27481/35584)/ 93.593% (33304/35584)
01/14/2023 14:15:14 - INFO - __main__ -   test: [batch: 278/391 ] | Loss: 0.906 | Acc: 77.237% (27583/35712)/ 93.590% (33423/35712)
01/14/2023 14:15:16 - INFO - __main__ -   test: [batch: 279/391 ] | Loss: 0.907 | Acc: 77.246% (27685/35840)/ 93.577% (33538/35840)
01/14/2023 14:15:18 - INFO - __main__ -   test: [batch: 280/391 ] | Loss: 0.907 | Acc: 77.227% (27777/35968)/ 93.572% (33656/35968)
01/14/2023 14:15:20 - INFO - __main__ -   test: [batch: 281/391 ] | Loss: 0.908 | Acc: 77.236% (27879/36096)/ 93.567% (33774/36096)
01/14/2023 14:15:22 - INFO - __main__ -   test: [batch: 282/391 ] | Loss: 0.907 | Acc: 77.269% (27990/36224)/ 93.571% (33895/36224)
01/14/2023 14:15:24 - INFO - __main__ -   test: [batch: 283/391 ] | Loss: 0.907 | Acc: 77.247% (28081/36352)/ 93.566% (34013/36352)
01/14/2023 14:15:26 - INFO - __main__ -   test: [batch: 284/391 ] | Loss: 0.911 | Acc: 77.198% (28162/36480)/ 93.531% (34120/36480)
01/14/2023 14:15:29 - INFO - __main__ -   test: [batch: 285/391 ] | Loss: 0.913 | Acc: 77.161% (28247/36608)/ 93.482% (34222/36608)
01/14/2023 14:15:31 - INFO - __main__ -   test: [batch: 286/391 ] | Loss: 0.914 | Acc: 77.129% (28334/36736)/ 93.470% (34337/36736)
01/14/2023 14:15:33 - INFO - __main__ -   test: [batch: 287/391 ] | Loss: 0.915 | Acc: 77.127% (28432/36864)/ 93.465% (34455/36864)
01/14/2023 14:15:35 - INFO - __main__ -   test: [batch: 288/391 ] | Loss: 0.914 | Acc: 77.146% (28538/36992)/ 93.466% (34575/36992)
01/14/2023 14:15:37 - INFO - __main__ -   test: [batch: 289/391 ] | Loss: 0.916 | Acc: 77.107% (28622/37120)/ 93.427% (34680/37120)
01/14/2023 14:15:39 - INFO - __main__ -   test: [batch: 290/391 ] | Loss: 0.917 | Acc: 77.035% (28694/37248)/ 93.428% (34800/37248)
01/14/2023 14:15:41 - INFO - __main__ -   test: [batch: 291/391 ] | Loss: 0.917 | Acc: 77.039% (28794/37376)/ 93.418% (34916/37376)
01/14/2023 14:15:43 - INFO - __main__ -   test: [batch: 292/391 ] | Loss: 0.919 | Acc: 76.992% (28875/37504)/ 93.398% (35028/37504)
01/14/2023 14:15:46 - INFO - __main__ -   test: [batch: 293/391 ] | Loss: 0.919 | Acc: 76.982% (28970/37632)/ 93.394% (35146/37632)
01/14/2023 14:15:48 - INFO - __main__ -   test: [batch: 294/391 ] | Loss: 0.920 | Acc: 76.960% (29060/37760)/ 93.387% (35263/37760)
01/14/2023 14:15:50 - INFO - __main__ -   test: [batch: 295/391 ] | Loss: 0.919 | Acc: 76.990% (29170/37888)/ 93.391% (35384/37888)
01/14/2023 14:15:52 - INFO - __main__ -   test: [batch: 296/391 ] | Loss: 0.919 | Acc: 76.981% (29265/38016)/ 93.382% (35500/38016)
01/14/2023 14:15:54 - INFO - __main__ -   test: [batch: 297/391 ] | Loss: 0.921 | Acc: 76.964% (29357/38144)/ 93.357% (35610/38144)
01/14/2023 14:15:56 - INFO - __main__ -   test: [batch: 298/391 ] | Loss: 0.923 | Acc: 76.936% (29445/38272)/ 93.335% (35721/38272)
01/14/2023 14:15:58 - INFO - __main__ -   test: [batch: 299/391 ] | Loss: 0.924 | Acc: 76.927% (29540/38400)/ 93.312% (35832/38400)
01/14/2023 14:16:00 - INFO - __main__ -   test: [batch: 300/391 ] | Loss: 0.925 | Acc: 76.931% (29640/38528)/ 93.309% (35950/38528)
01/14/2023 14:16:03 - INFO - __main__ -   test: [batch: 301/391 ] | Loss: 0.925 | Acc: 76.917% (29733/38656)/ 93.295% (36064/38656)
01/14/2023 14:16:05 - INFO - __main__ -   test: [batch: 302/391 ] | Loss: 0.927 | Acc: 76.877% (29816/38784)/ 93.281% (36178/38784)
01/14/2023 14:16:07 - INFO - __main__ -   test: [batch: 303/391 ] | Loss: 0.928 | Acc: 76.853% (29905/38912)/ 93.267% (36292/38912)
01/14/2023 14:16:09 - INFO - __main__ -   test: [batch: 304/391 ] | Loss: 0.927 | Acc: 76.872% (30011/39040)/ 93.271% (36413/39040)
01/14/2023 14:16:11 - INFO - __main__ -   test: [batch: 305/391 ] | Loss: 0.928 | Acc: 76.828% (30092/39168)/ 93.260% (36528/39168)
01/14/2023 14:16:13 - INFO - __main__ -   test: [batch: 306/391 ] | Loss: 0.929 | Acc: 76.809% (30183/39296)/ 93.238% (36639/39296)
01/14/2023 14:16:15 - INFO - __main__ -   test: [batch: 307/391 ] | Loss: 0.930 | Acc: 76.814% (30283/39424)/ 93.222% (36752/39424)
01/14/2023 14:16:17 - INFO - __main__ -   test: [batch: 308/391 ] | Loss: 0.931 | Acc: 76.798% (30375/39552)/ 93.219% (36870/39552)
01/14/2023 14:16:19 - INFO - __main__ -   test: [batch: 309/391 ] | Loss: 0.932 | Acc: 76.794% (30472/39680)/ 93.198% (36981/39680)
01/14/2023 14:16:22 - INFO - __main__ -   test: [batch: 310/391 ] | Loss: 0.932 | Acc: 76.784% (30566/39808)/ 93.187% (37096/39808)
01/14/2023 14:16:24 - INFO - __main__ -   test: [batch: 311/391 ] | Loss: 0.934 | Acc: 76.755% (30653/39936)/ 93.172% (37209/39936)
01/14/2023 14:16:26 - INFO - __main__ -   test: [batch: 312/391 ] | Loss: 0.935 | Acc: 76.740% (30745/40064)/ 93.151% (37320/40064)
01/14/2023 14:16:28 - INFO - __main__ -   test: [batch: 313/391 ] | Loss: 0.934 | Acc: 76.779% (30859/40192)/ 93.170% (37447/40192)
01/14/2023 14:16:30 - INFO - __main__ -   test: [batch: 314/391 ] | Loss: 0.934 | Acc: 76.773% (30955/40320)/ 93.167% (37565/40320)
01/14/2023 14:16:32 - INFO - __main__ -   test: [batch: 315/391 ] | Loss: 0.935 | Acc: 76.755% (31046/40448)/ 93.154% (37679/40448)
01/14/2023 14:16:34 - INFO - __main__ -   test: [batch: 316/391 ] | Loss: 0.937 | Acc: 76.664% (31107/40576)/ 93.131% (37789/40576)
01/14/2023 14:16:36 - INFO - __main__ -   test: [batch: 317/391 ] | Loss: 0.939 | Acc: 76.621% (31188/40704)/ 93.106% (37898/40704)
01/14/2023 14:16:39 - INFO - __main__ -   test: [batch: 318/391 ] | Loss: 0.938 | Acc: 76.651% (31298/40832)/ 93.123% (38024/40832)
01/14/2023 14:16:41 - INFO - __main__ -   test: [batch: 319/391 ] | Loss: 0.941 | Acc: 76.597% (31374/40960)/ 93.098% (38133/40960)
01/14/2023 14:16:43 - INFO - __main__ -   test: [batch: 320/391 ] | Loss: 0.939 | Acc: 76.633% (31487/41088)/ 93.107% (38256/41088)
01/14/2023 14:16:45 - INFO - __main__ -   test: [batch: 321/391 ] | Loss: 0.939 | Acc: 76.647% (31591/41216)/ 93.100% (38372/41216)
01/14/2023 14:16:47 - INFO - __main__ -   test: [batch: 322/391 ] | Loss: 0.941 | Acc: 76.621% (31678/41344)/ 93.095% (38489/41344)
01/14/2023 14:16:49 - INFO - __main__ -   test: [batch: 323/391 ] | Loss: 0.943 | Acc: 76.582% (31760/41472)/ 93.072% (38599/41472)
01/14/2023 14:16:51 - INFO - __main__ -   test: [batch: 324/391 ] | Loss: 0.943 | Acc: 76.584% (31859/41600)/ 93.067% (38716/41600)
01/14/2023 14:16:53 - INFO - __main__ -   test: [batch: 325/391 ] | Loss: 0.943 | Acc: 76.591% (31960/41728)/ 93.065% (38834/41728)
01/14/2023 14:16:55 - INFO - __main__ -   test: [batch: 326/391 ] | Loss: 0.946 | Acc: 76.510% (32024/41856)/ 93.033% (38940/41856)
01/14/2023 14:16:57 - INFO - __main__ -   test: [batch: 327/391 ] | Loss: 0.949 | Acc: 76.431% (32089/41984)/ 93.002% (39046/41984)
01/14/2023 14:17:00 - INFO - __main__ -   test: [batch: 328/391 ] | Loss: 0.951 | Acc: 76.380% (32165/42112)/ 92.981% (39156/42112)
01/14/2023 14:17:02 - INFO - __main__ -   test: [batch: 329/391 ] | Loss: 0.951 | Acc: 76.380% (32263/42240)/ 92.983% (39276/42240)
01/14/2023 14:17:04 - INFO - __main__ -   test: [batch: 330/391 ] | Loss: 0.953 | Acc: 76.338% (32343/42368)/ 92.959% (39385/42368)
01/14/2023 14:17:06 - INFO - __main__ -   test: [batch: 331/391 ] | Loss: 0.953 | Acc: 76.306% (32427/42496)/ 92.973% (39510/42496)
01/14/2023 14:17:08 - INFO - __main__ -   test: [batch: 332/391 ] | Loss: 0.953 | Acc: 76.293% (32519/42624)/ 92.973% (39629/42624)
01/14/2023 14:17:10 - INFO - __main__ -   test: [batch: 333/391 ] | Loss: 0.952 | Acc: 76.322% (32629/42752)/ 92.983% (39752/42752)
01/14/2023 14:17:12 - INFO - __main__ -   test: [batch: 334/391 ] | Loss: 0.953 | Acc: 76.290% (32713/42880)/ 92.964% (39863/42880)
01/14/2023 14:17:14 - INFO - __main__ -   test: [batch: 335/391 ] | Loss: 0.954 | Acc: 76.270% (32802/43008)/ 92.955% (39978/43008)
01/14/2023 14:17:16 - INFO - __main__ -   test: [batch: 336/391 ] | Loss: 0.956 | Acc: 76.224% (32880/43136)/ 92.939% (40090/43136)
01/14/2023 14:17:18 - INFO - __main__ -   test: [batch: 337/391 ] | Loss: 0.956 | Acc: 76.216% (32974/43264)/ 92.934% (40207/43264)
01/14/2023 14:17:21 - INFO - __main__ -   test: [batch: 338/391 ] | Loss: 0.956 | Acc: 76.203% (33066/43392)/ 92.943% (40330/43392)
01/14/2023 14:17:22 - INFO - __main__ -   test: [batch: 339/391 ] | Loss: 0.959 | Acc: 76.167% (33148/43520)/ 92.918% (40438/43520)
01/14/2023 14:17:24 - INFO - __main__ -   test: [batch: 340/391 ] | Loss: 0.959 | Acc: 76.162% (33243/43648)/ 92.928% (40561/43648)
01/14/2023 14:17:27 - INFO - __main__ -   test: [batch: 341/391 ] | Loss: 0.957 | Acc: 76.202% (33358/43776)/ 92.944% (40687/43776)
01/14/2023 14:17:28 - INFO - __main__ -   test: [batch: 342/391 ] | Loss: 0.958 | Acc: 76.146% (33431/43904)/ 92.937% (40803/43904)
01/14/2023 14:17:31 - INFO - __main__ -   test: [batch: 343/391 ] | Loss: 0.957 | Acc: 76.145% (33528/44032)/ 92.939% (40923/44032)
01/14/2023 14:17:33 - INFO - __main__ -   test: [batch: 344/391 ] | Loss: 0.958 | Acc: 76.144% (33625/44160)/ 92.930% (41038/44160)
01/14/2023 14:17:35 - INFO - __main__ -   test: [batch: 345/391 ] | Loss: 0.961 | Acc: 76.073% (33691/44288)/ 92.887% (41138/44288)
01/14/2023 14:17:37 - INFO - __main__ -   test: [batch: 346/391 ] | Loss: 0.963 | Acc: 76.056% (33781/44416)/ 92.874% (41251/44416)
01/14/2023 14:17:39 - INFO - __main__ -   test: [batch: 347/391 ] | Loss: 0.962 | Acc: 76.071% (33885/44544)/ 92.883% (41374/44544)
01/14/2023 14:17:41 - INFO - __main__ -   test: [batch: 348/391 ] | Loss: 0.964 | Acc: 76.050% (33973/44672)/ 92.859% (41482/44672)
01/14/2023 14:17:44 - INFO - __main__ -   test: [batch: 349/391 ] | Loss: 0.963 | Acc: 76.054% (34072/44800)/ 92.866% (41604/44800)
01/14/2023 14:17:46 - INFO - __main__ -   test: [batch: 350/391 ] | Loss: 0.963 | Acc: 76.068% (34176/44928)/ 92.864% (41722/44928)
01/14/2023 14:17:48 - INFO - __main__ -   test: [batch: 351/391 ] | Loss: 0.965 | Acc: 76.017% (34250/45056)/ 92.849% (41834/45056)
01/14/2023 14:17:50 - INFO - __main__ -   test: [batch: 352/391 ] | Loss: 0.966 | Acc: 76.018% (34348/45184)/ 92.845% (41951/45184)
01/14/2023 14:17:52 - INFO - __main__ -   test: [batch: 353/391 ] | Loss: 0.968 | Acc: 75.980% (34428/45312)/ 92.803% (42051/45312)
01/14/2023 14:17:54 - INFO - __main__ -   test: [batch: 354/391 ] | Loss: 0.970 | Acc: 75.922% (34499/45440)/ 92.784% (42161/45440)
01/14/2023 14:17:57 - INFO - __main__ -   test: [batch: 355/391 ] | Loss: 0.973 | Acc: 75.860% (34568/45568)/ 92.778% (42277/45568)
01/14/2023 14:17:59 - INFO - __main__ -   test: [batch: 356/391 ] | Loss: 0.973 | Acc: 75.862% (34666/45696)/ 92.781% (42397/45696)
01/14/2023 14:18:01 - INFO - __main__ -   test: [batch: 357/391 ] | Loss: 0.972 | Acc: 75.895% (34778/45824)/ 92.794% (42522/45824)
01/14/2023 14:18:03 - INFO - __main__ -   test: [batch: 358/391 ] | Loss: 0.971 | Acc: 75.923% (34888/45952)/ 92.797% (42642/45952)
01/14/2023 14:18:05 - INFO - __main__ -   test: [batch: 359/391 ] | Loss: 0.972 | Acc: 75.933% (34990/46080)/ 92.793% (42759/46080)
01/14/2023 14:18:07 - INFO - __main__ -   test: [batch: 360/391 ] | Loss: 0.974 | Acc: 75.902% (35073/46208)/ 92.787% (42875/46208)
01/14/2023 14:18:09 - INFO - __main__ -   test: [batch: 361/391 ] | Loss: 0.974 | Acc: 75.900% (35169/46336)/ 92.794% (42997/46336)
01/14/2023 14:18:11 - INFO - __main__ -   test: [batch: 362/391 ] | Loss: 0.973 | Acc: 75.902% (35267/46464)/ 92.807% (43122/46464)
01/14/2023 14:18:13 - INFO - __main__ -   test: [batch: 363/391 ] | Loss: 0.973 | Acc: 75.897% (35362/46592)/ 92.799% (43237/46592)
01/14/2023 14:18:16 - INFO - __main__ -   test: [batch: 364/391 ] | Loss: 0.972 | Acc: 75.923% (35471/46720)/ 92.810% (43361/46720)
01/14/2023 14:18:18 - INFO - __main__ -   test: [batch: 365/391 ] | Loss: 0.972 | Acc: 75.937% (35575/46848)/ 92.815% (43482/46848)
01/14/2023 14:18:20 - INFO - __main__ -   test: [batch: 366/391 ] | Loss: 0.970 | Acc: 75.973% (35689/46976)/ 92.833% (43609/46976)
01/14/2023 14:18:22 - INFO - __main__ -   test: [batch: 367/391 ] | Loss: 0.969 | Acc: 75.994% (35796/47104)/ 92.843% (43733/47104)
01/14/2023 14:18:24 - INFO - __main__ -   test: [batch: 368/391 ] | Loss: 0.969 | Acc: 75.997% (35895/47232)/ 92.852% (43856/47232)
01/14/2023 14:18:26 - INFO - __main__ -   test: [batch: 369/391 ] | Loss: 0.968 | Acc: 76.016% (36001/47360)/ 92.861% (43979/47360)
01/14/2023 14:18:28 - INFO - __main__ -   test: [batch: 370/391 ] | Loss: 0.968 | Acc: 76.000% (36091/47488)/ 92.861% (44098/47488)
01/14/2023 14:18:31 - INFO - __main__ -   test: [batch: 371/391 ] | Loss: 0.968 | Acc: 76.006% (36191/47616)/ 92.864% (44218/47616)
01/14/2023 14:18:33 - INFO - __main__ -   test: [batch: 372/391 ] | Loss: 0.966 | Acc: 76.054% (36311/47744)/ 92.881% (44345/47744)
01/14/2023 14:18:35 - INFO - __main__ -   test: [batch: 373/391 ] | Loss: 0.965 | Acc: 76.088% (36425/47872)/ 92.889% (44468/47872)
01/14/2023 14:18:37 - INFO - __main__ -   test: [batch: 374/391 ] | Loss: 0.963 | Acc: 76.119% (36537/48000)/ 92.896% (44590/48000)
01/14/2023 14:18:39 - INFO - __main__ -   test: [batch: 375/391 ] | Loss: 0.966 | Acc: 76.058% (36605/48128)/ 92.861% (44692/48128)
01/14/2023 14:18:41 - INFO - __main__ -   test: [batch: 376/391 ] | Loss: 0.967 | Acc: 76.049% (36698/48256)/ 92.846% (44804/48256)
01/14/2023 14:18:43 - INFO - __main__ -   test: [batch: 377/391 ] | Loss: 0.968 | Acc: 76.035% (36789/48384)/ 92.836% (44918/48384)
01/14/2023 14:18:45 - INFO - __main__ -   test: [batch: 378/391 ] | Loss: 0.971 | Acc: 75.963% (36851/48512)/ 92.798% (45018/48512)
01/14/2023 14:18:48 - INFO - __main__ -   test: [batch: 379/391 ] | Loss: 0.971 | Acc: 75.944% (36939/48640)/ 92.804% (45140/48640)
01/14/2023 14:18:50 - INFO - __main__ -   test: [batch: 380/391 ] | Loss: 0.971 | Acc: 75.939% (37034/48768)/ 92.811% (45262/48768)
01/14/2023 14:18:52 - INFO - __main__ -   test: [batch: 381/391 ] | Loss: 0.972 | Acc: 75.896% (37110/48896)/ 92.809% (45380/48896)
01/14/2023 14:18:54 - INFO - __main__ -   test: [batch: 382/391 ] | Loss: 0.974 | Acc: 75.863% (37191/49024)/ 92.797% (45493/49024)
01/14/2023 14:18:56 - INFO - __main__ -   test: [batch: 383/391 ] | Loss: 0.974 | Acc: 75.875% (37294/49152)/ 92.790% (45608/49152)
01/14/2023 14:18:58 - INFO - __main__ -   test: [batch: 384/391 ] | Loss: 0.972 | Acc: 75.913% (37410/49280)/ 92.802% (45733/49280)
01/14/2023 14:19:00 - INFO - __main__ -   test: [batch: 385/391 ] | Loss: 0.971 | Acc: 75.923% (37512/49408)/ 92.813% (45857/49408)
01/14/2023 14:19:02 - INFO - __main__ -   test: [batch: 386/391 ] | Loss: 0.969 | Acc: 75.967% (37631/49536)/ 92.829% (45984/49536)
01/14/2023 14:19:04 - INFO - __main__ -   test: [batch: 387/391 ] | Loss: 0.967 | Acc: 76.007% (37748/49664)/ 92.840% (46108/49664)
01/14/2023 14:19:06 - INFO - __main__ -   test: [batch: 388/391 ] | Loss: 0.966 | Acc: 76.052% (37868/49792)/ 92.852% (46233/49792)
01/14/2023 14:19:09 - INFO - __main__ -   test: [batch: 389/391 ] | Loss: 0.965 | Acc: 76.056% (37967/49920)/ 92.853% (46352/49920)
01/14/2023 14:19:11 - INFO - __main__ -   test: [batch: 390/391 ] | Loss: 0.967 | Acc: 76.006% (38003/50000)/ 92.842% (46421/50000)
01/14/2023 14:19:11 - INFO - __main__ -   Final accuracy: 76.006
